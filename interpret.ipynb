{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import copy\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import cl_gym as cl\n",
    "from metrics import MetricCollector2, FairMetricCollector\n",
    "from configs import make_params\n",
    "\n",
    "std_datasets = [\"MNIST\", \"FashionMNIST\", \"CIFAR10\", \"CIFAR100\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(dataset, seed, epoch, lr, tau, alpha, lmbd, method, verbose=0):\n",
    "    log_dir = f\"scripts_output/dataset={dataset}\"\n",
    "    target_dir = f\"seed={seed}_epoch={epoch}_lr={lr}\"\n",
    "    log_dir = os.path.join(log_dir, method)\n",
    "    if method in ['FSW', \"GSS\"]:\n",
    "        target_dir+=f\"_tau={tau}_alpha={alpha}\"\n",
    "        if alpha != 0 and dataset not in std_datasets:\n",
    "            target_dir+=f\"_lmbd={lmbd}_lmbdold={0.0}\"\n",
    "\n",
    "    if not target_dir in os.listdir(log_dir):\n",
    "        for dir in os.listdir(log_dir):\n",
    "            if target_dir in dir:\n",
    "                target_dir = dir\n",
    "                break\n",
    "\n",
    "    # print(f\"{target_dir=}\")\n",
    "    log_dir = os.path.join(log_dir, target_dir)\n",
    "    # print(f\"{log_dir=}\")\n",
    "    out = os.path.join(log_dir, \"log.out\")\n",
    "    err = os.path.join(log_dir, \"log.err\")\n",
    "    if os.path.exists(err):\n",
    "        with open(err, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "        if len(lines):\n",
    "            if verbose:\n",
    "                print(f\"Error in {target_dir} - error during running\")\n",
    "                for line in lines:\n",
    "                    print(line)\n",
    "            return False\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(f\"error in {target_dir} - not exists\")\n",
    "        return False\n",
    "    return target_dir\n",
    "\n",
    "def check_running(dataset, target_dir, method):\n",
    "    log_dir = f\"scripts_output/dataset={dataset}\"\n",
    "    log_dir = os.path.join(log_dir, method)\n",
    "    log_dir = os.path.join(log_dir, target_dir)        \n",
    "    out = os.path.join(log_dir, \"log.out\")\n",
    "    if os.path.exists(out):\n",
    "        with open(out, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "    if len(lines) == 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def load_log(dataset, target_dir, method):\n",
    "    log_dir = f\"scripts_output/dataset={dataset}\"\n",
    "    log_dir = os.path.join(log_dir, method)\n",
    "    log_dir = os.path.join(log_dir, target_dir)      \n",
    "    # print(f\"load_log_log_{log_dir=}\")  \n",
    "    out = os.path.join(log_dir, \"log.out\")\n",
    "    acc, fairness = 0, 0\n",
    "    if os.path.exists(out):\n",
    "        with open(out, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "        if \"accuracy\" in lines[-2]:\n",
    "            acc = float(lines[-2].strip().split(\":\")[-1])\n",
    "        elif \"accuracy\" in lines[-3]:\n",
    "            acc = float(lines[-3].strip().split(\":\")[-1])\n",
    "        if \"fairness\" in lines[-1]:\n",
    "            fairness = float(lines[-1].strip().split(\":\")[-1])\n",
    "        elif \"fairness\" in lines[-2]:\n",
    "            fairness = float(lines[-2].strip().split(\":\")[-1])\n",
    "    else:\n",
    "        print(f\"{out=} not exists\")\n",
    "    if acc * fairness == 0:\n",
    "        print(f\"{out=} : wrong output\")\n",
    "    return acc, fairness\n",
    "\n",
    "def load_metrics(dataset, target_dir, method, validation=False):\n",
    "    metrics_dir = f\"outputs/dataset={dataset}\"\n",
    "    metrics_dir = os.path.join(metrics_dir, method)\n",
    "\n",
    "    metrics_dir = os.path.join(metrics_dir, target_dir)\n",
    "    if not os.path.exists(metrics_dir):\n",
    "        metrics_dir = metrics_dir.replace(\"lmbd=\", \"lmbd_\")\n",
    "        metrics_dir = metrics_dir.replace(\"lmbdold=\", \"lmbdold_\")\n",
    "    out = os.path.join(metrics_dir, \"plots/output.txt\")\n",
    "\n",
    "    if validation:\n",
    "        if os.path.exists(out):\n",
    "            with open(out, \"r\") as f:\n",
    "                lines = f.readlines()\n",
    "            for i, line in enumerate(lines):\n",
    "                if i == 0:\n",
    "                    continue\n",
    "                if \"acc\" in line:\n",
    "                    acc = float(lines[i+1].strip())\n",
    "        else:\n",
    "            print(f\"{out=} not exists\")\n",
    "        if acc != load_log(dataset, target_dir, method)[0]:\n",
    "            print(acc)\n",
    "            print(load_log(dataset, target_dir, method)[0])\n",
    "            raise ValueError\n",
    "    \n",
    "    metrics_dir = os.path.join(metrics_dir, \"metrics/metrics.pickle\")\n",
    "    with open(metrics_dir, \"rb\") as f:\n",
    "        metric_manager_callback = pickle.load(f)\n",
    "    return metric_manager_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best(dataset, seed_range, epoch, lr_range, tau_range, alpha_range, lambda_range, \\\n",
    "             method, verbose=0):\n",
    "    acc_list = list()\n",
    "    fair_list = list()\n",
    "    info_list = list()\n",
    "    fair_metric = \"multiclass_eo\"\n",
    "    if dataset in std_datasets:\n",
    "        lambda_range = [0]\n",
    "        fair_metric = \"std\"\n",
    "    # MNIST\n",
    "    for tau in tau_range:\n",
    "        for lr in lr_range:\n",
    "            for alpha in alpha_range:\n",
    "                for lmbd in lambda_range:\n",
    "                    cnt = 0\n",
    "                    acc_sum = 0\n",
    "                    fair_sum = 0\n",
    "                    info = f\"tau={tau}/lr_{lr}/alpha_{alpha}\"\n",
    "                    # print(f\"{info=}\")\n",
    "                    avail_seed = copy.deepcopy(seed_range)\n",
    "                    for seed in seed_range:\n",
    "                        target_dir = load(dataset, seed, epoch, lr, tau, alpha, lmbd, method)\n",
    "                        # print(f\"{target_dir=}\")\n",
    "                        if not target_dir or check_running(dataset, target_dir, method):\n",
    "                            avail_seed.remove(seed)\n",
    "                            # print(seed)\n",
    "                            # print(target_dir)\n",
    "                            continue\n",
    "                        acc, fair = load_log(dataset, target_dir, method)\n",
    "                        if acc*fair == 0:\n",
    "                            avail_seed.remove(seed)\n",
    "                            # print(seed)\n",
    "                            # print(target_dir)\n",
    "                            continue\n",
    "                        mmc = load_metrics(dataset, target_dir, method)\n",
    "                        \n",
    "                        acc = np.mean(mmc.meters['accuracy'].compute_overall())\n",
    "                        fair = np.mean(mmc.meters[fair_metric].compute_overall())\n",
    "                        acc_sum+=acc\n",
    "                        fair_sum+=fair\n",
    "                        cnt+=1\n",
    "                    info = f\"tau={tau}/lr_{lr}/alpha_{alpha}({cnt=}, {avail_seed})\"\n",
    "                    if cnt == 0:\n",
    "                        print(f\"{info=}: check if boom?\")\n",
    "                        continue\n",
    "\n",
    "                    info_list.append(info)\n",
    "                    acc_list.append(acc_sum/cnt)\n",
    "                    fair_list.append(fair_sum/cnt)\n",
    "                    out = f\"{info}\\n{acc_sum/cnt}\\n{fair_sum/cnt}\"\n",
    "                    if verbose:\n",
    "                        print(out)\n",
    "    if verbose:\n",
    "        print()\n",
    "    \n",
    "    integrated_score = [e - 2*fair_list[i] for i, e in enumerate(acc_list)]\n",
    "    idx = integrated_score.index(max(integrated_score))\n",
    "    print(f\"{info_list[idx]}\")\n",
    "    accuracy = acc_list[idx]\n",
    "    fairness = fair_list[idx]\n",
    "\n",
    "    if accuracy > 1:\n",
    "        accuracy /= 100\n",
    "    print(f\"acc:{accuracy}\")\n",
    "    print(f\"fair:{fairness}\")\n",
    "    return info_list, acc_list, fair_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot(acc_list, fair_list, marker = \"o\"):\n",
    "    plt.scatter(acc_list, fair_list, marker=marker, s = 10)\n",
    "    plt.xlabel('acc')\n",
    "    plt.ylabel('fairness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(dataset, epoch, size = 20):\n",
    "    print(\"joint\")\n",
    "    tau_range = [0.0]\n",
    "    # lr_range = [0.01, 0.001]\n",
    "    lr_range = [0.01]\n",
    "    alpha_range = [0.0]\n",
    "    lambda_range = [0.0]\n",
    "    seed_range = [0, 1, 2, 3, 4]\n",
    "\n",
    "    joint_info_list, joint_acc_list, joint_fair_list = get_best(dataset, seed_range, epoch, lr_range, tau_range, alpha_range, lambda_range, \"joint\")\n",
    "    plt.scatter(joint_acc_list, joint_fair_list, marker='o', s = size)\n",
    "\n",
    "    print(\"finetune\")\n",
    "    tau_range = [0.0]\n",
    "    alpha_range = [0.0]\n",
    "    lambda_range = [0.0]\n",
    "    seed_range = [0, 1, 2, 3, 4]\n",
    "    finetune_info_list, finetune_acc_list, finetune_fair_list = get_best(dataset, seed_range, epoch, lr_range, tau_range, alpha_range, lambda_range, \"finetune\")\n",
    "    # plt.scatter(finetune_acc_list, finetune_fair_list, marker='x', s = size)\n",
    "\n",
    "\n",
    "    print(\"vanilla\")\n",
    "    tau_range = [1.0, 5.0, 10.0]\n",
    "    alpha_range = [0.0]\n",
    "    lambda_range = [1.0, 5.0, 10.0]\n",
    "    seed_range = [0, 1, 2, 3, 4]\n",
    "\n",
    "    base_info_list, base_acc_list, base_fair_list = get_best(dataset, seed_range, epoch, lr_range, tau_range, alpha_range, lambda_range, \"vanilla\")\n",
    "    plt.scatter(base_acc_list, base_fair_list, marker='v', s = size)\n",
    "\n",
    "    print(\"FSW\")\n",
    "    tau_range = [1.0, 5.0, 10.0]\n",
    "    alpha_range = [0.0005, 0.001, 0.002, 0.005, 0.01, 0.02]\n",
    "    lambda_range = [1.0, 5.0, 10.0]\n",
    "    seed_range = [0, 1, 2, 3, 4]\n",
    "\n",
    "    fss_info_list, fss_acc_list, fss_fair_list = get_best(dataset, seed_range, epoch, lr_range, tau_range, alpha_range, lambda_range, \"FSW\")\n",
    "    for i, e in enumerate(fss_info_list):\n",
    "        print(e, fss_acc_list[i], fss_fair_list[i])\n",
    "    plt.scatter(fss_acc_list, fss_fair_list, marker='x', s = size)\n",
    "\n",
    "    target_baseline = [e - 2*base_fair_list[i] for i, e in enumerate(base_acc_list)]\n",
    "    idx = target_baseline.index(max(target_baseline))\n",
    "    base_fair_max = base_fair_list[idx]\n",
    "    base_acc_min = base_acc_list[idx]\n",
    "    plt.xlim([base_acc_min-5, 100])\n",
    "    if dataset != \"BiasedMNIST\":\n",
    "        plt.ylim([0, base_fair_max+5])\n",
    "    else:\n",
    "        plt.ylim([0, base_fair_max+0.15])\n",
    "\n",
    "    plt.xlabel('acc')\n",
    "    if dataset in std_datasets:\n",
    "        plt.ylabel('std')\n",
    "    else:\n",
    "        plt.ylabel('eo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"MNIST\"\n",
    "epoch = 5\n",
    "display(dataset, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"MNIST\"\n",
    "epoch = 5\n",
    "display(dataset, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"MNIST\"\n",
    "epoch = 15\n",
    "display(dataset, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"gss\")\n",
    "dataset = \"MNIST\"\n",
    "epoch = 1\n",
    "tau_range = [1.0, 5.0, 10.0]\n",
    "alpha_range = [0.0]\n",
    "lr_range = [0.01, 0.001]\n",
    "lambda_range = [0.0]\n",
    "seed_range = [0, 1, 2]\n",
    "\n",
    "base_info_list, base_acc_list, base_fair_list = get_best(dataset, seed_range, epoch, lr_range, tau_range, alpha_range, lambda_range)\n",
    "plt.scatter(base_acc_list, base_fair_list, marker='v', s = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_range = [1.0, 5.0, 10.0]\n",
    "lr_range = [0.01, 0.001]\n",
    "alpha_range = [0.0005, 0.001, 0.002, 0.005, 0.01, 0.02]\n",
    "lambda_range = [1.0, 5.0, 10.0]\n",
    "seed_range = [0, 1, 2, 3, 4]\n",
    "\n",
    "\n",
    "info_list, acc_list, fair_list = get_best(dataset, seed_range, epoch, lr_range, tau_range, alpha_range, lambda_range)\n",
    "plot(acc_list, fair_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_range = [1.0, 5.0, 10.0]\n",
    "lr_range = [0.01, 0.001]\n",
    "alpha_range = [0.0]\n",
    "lambda_range = [1.0, 5.0, 10.0]\n",
    "seed_range = [0, 1, 2, 3, 4]\n",
    "\n",
    "info_list, acc_list, fair_list = get_best(dataset, seed_range, epoch, lr_range, tau_range, alpha_range, lambda_range)\n",
    "plot(acc_list, fair_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_range = [0.0]\n",
    "lr_range = [0.01, 0.001]\n",
    "alpha_range = [0.0]\n",
    "seed_range = [0, 1, 2, 3, 4]\n",
    "\n",
    "info_list, acc_list, fair_list = get_best(dataset, seed_range, epoch, lr_range, tau_range, alpha_range, lambda_range, joint=True)\n",
    "plot(acc_list, fair_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_range = [1.0, 5.0, 10.0]\n",
    "lr_range = [0.01, 0.001]\n",
    "alpha_range = [0.0005, 0.001, 0.002, 0.005, 0.01, 0.02]\n",
    "lambda_range = [1.0, 5.0, 10.0]\n",
    "seed_range = [0, 1, 2, 3, 4]\n",
    "\n",
    "dataset = \"FashionMNIST\"\n",
    "epoch = 1\n",
    "lmbd = 1.0\n",
    "\n",
    "info_list, acc_list, fair_list = get_best(dataset, seed_range, epoch, lr_range, tau_range, alpha_range, lambda_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_range = [1.0, 5.0, 10.0]\n",
    "lr_range = [0.01, 0.001]\n",
    "alpha_range = [0.0]\n",
    "lambda_range = [1.0, 5.0, 10.0]\n",
    "seed_range = [0, 1, 2, 3, 4]\n",
    "\n",
    "dataset = \"FashionMNIST\"\n",
    "epoch = 1\n",
    "lmbd = 1.0\n",
    "\n",
    "info_list, acc_list, fair_list = get_best(dataset, seed_range, epoch, lr_range, tau_range, alpha_range, lambda_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
