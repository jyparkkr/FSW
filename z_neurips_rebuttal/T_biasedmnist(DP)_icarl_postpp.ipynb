{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0c3b92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_dir=./outputs/demo/dataset=BiasedMNIST/seed=0_epoch=15_lr=0.1_tau=1.0_alpha=0.0\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST, FashionMNIST, CIFAR10\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import cl_gym as cl\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "seed = 0\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.set_num_threads(8)\n",
    "\n",
    "def make_params() -> dict:\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    import uuid\n",
    "\n",
    "    params = {\n",
    "            # dataset\n",
    "            'dataset': \"BiasedMNIST\",\n",
    "            'fairness_agg': 'mean',\n",
    "            # 'model': 'MLP',\n",
    "\n",
    "            # benchmark\n",
    "            'seed': seed,\n",
    "            'num_tasks': 5,\n",
    "            'epochs_per_task': 15,\n",
    "            'per_task_examples': np.inf,\n",
    "            # 'per_task_examples': 10000,\n",
    "            'per_task_memory_examples': 128,\n",
    "            'batch_size_train': 64,\n",
    "            'batch_size_memory': 64,\n",
    "            'batch_size_validation': 256,\n",
    "            'tau': 1.0,\n",
    "\n",
    "            # algorithm\n",
    "            'optimizer': 'sgd',\n",
    "            'learning_rate': 0.1,\n",
    "            'momentum': 0.9,\n",
    "            'learning_rate_decay': 1.0,\n",
    "            # 'criterion': torch.nn.CrossEntropyLoss(),\n",
    "            'criterion': torch.nn.BCEWithLogitsLoss(),\n",
    "\n",
    "            'device': torch.device('cuda:6' if torch.cuda.is_available() else 'cpu'),\n",
    "             \n",
    "            # sample selection\n",
    "            'alpha': 0.00,\n",
    "            'metric' : \"DP\",\n",
    "            'lambda': 0.0,\n",
    "            'lambda_old': 0.0,\n",
    "\n",
    "            # postprocessing\n",
    "            \"post_processing\": \"eps_fairness\",\n",
    "            \"pp_eps\": 0.0,\n",
    "\n",
    "              }\n",
    "    \n",
    "\n",
    "#     trial_id = str(uuid.uuid4())\n",
    "    trial_id = f\"demo/dataset={params['dataset']}/seed={params['seed']}_epoch={params['epochs_per_task']}_lr={params['learning_rate']}_tau={params['tau']}_alpha={params['alpha']}\"\n",
    "    if params['lambda'] != 0:\n",
    "        trial_id+=f\"_lmbd_{params['lambda']}_lmbdold_{params['lambda_old']}\"\n",
    "    params['trial_id'] = trial_id\n",
    "    params['output_dir'] = os.path.join(\"./outputs/{}\".format(trial_id))\n",
    "    print(f\"output_dir={params['output_dir']}\")\n",
    "    Path(params['output_dir']).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    return params\n",
    "\n",
    "params = make_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99826537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"MNIST\" in params['dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20c7b886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "from datasets import BiasedMNIST\n",
    "\n",
    "if  params['dataset'] in [\"BiasedMNIST\"]:\n",
    "    benchmark = BiasedMNIST(num_tasks=params['num_tasks'],\n",
    "                                per_task_memory_examples=params['per_task_memory_examples'],\n",
    "                                per_task_examples = params['per_task_examples'],\n",
    "                                random_class_idx=False)\n",
    "    input_dim = (3, 28, 28)\n",
    "    class_idx = benchmark.class_idx\n",
    "    num_classes = len(class_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2374d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark.mnist_train.sensitives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1246d96a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87fd9653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAAfklEQVR4nGP8/4+B6oCJ+kaOGjpkDGUhQg2uRIfTQQRdSk4yxu9SZBOZcIhjAUSGKWlBPwARhdVKwqFMV5eSnIwIKsLjQbgUPtMJ2syE2+J/GNZDuXgiisjgxuItPIbiD1Z8aYCYvI9mHCabZEPJSXNYDaU08Q6dQnrUUOoDAA8BEUXMYt+3AAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.transforms.functional import to_pil_image\n",
    "from cl_gym.benchmarks.transforms import MNIST_MEAN, MNIST_STD\n",
    "COLOR_MAP = {\n",
    "    0: (1, 0, 0),\n",
    "    1: (0, 1, 0),\n",
    "    2: (1, 1, 0),\n",
    "    3: (0, 0, 1),\n",
    "    4: (1, 0.65, 0),\n",
    "    5: (0.5, 0, 0.5),\n",
    "    6: (0, 1, 1),\n",
    "    7: (1, 0.75, 0.8),\n",
    "    8: (0.8, 1, 0),\n",
    "    9: (.588, .294, 0.)\n",
    "}\n",
    "\n",
    "r = (1 - 0.1913)\n",
    "color_values = np.array(list(COLOR_MAP.values()))\n",
    "m_rgb = color_values.mean(axis=0)\n",
    "std_rgb = color_values.std(axis=0)\n",
    "\n",
    "bmnist_mean = [r*m + MNIST_MEAN[0] for m in m_rgb]\n",
    "bmnist_std = [(r*s**2+(1-r)*MNIST_STD[0]**2+r*(1-r)*(bmnist_mean[i] - m_rgb[i])**2)**0.5 for i, s in enumerate(std_rgb)]\n",
    "\n",
    "unnormalize = torchvision.transforms.Normalize([-m/s for m, s in zip(bmnist_mean, bmnist_std)], [1/s for s in bmnist_std])\n",
    "sample_idx = 95\n",
    "to_pil_image(unnormalize(benchmark.trains[2][sample_idx][0]), mode=\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8806699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARgAAAAcCAIAAAA1Cjd5AAACgklEQVR4nO2b3W7DIAyFCdpDVnuYrdvDTHtKuotoEYX8GDjGhvpTLyq1IifGBzAhiwtuCB4e3+bCcO8cOt0PQ5vv+CY54nn3d3ybAd8mR7cbxsthRjIMAGYkwwDwdvmPR1RFLWa8KCD10QjBOec8Opi3qEb5BTUenuseqGZAJCM+w8f65ct/t7e2aqML622MhwvxB3+BEHY+OJo0J3rQ2p64tbV8FDo+wYPT20i8c9pRN4O6v2lyZtaG5FwSQjDXMCqHwFKNy0vM3d86F1X/Ko736YpOueBmtr6md/osNQ9z1yYBLRsLYm1rUipPzd1CCF7RzUVZdOAzMqa1vCDWk6wnF9Ugb5fE+bvfp6Zi0SQfmlYvnW8r5XYSJFcC9FKyu4DatWNgrOqIqFYm3LAyqTTzyjM1n4Rl9ktEYBiDmFy07X1LoWLcggX3qONxCdFUHe2ias50Ak6e4+Gk2D2Aw9clHes1F2lTNSkltAU5HzHncJGTnZH0B7HfqQ7sKKC4QOIGcqyhgteNuGo0TEqqFpzdKR03tQSrpkyiZ9v2z5Lk6L25NETianB4hvhOg6McWjX0L0EHZabACt9Jj1BWDaJjPevoRNt01CGk2AKpKDlr8lhLklHWQrJLkU0hRYa2VVOih7KVf0z+LA41hnZY11ES/npptzivxTknUN7wkS1CtPmkiKHFd4GUW/ngocVaJ0dsktdppFxUd10lGw8ML3TNynSbDbu93vwYsWkdsl6dmI7iFvK+4KCt8Y8iI1Xm63nHu8q+X5WUvm8MlyHDZUiNDKqRVO9UHtX0zbmr+q4TsKcZ0LbniyTrUQa6bPkZCRnigUZ9Yy4s8wwDgBnJMAD8AdsJ+6s7YIfOAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=280x28>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_label = 0\n",
    "incremental_step = 1\n",
    "# cat_img = torch.cat([img for img in benchmark.trains[incremental_step].inputs[benchmark.trains[incremental_step].targets == target_label][20:30]], dim=2)\n",
    "cat_img = torch.cat([img for img, target, *_ in benchmark.tests[incremental_step]][20:30], dim=2)\n",
    "to_pil_image(unnormalize(cat_img), mode=\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e73e1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iCaRL\n"
     ]
    }
   ],
   "source": [
    "from trainers import FairContinualTrainer\n",
    "from trainers.fair_trainer import FairContinualTrainer2\n",
    "from metrics import FairMetricCollector\n",
    "from metrics import MetricCollector2\n",
    "\n",
    "from algorithms import Heuristic3\n",
    "from algorithms.fairl import FaIRL\n",
    "from algorithms.icarl import iCaRL\n",
    "from backbones import MLP2Layers2\n",
    "\n",
    "backbone = MLP2Layers2(\n",
    "    input_dim=input_dim, \n",
    "    hidden_dim_1=256, \n",
    "    hidden_dim_2=256, \n",
    "    output_dim=num_classes,\n",
    "    class_idx=class_idx,\n",
    "    config=params\n",
    "    ).to(params['device'])\n",
    "# backbone = ResNet18Small2(\n",
    "#         input_dim=input_dim, \n",
    "#         output_dim=num_classes,\n",
    "#         class_idx=class_idx,\n",
    "#         config=params\n",
    "#     ).to(params['device'])\n",
    "algorithm = iCaRL(backbone, benchmark, params, requires_memory=True)\n",
    "# algorithm = Heuristic3(backbone, benchmark, params, requires_memory=True)\n",
    "\n",
    "metric_manager_callback = FairMetricCollector(num_tasks=params['num_tasks'],\n",
    "                                                        eval_interval='epoch',\n",
    "                                                        epochs_per_task=params['epochs_per_task'])\n",
    "# metric_manager_callback = MetricCollector2(num_tasks=params['num_tasks'],\n",
    "#                                                         eval_interval='epoch',\n",
    "#                                                         epochs_per_task=params['epochs_per_task'])\n",
    "# from trainers.baselines import BaseMemoryContinualTrainer as ContinualTrainer\n",
    "from trainers.baselines import BaseContinualTrainer as ContinualTrainer\n",
    "\n",
    "trainer = ContinualTrainer(algorithm, params, callbacks=[metric_manager_callback])\n",
    "# \n",
    "# trainer = FairContinualTrainer2(algorithm, params, callbacks=[metric_manager_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b28299a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algorithm.params['dataset'] == \"BiasedMNIST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b8e3d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "if params['fairness_agg'] == \"mean\":\n",
    "    agg = np.mean\n",
    "elif params['fairness_agg'] == \"max\":\n",
    "    agg = np.max\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "fairness_metrics = [\"std\", \"EER\", \"EO\", \"DP\"]\n",
    "for metric in metric_manager_callback.meters:\n",
    "    if metric in fairness_metrics:\n",
    "        metric_manager_callback.meters[metric].agg = agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbbb73ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Task 1 -----------------------\n",
      "[1] Eval metrics for task 1 >> {'accuracy': 0.9909804009709611, 'loss': 0.0, 'std': 0.005958374539242972, 'EER': -1, 'EO': [0.03125, 0.0060975609756097615], 'DP': -1, 'accuracy_s0': 1.0, 'accuracy_s1': 0.9813262195121951, 'classwise_accuracy': {1: array([1118, 1135]), 0: array([977, 980])}, 'DP_ingredients': {'class_pred_count_s0': {1: 591, 0: 488}, 'class_pred_count_s1': {1: 543, 0: 493}, 'class_pred_count': {1: 1134, 0: 981}, 'count_s0': 1079, 'count_s1': 1036, 'count': 2115}}\n",
      "[2] Eval metrics for task 1 >> {'accuracy': 0.9912815787107795, 'loss': 0.0, 'std': 0.003616380472894032, 'EER': -1, 'EO': [0.010162601626016232, 0.02573529411764708], 'DP': -1, 'accuracy_s0': 1.0, 'accuracy_s1': 0.9820510521281683, 'classwise_accuracy': {0: array([975, 980]), 1: array([1121, 1135])}, 'DP_ingredients': {'class_pred_count_s0': {0: 488, 1: 591}, 'class_pred_count_s1': {0: 492, 1: 544}, 'class_pred_count': {0: 980, 1: 1135}, 'count_s0': 1079, 'count_s1': 1036, 'count': 2115}}\n"
     ]
    }
   ],
   "source": [
    "trainer.run()\n",
    "print(\"final avg-acc\", metric_manager_callback.meters['accuracy'].compute_final())\n",
    "print(\"final avg-forget\", metric_manager_callback.meters['forgetting'].compute_final())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee4e697",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'iCaRL' object has no attribute 'weight_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m task_weight \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[43malgorithm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight_all\u001b[49m)\n\u001b[1;32m      4\u001b[0m num_bin \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[1;32m      5\u001b[0m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mnum_bin, \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mnum_bin, \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mnum_bin)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'iCaRL' object has no attribute 'weight_all'"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "task_weight = copy.deepcopy(algorithm.weight_all)\n",
    "\n",
    "num_bin = 20\n",
    "np.arange(0+1/num_bin, 1+1/num_bin, 1/num_bin)\n",
    "\n",
    "def bin(w: np.array, num_bin=20):\n",
    "    out = dict()\n",
    "    for r in np.arange(0+1/num_bin, 1+1/num_bin, 1/num_bin):\n",
    "        r = np.round(r, 2)\n",
    "        out[r] = np.sum(np.logical_and(w<=r, r-1/num_bin<w))\n",
    "    out[1/num_bin] += np.sum(w==0)\n",
    "    kk = list(out.keys())\n",
    "    for k in kk:\n",
    "        if out[k] == 0:\n",
    "            del(out[k])\n",
    "    return out\n",
    "\n",
    "\n",
    "binned_weight = dict()\n",
    "for i, wt in enumerate(task_weight):\n",
    "    if i==0:\n",
    "        continue\n",
    "    print(f\"task:{i+1}\")\n",
    "    binned_weight[i+1] = list()\n",
    "    for we in wt:\n",
    "        binned_weight[i+1].append({k: bin(we[k]) for k in we})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48ee970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: [], 3: [], 4: [], 5: []}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binned_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b41373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebde5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.997, 0.   , 0.   , 0.   , 0.   ],\n",
       "       [0.952, 0.928, 0.   , 0.   , 0.   ],\n",
       "       [0.931, 0.854, 0.918, 0.   , 0.   ],\n",
       "       [0.891, 0.811, 0.834, 0.943, 0.   ],\n",
       "       [0.871, 0.747, 0.77 , 0.894, 0.897]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_manager_callback.meters['accuracy'].get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e893eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9085274492422579"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(metric_manager_callback.meters['accuracy'].compute_overall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82bd073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.007, 0.107, 0.141, 0.166, 0.229]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.round(x, 3) for x in metric_manager_callback.meters['EO'].compute_overall()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7973e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13011964420023836"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(metric_manager_callback.meters['EO'].compute_overall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5196d155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.015, 0.005, 0.004, 0.004, 0.003]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.round(x, 3) for x in metric_manager_callback.meters['DP'].compute_overall()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e94bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0062905064140212925"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(metric_manager_callback.meters['DP'].compute_overall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61271a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_id=2\n",
      "sensitive samples / all samples = 568 / 12089\n",
      "sensitive samples / selected samples = 568 / 12089\n"
     ]
    }
   ],
   "source": [
    "task_id = 2\n",
    "\n",
    "print(f\"{task_id=}\")\n",
    "print(f\"sensitive samples / all samples = {(benchmark.trains[task_id].sensitives != benchmark.trains[task_id].targets).sum().item()} / {benchmark.trains[task_id].sensitives.shape[0]}\")\n",
    "\n",
    "updated_seq_indices = benchmark.seq_indices_train[task_id]\n",
    "print(f\"sensitive samples / selected samples = {(benchmark.trains[task_id].sensitives[updated_seq_indices] != benchmark.trains[task_id].targets[updated_seq_indices]).sum().item()} / {len(updated_seq_indices)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32febda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incremental_step=2\n",
      "2 : 5958 --> 5958\n",
      "3 : 6131 --> 6131\n",
      "incremental_step=3\n",
      "4 : 5842 --> 5842\n",
      "5 : 5421 --> 5421\n",
      "incremental_step=4\n",
      "6 : 5918 --> 5918\n",
      "7 : 6265 --> 6265\n",
      "incremental_step=5\n",
      "8 : 5851 --> 5851\n",
      "9 : 5949 --> 5949\n"
     ]
    }
   ],
   "source": [
    "step_class = 2\n",
    "for i in range(2, 6):\n",
    "    incremental_step = i\n",
    "    print(f\"{incremental_step=}\")\n",
    "    one_idx = benchmark.trains[incremental_step].sample_weight > 0.9\n",
    "\n",
    "    print(f\"{2*i-2} : {(benchmark.trains[incremental_step].targets == (2*i-2)).sum().item()} --> {(benchmark.trains[incremental_step].targets[one_idx] == (2*i-2)).sum().item()}\")\n",
    "    print(f\"{2*i-1} : {(benchmark.trains[incremental_step].targets == (2*i-1)).sum().item()} --> {(benchmark.trains[incremental_step].targets[one_idx] == (2*i-1)).sum().item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6233f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0: array([976, 980]), 1: array([1132, 1135])},\n",
       " {0: array([912, 980]),\n",
       "  1: array([1105, 1135]),\n",
       "  3: array([ 949, 1010]),\n",
       "  2: array([ 945, 1032])},\n",
       " {1: array([1094, 1135]),\n",
       "  0: array([880, 980]),\n",
       "  2: array([ 900, 1032]),\n",
       "  3: array([ 845, 1010]),\n",
       "  5: array([774, 892]),\n",
       "  4: array([950, 982])},\n",
       " {1: array([1034, 1135]),\n",
       "  0: array([853, 980]),\n",
       "  3: array([ 806, 1010]),\n",
       "  2: array([ 850, 1032]),\n",
       "  5: array([707, 892]),\n",
       "  4: array([860, 982]),\n",
       "  7: array([ 981, 1028]),\n",
       "  6: array([892, 958])},\n",
       " {1: array([1031, 1135]),\n",
       "  0: array([817, 980]),\n",
       "  3: array([ 713, 1010]),\n",
       "  2: array([ 813, 1032]),\n",
       "  4: array([786, 982]),\n",
       "  5: array([659, 892]),\n",
       "  6: array([866, 958]),\n",
       "  7: array([ 908, 1028]),\n",
       "  9: array([ 867, 1009]),\n",
       "  8: array([910, 974])}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_manager_callback.meters['classwise_accuracy'].get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21212733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2088139f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
