{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0c3b92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_dir=./outputs/demo/dataset=BiasedMNIST/seed=10_epoch=1_lr=0.001_tau=5_alpha=0.0_lmbd_1.0_lmbdold_0.0\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST, FashionMNIST, CIFAR10\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import cl_gym as cl\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "seed = 10\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed) \n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "# torch.backends.cudnn.enabled = False\n",
    "\n",
    "def make_params() -> dict:\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    import uuid\n",
    "\n",
    "    params = {\n",
    "            # dataset\n",
    "            'dataset': \"BiasedMNIST\",\n",
    "            'fairness_agg': 'mean',\n",
    "            'model': 'resnet18',\n",
    "\n",
    "            # benchmark\n",
    "            'seed': seed,\n",
    "            'num_tasks': 5,\n",
    "            'epochs_per_task': 1,\n",
    "            # 'per_task_examples': np.inf,\n",
    "            'per_task_examples': 10000,\n",
    "            'per_task_memory_examples': 128,\n",
    "            'batch_size_train': 64,\n",
    "            'batch_size_memory': 64,\n",
    "            'batch_size_validation': 256,\n",
    "            'tau': 5,\n",
    "\n",
    "            # algorithm\n",
    "            'optimizer': 'sgd',\n",
    "            'learning_rate': 0.001,\n",
    "            'momentum': 0.9,\n",
    "            'learning_rate_decay': 1.0,\n",
    "            'criterion': torch.nn.CrossEntropyLoss(),\n",
    "            'device': torch.device('cuda:6' if torch.cuda.is_available() else 'cpu'),\n",
    "             \n",
    "            # sample selection\n",
    "            'alpha': 0.00,\n",
    "            'lambda': 1.0,\n",
    "            'lambda_old': 0.0,\n",
    "              }\n",
    "    \n",
    "\n",
    "\n",
    "#     trial_id = str(uuid.uuid4())\n",
    "    trial_id = f\"demo/dataset={params['dataset']}/seed={params['seed']}_epoch={params['epochs_per_task']}_lr={params['learning_rate']}_tau={params['tau']}_alpha={params['alpha']}\"\n",
    "    if params['lambda'] != 0:\n",
    "        trial_id+=f\"_lmbd_{params['lambda']}_lmbdold_{params['lambda_old']}\"\n",
    "    params['trial_id'] = trial_id\n",
    "    params['output_dir'] = os.path.join(\"./outputs/{}\".format(trial_id))\n",
    "    print(f\"output_dir={params['output_dir']}\")\n",
    "    Path(params['output_dir']).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    return params\n",
    "\n",
    "params = make_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99826537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"MNIST\" in params['dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20c7b886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 2 5 6 3 1 0 7 4 9]\n"
     ]
    }
   ],
   "source": [
    "from datasets import BiasedMNIST\n",
    "\n",
    "if  params['dataset'] in [\"BiasedMNIST\"]:\n",
    "    benchmark = BiasedMNIST(num_tasks=params['num_tasks'],\n",
    "                                per_task_memory_examples=params['per_task_memory_examples'],\n",
    "                                per_task_examples = params['per_task_examples'],\n",
    "                                random_class_idx=True)\n",
    "    input_dim = (3, 28, 28)\n",
    "    class_idx = benchmark.class_idx\n",
    "    num_classes = len(class_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87fd9653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAAkklEQVR4nO2UwQqAMAxD5/C71e3DxYMwStnapMyDYm4OfCRduuVIR5qtPJ34Q9fwn/u5yc+SaxyqWOr8RnPxR0QlyGmXJfPSUGN2IznxwbxKllNJRAw2oRdFWSYq1biua8tpyZVK3eQ7bVx8Ah97UNi2+k4DG9VxavgCy0DMFK8XCp2/puwKdGYa2yKp95T/EegFDm4sUZ7Zvy4AAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.transforms.functional import to_pil_image\n",
    "from cl_gym.benchmarks.transforms import MNIST_MEAN, MNIST_STD\n",
    "COLOR_MAP = {\n",
    "    0: (1, 0, 0),\n",
    "    1: (0, 1, 0),\n",
    "    2: (1, 1, 0),\n",
    "    3: (0, 0, 1),\n",
    "    4: (1, 0.65, 0),\n",
    "    5: (0.5, 0, 0.5),\n",
    "    6: (0, 1, 1),\n",
    "    7: (1, 0.75, 0.8),\n",
    "    8: (0.8, 1, 0),\n",
    "    9: (.588, .294, 0.)\n",
    "}\n",
    "\n",
    "r = (1 - 0.1913)\n",
    "color_values = np.array(list(COLOR_MAP.values()))\n",
    "m_rgb = color_values.mean(axis=0)\n",
    "std_rgb = color_values.std(axis=0)\n",
    "\n",
    "bmnist_mean = [r*m + MNIST_MEAN[0] for m in m_rgb]\n",
    "bmnist_std = [(r*s**2+(1-r)*MNIST_STD[0]**2+r*(1-r)*(bmnist_mean[i] - m_rgb[i])**2)**0.5 for i, s in enumerate(std_rgb)]\n",
    "\n",
    "unnormalize = torchvision.transforms.Normalize([-m/s for m, s in zip(bmnist_mean, bmnist_std)], [1/s for s in bmnist_std])\n",
    "sample_idx = 95\n",
    "to_pil_image(unnormalize(benchmark.trains[2][sample_idx][0]), mode=\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8806699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARgAAAAcCAIAAAA1Cjd5AAADpUlEQVR4nO1b25HkIAzErsto7r43jQlx05gAnBJzH9S6MAgQUguzNXT5Y2tsCxnR6IF2c947NN6vAy7z+PoHl2mBh4XQbwOZT7xIvNWd+2sg820gczeQubDwcVhEWlgAYBFpYQGAP3cO/pUlFIrk6uGKyd4h3S9KMkUC67moekd7FuR/iyWXFJYIJGdSbBczcOoFtM4sIpHJ2cZ5k0TOHzUqLLKQ+XAevQi8nEslCqlQkdmnqvU0vin5G36nix8jhLfHA5c46iwSccyCRScOt8eXVAxHQ9FXNFlkQjMumqbR2O7tPMkiV2AXDoRweWj37nVKBo6ogrDoNXaq08bAKZnh6RUBnot2W9XqPKcrMYpgJjk8eTsv8ksB5Iv++vflmb6RNk1ER+J1aPKiHInr0NPpU7FHV/xjH0iGKDcgY2/jyp9ZU7vhkc64DsyfEtAnuXYU6lwN+89+Fr9loFvwPLeGcwlKXBqwu3U6pV1jkYFVu9dBR3fQkC+YR2knGxvbxIGqmK0XyGmJbQSJkwNndP5KrkP3m6raQ+5wECzKbZAwYcpkJrf3hEqOg2bz2tyuSIf4qGlYGz7nTPyLMNirBG+KuA5LlWaNTj2cZVSTx3VgrwWTJpvGhDNDKJQjHfQOJQxaWl3ZKppFryt5dwE0iiGLJsq7YhcUiuDnZTOgv34+MaXcHAl8mpTnS2p2jTyT1cX0ZkHdTDWGGPk0Tl+4i5GMRWte+x7DSl2eGumSpQEsArkmsxVAskjVH5RcAd0CSdM8nA+XtcNXuykWi2o3mpD7KPuT2dg8EI4FgTapEWIlIX2Rb/UH1R/og8A6AmJIAz8uixr3XOaUAAeyFRZBCabkUvyK5a6ZHCvlHoCBCouevpNj/Ie7tZ2ydspHQ3nVORKgSyikRjYUgpz64ZxbJTWSip01KSIRB3LT95p0+CLuEwGkL8InUWP78UoohfXocRRhUrerYepTwn698rssnHM4t3dKCnQsVbktQrYoNT2IAF/x8KITAzj5gPK3nDnOoBtoc3sz24mL42zBvR36l0noC+0AB7IJ5nBBCZLulfyu2ciz7dN4fQYEdfERre64tqMxcuw5EtTzxKhve3MHEidu90JWs8RxSigbQf+lrx7rXiAsNgxqBkdAZiHS9jaEvJ0/I4Dd6TjRnRlE/2q+Ub5IxSKb/iBnsMrRAqHSJuZMCdj5jHu91e12AMXaHukXOZ+FT8NNHasEZtFjYeFXYxFpYQGA/xe5Q9PxOrdyAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=280x28>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_label = 0\n",
    "incremental_step = 1\n",
    "# cat_img = torch.cat([img for img in benchmark.trains[incremental_step].inputs[benchmark.trains[incremental_step].targets == target_label][20:30]], dim=2)\n",
    "cat_img = torch.cat([img for img, target, *_ in benchmark.tests[incremental_step]][20:30], dim=2)\n",
    "to_pil_image(unnormalize(cat_img), mode=\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e73e1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainers import FairContinualTrainer\n",
    "from trainers.fair_trainer import FairContinualTrainer2\n",
    "from metrics import FairMetricCollector\n",
    "from algorithms import Heuristic3\n",
    "from algorithms.fairl import FaIRL\n",
    "from backbones import MLP2Layers2, ResNet18Small2\n",
    "\n",
    "# backbone = MLP2Layers2(input_dim=n_feature, hidden_dim_1=256, hidden_dim_2=256, output_dim=10)\n",
    "backbone = ResNet18Small2(\n",
    "        input_dim=input_dim, \n",
    "        output_dim=num_classes,\n",
    "        class_idx=class_idx,\n",
    "        config=params\n",
    "    ).to(params['device'])\n",
    "algorithm = Heuristic3(backbone, benchmark, params, requires_memory=True)\n",
    "metric_manager_callback = FairMetricCollector(num_tasks=params['num_tasks'],\n",
    "                                                        eval_interval='epoch',\n",
    "                                                        epochs_per_task=params['epochs_per_task'])\n",
    "\n",
    "trainer = FairContinualTrainer2(algorithm, params, callbacks=[metric_manager_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b8e3d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function mean at 0x7f0adb427c70>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if params['fairness_agg'] == \"mean\":\n",
    "    agg = np.mean\n",
    "elif params['fairness_agg'] == \"max\":\n",
    "    agg = np.max\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "metric_manager_callback.meters['fairness'].agg = agg\n",
    "metric_manager_callback.meters['fairness'].agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2eac756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Task 1 -----------------------\n",
      "[1] Eval metrics for task 1 >> {'accuracy': 77.34269296276841, 'loss': 0.0023766214386416098, 'fairness': [0.3360995850622407, 0.5595463137996219], 'accuracy_s0': 100.0, 'accuracy_s1': 55.217705056906865, 'classwise_accuracy': {8: array([812, 974]), 2: array([ 736, 1032])}}\n",
      "training_task_end\n",
      "---------------------------- Task 2 -----------------------\n",
      "[2] Eval metrics for task 1 >> {'accuracy': 92.77862009136781, 'loss': 0.0014892295820049845, 'fairness': [0.13697162905239002, 0.13780079447699434], 'accuracy_s0': 99.69956682668217, 'accuracy_s1': 85.96094565021296, 'classwise_accuracy': {8: array([906, 974]), 2: array([ 955, 1032])}}\n",
      "[2] Eval metrics for task 2 >> {'accuracy': 66.88226125055, 'loss': 0.005384430240940403, 'fairness': [0.8009084885261909, 0.5261871772263509], 'accuracy_s0': 99.14765467346956, 'accuracy_s1': 32.79287138584247, 'classwise_accuracy': {6: array([578, 958]), 5: array([655, 892])}}\n",
      "training_task_end\n",
      "---------------------------- Task 3 -----------------------\n",
      "[3] Eval metrics for task 1 >> {'accuracy': 74.5838506597902, 'loss': 0.003994689387077111, 'fairness': [0.13043551597341696, 0.15964327456809235], 'accuracy_s0': 81.90289159352827, 'accuracy_s1': 67.3989520664528, 'classwise_accuracy': {8: array([729, 974]), 2: array([ 767, 1032])}}\n",
      "[3] Eval metrics for task 2 >> {'accuracy': 83.17168615482554, 'loss': 0.0026060464575483992, 'fairness': [0.19644102671409636, 0.30990301045471724], 'accuracy_s0': 95.39372229712463, 'accuracy_s1': 70.07652043868396, 'classwise_accuracy': {6: array([816, 958]), 5: array([724, 892])}}\n",
      "[3] Eval metrics for task 3 >> {'accuracy': 92.95503118593797, 'loss': 0.0009683487784890306, 'fairness': [0.12598425196850394, 0.11963896669779017], 'accuracy_s0': 99.25925925925925, 'accuracy_s1': 86.97809832594456, 'classwise_accuracy': {3: array([ 946, 1010]), 1: array([1047, 1135])}}\n",
      "training_task_end\n",
      "---------------------------- Task 4 -----------------------\n",
      "[4] Eval metrics for task 1 >> {'accuracy': 70.21870970822788, 'loss': 0.004909770676526329, 'fairness': [0.12496664624728004, 0.16849677832877907], 'accuracy_s0': 77.59075627535599, 'accuracy_s1': 62.917585046553036, 'classwise_accuracy': {2: array([ 732, 1032]), 8: array([677, 974])}}\n",
      "[4] Eval metrics for task 2 >> {'accuracy': 69.84199612421243, 'loss': 0.005116478623570623, 'fairness': [0.4963698198765587, 0.3274482109227872], 'accuracy_s0': 89.7335236735665, 'accuracy_s1': 48.5426221335992, 'classwise_accuracy': {5: array([597, 892]), 6: array([697, 958])}}\n",
      "[4] Eval metrics for task 3 >> {'accuracy': 91.29955947136563, 'loss': 0.0012208942002627677, 'fairness': [0.13545032468551, 0.0987861811391223], 'accuracy_s0': 97.29526339088093, 'accuracy_s1': 85.5834380996493, 'classwise_accuracy': {3: array([ 909, 1010]), 1: array([1051, 1135])}}\n",
      "[4] Eval metrics for task 4 >> {'accuracy': 93.17120622568093, 'loss': 0.0009326884574980375, 'fairness': [0.16421248128565202, 0.09245244511456074], 'accuracy_s0': 99.42192572183173, 'accuracy_s1': 86.58867940182108, 'classwise_accuracy': {7: array([ 939, 1028]), 0: array([931, 980])}}\n",
      "training_task_end\n",
      "---------------------------- Task 5 -----------------------\n",
      "[5] Eval metrics for task 1 >> {'accuracy': 65.84551040224122, 'loss': 0.006084821457164, 'fairness': [0.17340518840873054, 0.16906500505473776], 'accuracy_s0': 74.46924146179832, 'accuracy_s1': 57.345731788624896, 'classwise_accuracy': {8: array([639, 974]), 2: array([ 682, 1032])}}\n",
      "[5] Eval metrics for task 2 >> {'accuracy': 67.90913431382646, 'loss': 0.006231646473343308, 'fairness': [0.22909255771779313, 0.46250661292354206], 'accuracy_s0': 84.57098545130903, 'accuracy_s1': 49.99102691924227, 'classwise_accuracy': {6: array([704, 958]), 5: array([556, 892])}}\n",
      "[5] Eval metrics for task 3 >> {'accuracy': 83.65638766519824, 'loss': 0.002547377320158454, 'fairness': [0.1748988484282602, 0.19168993318066319], 'accuracy_s0': 93.06145787221485, 'accuracy_s1': 74.73201879176867, 'classwise_accuracy': {1: array([ 991, 1135]), 3: array([ 808, 1010])}}\n",
      "[5] Eval metrics for task 4 >> {'accuracy': 92.34773286746605, 'loss': 0.0010488092661853805, 'fairness': [0.1028943192372892, 0.15815187522504592], 'accuracy_s0': 98.71198657375871, 'accuracy_s1': 85.65967685064196, 'classwise_accuracy': {0: array([912, 980]), 7: array([ 942, 1028])}}\n",
      "[5] Eval metrics for task 5 >> {'accuracy': 90.24431844559857, 'loss': 0.001254766206535366, 'fairness': [0.13737373737373737, 0.2521144396144396], 'accuracy_s0': 99.71590909090908, 'accuracy_s1': 80.24150024150025, 'classwise_accuracy': {4: array([914, 982]), 9: array([ 882, 1009])}}\n",
      "training_task_end\n",
      "final avg-acc 80.0006167388661\n",
      "final avg-forget 13.079444602270073\n"
     ]
    }
   ],
   "source": [
    "trainer.run()\n",
    "print(\"final avg-acc\", metric_manager_callback.meters['accuracy'].compute_final())\n",
    "print(\"final avg-forget\", metric_manager_callback.meters['forgetting'].compute_final())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ebde5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[77.343,  0.   ,  0.   ,  0.   ,  0.   ],\n",
       "       [92.779, 66.882,  0.   ,  0.   ,  0.   ],\n",
       "       [74.584, 83.172, 92.955,  0.   ,  0.   ],\n",
       "       [70.219, 69.842, 91.3  , 93.171,  0.   ],\n",
       "       [65.846, 67.909, 83.656, 92.348, 90.244]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_manager_callback.meters['accuracy'].get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e893eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.3753615176966"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(metric_manager_callback.meters['accuracy'].compute_overall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b82bd073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.448, 0.4, 0.174, 0.201, 0.205]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.round(x, 3) for x in metric_manager_callback.meters['fairness'].compute_overall()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a7973e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28562128509612755"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(metric_manager_callback.meters['fairness'].compute_overall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61271a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_id=2\n",
      "sensitive samples / all samples = 595 / 11339\n",
      "sensitive samples / selected samples = 530 / 10000\n"
     ]
    }
   ],
   "source": [
    "task_id = 2\n",
    "\n",
    "print(f\"{task_id=}\")\n",
    "print(f\"sensitive samples / all samples = {(benchmark.trains[task_id].sensitives != benchmark.trains[task_id].targets).sum().item()} / {benchmark.trains[task_id].sensitives.shape[0]}\")\n",
    "\n",
    "updated_seq_indices = benchmark.seq_indices_train[task_id]\n",
    "print(f\"sensitive samples / selected samples = {(benchmark.trains[task_id].sensitives[updated_seq_indices] != benchmark.trains[task_id].targets[updated_seq_indices]).sum().item()} / {len(updated_seq_indices)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b32febda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incremental_step=2\n",
      "2 : 0 --> 0\n",
      "3 : 0 --> 0\n",
      "incremental_step=3\n",
      "4 : 0 --> 0\n",
      "5 : 0 --> 0\n",
      "incremental_step=4\n",
      "6 : 0 --> 0\n",
      "7 : 6265 --> 6265\n",
      "incremental_step=5\n",
      "8 : 0 --> 0\n",
      "9 : 5949 --> 5949\n"
     ]
    }
   ],
   "source": [
    "step_class = 2\n",
    "for i in range(2, 6):\n",
    "    incremental_step = i\n",
    "    print(f\"{incremental_step=}\")\n",
    "    one_idx = benchmark.trains[incremental_step].sample_weight > 0.9\n",
    "\n",
    "    print(f\"{2*i-2} : {(benchmark.trains[incremental_step].targets == (2*i-2)).sum().item()} --> {(benchmark.trains[incremental_step].targets[one_idx] == (2*i-2)).sum().item()}\")\n",
    "    print(f\"{2*i-1} : {(benchmark.trains[incremental_step].targets == (2*i-1)).sum().item()} --> {(benchmark.trains[incremental_step].targets[one_idx] == (2*i-1)).sum().item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0880e76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.336 0.56 \n",
      "0.137 0.138 0.801 0.526 \n",
      "0.13 0.16 0.196 0.31 0.126 0.12 \n",
      "0.125 0.168 0.496 0.327 0.135 0.099 0.164 0.092 \n",
      "0.173 0.169 0.229 0.463 0.175 0.192 0.103 0.158 0.137 0.252 \n"
     ]
    }
   ],
   "source": [
    "for eos in metric_manager_callback.meters['fairness'].get_data():\n",
    "    for eo in eos:\n",
    "        print(round(eo, 3),end=\" \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6233f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{8: array([812, 974]), 2: array([ 736, 1032])},\n",
       " {8: array([906, 974]),\n",
       "  2: array([ 955, 1032]),\n",
       "  6: array([578, 958]),\n",
       "  5: array([655, 892])},\n",
       " {8: array([729, 974]),\n",
       "  2: array([ 767, 1032]),\n",
       "  6: array([816, 958]),\n",
       "  5: array([724, 892]),\n",
       "  3: array([ 946, 1010]),\n",
       "  1: array([1047, 1135])},\n",
       " {2: array([ 732, 1032]),\n",
       "  8: array([677, 974]),\n",
       "  5: array([597, 892]),\n",
       "  6: array([697, 958]),\n",
       "  3: array([ 909, 1010]),\n",
       "  1: array([1051, 1135]),\n",
       "  7: array([ 939, 1028]),\n",
       "  0: array([931, 980])},\n",
       " {8: array([639, 974]),\n",
       "  2: array([ 682, 1032]),\n",
       "  6: array([704, 958]),\n",
       "  5: array([556, 892]),\n",
       "  1: array([ 991, 1135]),\n",
       "  3: array([ 808, 1010]),\n",
       "  0: array([912, 980]),\n",
       "  7: array([ 942, 1028]),\n",
       "  4: array([914, 982]),\n",
       "  9: array([ 882, 1009])}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_manager_callback.meters['classwise_accuracy'].get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21212733",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
