{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0c3b92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_dir=./outputs/demo/dataset=BiasedMNIST/seed=10_epoch=3_lr=0.001_tau=5_alpha=0.001_lmbd_1.0_lmbdold_0.0\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST, FashionMNIST, CIFAR10\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import cl_gym as cl\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "seed = 10\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.enabled = False\n",
    "\n",
    "def make_params() -> dict:\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    import uuid\n",
    "\n",
    "    params = {\n",
    "            # dataset\n",
    "            'dataset': \"BiasedMNIST\",\n",
    "            'fairness_agg': 'mean',\n",
    "            'model': 'resnet18',\n",
    "\n",
    "            # benchmark\n",
    "            'seed': seed,\n",
    "            'num_tasks': 5,\n",
    "            'epochs_per_task': 3,\n",
    "            # 'per_task_examples': np.inf,\n",
    "            'per_task_examples': 10000,\n",
    "            'per_task_memory_examples': 128,\n",
    "            'batch_size_train': 64,\n",
    "            'batch_size_memory': 64,\n",
    "            'batch_size_validation': 256,\n",
    "            'tau': 5,\n",
    "\n",
    "            # algorithm\n",
    "            'optimizer': 'sgd',\n",
    "            'learning_rate': 0.001,\n",
    "            'momentum': 0.9,\n",
    "            'learning_rate_decay': 1.0,\n",
    "            # 'criterion': torch.nn.CrossEntropyLoss(),\n",
    "            'criterion': torch.nn.BCEWithLogitsLoss(),\n",
    "\n",
    "            'device': torch.device('cuda:5' if torch.cuda.is_available() else 'cpu'),\n",
    "             \n",
    "            # sample selection\n",
    "            'alpha': 0.001,\n",
    "            'lambda': 1.0,\n",
    "            'lambda_old': 0.0,\n",
    "              }\n",
    "    \n",
    "\n",
    "#     trial_id = str(uuid.uuid4())\n",
    "    trial_id = f\"demo/dataset={params['dataset']}/seed={params['seed']}_epoch={params['epochs_per_task']}_lr={params['learning_rate']}_tau={params['tau']}_alpha={params['alpha']}\"\n",
    "    if params['lambda'] != 0:\n",
    "        trial_id+=f\"_lmbd_{params['lambda']}_lmbdold_{params['lambda_old']}\"\n",
    "    params['trial_id'] = trial_id\n",
    "    params['output_dir'] = os.path.join(\"./outputs/{}\".format(trial_id))\n",
    "    print(f\"output_dir={params['output_dir']}\")\n",
    "    Path(params['output_dir']).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    return params\n",
    "\n",
    "params = make_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99826537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"MNIST\" in params['dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20c7b886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 2 5 6 3 1 0 7 4 9]\n"
     ]
    }
   ],
   "source": [
    "from datasets import BiasedMNIST\n",
    "\n",
    "if  params['dataset'] in [\"BiasedMNIST\"]:\n",
    "    benchmark = BiasedMNIST(num_tasks=params['num_tasks'],\n",
    "                                per_task_memory_examples=params['per_task_memory_examples'],\n",
    "                                per_task_examples = params['per_task_examples'],\n",
    "                                random_class_idx=True)\n",
    "    input_dim = (3, 28, 28)\n",
    "    class_idx = benchmark.class_idx\n",
    "    num_classes = len(class_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87fd9653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAAkklEQVR4nO2UwQqAMAxD5/C71e3DxYMwStnapMyDYm4OfCRduuVIR5qtPJ34Q9fwn/u5yc+SaxyqWOr8RnPxR0QlyGmXJfPSUGN2IznxwbxKllNJRAw2oRdFWSYq1biua8tpyZVK3eQ7bVx8Ah97UNi2+k4DG9VxavgCy0DMFK8XCp2/puwKdGYa2yKp95T/EegFDm4sUZ7Zvy4AAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.transforms.functional import to_pil_image\n",
    "from cl_gym.benchmarks.transforms import MNIST_MEAN, MNIST_STD\n",
    "COLOR_MAP = {\n",
    "    0: (1, 0, 0),\n",
    "    1: (0, 1, 0),\n",
    "    2: (1, 1, 0),\n",
    "    3: (0, 0, 1),\n",
    "    4: (1, 0.65, 0),\n",
    "    5: (0.5, 0, 0.5),\n",
    "    6: (0, 1, 1),\n",
    "    7: (1, 0.75, 0.8),\n",
    "    8: (0.8, 1, 0),\n",
    "    9: (.588, .294, 0.)\n",
    "}\n",
    "\n",
    "r = (1 - 0.1913)\n",
    "color_values = np.array(list(COLOR_MAP.values()))\n",
    "m_rgb = color_values.mean(axis=0)\n",
    "std_rgb = color_values.std(axis=0)\n",
    "\n",
    "bmnist_mean = [r*m + MNIST_MEAN[0] for m in m_rgb]\n",
    "bmnist_std = [(r*s**2+(1-r)*MNIST_STD[0]**2+r*(1-r)*(bmnist_mean[i] - m_rgb[i])**2)**0.5 for i, s in enumerate(std_rgb)]\n",
    "\n",
    "unnormalize = torchvision.transforms.Normalize([-m/s for m, s in zip(bmnist_mean, bmnist_std)], [1/s for s in bmnist_std])\n",
    "sample_idx = 95\n",
    "to_pil_image(unnormalize(benchmark.trains[2][sample_idx][0]), mode=\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8806699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARgAAAAcCAIAAAA1Cjd5AAADpUlEQVR4nO1b25HkIAzErsto7r43jQlx05gAnBJzH9S6MAgQUguzNXT5Y2tsCxnR6IF2c947NN6vAy7z+PoHl2mBh4XQbwOZT7xIvNWd+2sg820gczeQubDwcVhEWlgAYBFpYQGAP3cO/pUlFIrk6uGKyd4h3S9KMkUC67moekd7FuR/iyWXFJYIJGdSbBczcOoFtM4sIpHJ2cZ5k0TOHzUqLLKQ+XAevQi8nEslCqlQkdmnqvU0vin5G36nix8jhLfHA5c46iwSccyCRScOt8eXVAxHQ9FXNFlkQjMumqbR2O7tPMkiV2AXDoRweWj37nVKBo6ogrDoNXaq08bAKZnh6RUBnot2W9XqPKcrMYpgJjk8eTsv8ksB5Iv++vflmb6RNk1ER+J1aPKiHInr0NPpU7FHV/xjH0iGKDcgY2/jyp9ZU7vhkc64DsyfEtAnuXYU6lwN+89+Fr9loFvwPLeGcwlKXBqwu3U6pV1jkYFVu9dBR3fQkC+YR2knGxvbxIGqmK0XyGmJbQSJkwNndP5KrkP3m6raQ+5wECzKbZAwYcpkJrf3hEqOg2bz2tyuSIf4qGlYGz7nTPyLMNirBG+KuA5LlWaNTj2cZVSTx3VgrwWTJpvGhDNDKJQjHfQOJQxaWl3ZKppFryt5dwE0iiGLJsq7YhcUiuDnZTOgv34+MaXcHAl8mpTnS2p2jTyT1cX0ZkHdTDWGGPk0Tl+4i5GMRWte+x7DSl2eGumSpQEsArkmsxVAskjVH5RcAd0CSdM8nA+XtcNXuykWi2o3mpD7KPuT2dg8EI4FgTapEWIlIX2Rb/UH1R/og8A6AmJIAz8uixr3XOaUAAeyFRZBCabkUvyK5a6ZHCvlHoCBCouevpNj/Ie7tZ2ydspHQ3nVORKgSyikRjYUgpz64ZxbJTWSip01KSIRB3LT95p0+CLuEwGkL8InUWP78UoohfXocRRhUrerYepTwn698rssnHM4t3dKCnQsVbktQrYoNT2IAF/x8KITAzj5gPK3nDnOoBtoc3sz24mL42zBvR36l0noC+0AB7IJ5nBBCZLulfyu2ciz7dN4fQYEdfERre64tqMxcuw5EtTzxKhve3MHEidu90JWs8RxSigbQf+lrx7rXiAsNgxqBkdAZiHS9jaEvJ0/I4Dd6TjRnRlE/2q+Ub5IxSKb/iBnsMrRAqHSJuZMCdj5jHu91e12AMXaHukXOZ+FT8NNHasEZtFjYeFXYxFpYQGA/xe5Q9PxOrdyAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=280x28>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_label = 0\n",
    "incremental_step = 1\n",
    "# cat_img = torch.cat([img for img in benchmark.trains[incremental_step].inputs[benchmark.trains[incremental_step].targets == target_label][20:30]], dim=2)\n",
    "cat_img = torch.cat([img for img, target, *_ in benchmark.tests[incremental_step]][20:30], dim=2)\n",
    "to_pil_image(unnormalize(cat_img), mode=\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e73e1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainers import FairContinualTrainer\n",
    "from trainers.fair_trainer import FairContinualTrainer2\n",
    "from metrics import FairMetricCollector\n",
    "from metrics import MetricCollector2\n",
    "\n",
    "from algorithms import Heuristic3\n",
    "from algorithms.fairl import FaIRL\n",
    "from algorithms.icarl import iCaRL\n",
    "from backbones import MLP2Layers2, ResNet18Small2\n",
    "\n",
    "backbone = MLP2Layers2(\n",
    "    input_dim=input_dim, \n",
    "    hidden_dim_1=256, \n",
    "    hidden_dim_2=256, \n",
    "    output_dim=num_classes,\n",
    "    class_idx=class_idx,\n",
    "    config=params\n",
    "    ).to(params['device'])\n",
    "# backbone = ResNet18Small2(\n",
    "#         input_dim=input_dim, \n",
    "#         output_dim=num_classes,\n",
    "#         class_idx=class_idx,\n",
    "#         config=params\n",
    "#     ).to(params['device'])\n",
    "algorithm = iCaRL(backbone, benchmark, params, requires_memory=True)\n",
    "metric_manager_callback = FairMetricCollector(num_tasks=params['num_tasks'],\n",
    "                                                        eval_interval='epoch',\n",
    "                                                        epochs_per_task=params['epochs_per_task'])\n",
    "# metric_manager_callback = MetricCollector2(num_tasks=params['num_tasks'],\n",
    "#                                                         eval_interval='epoch',\n",
    "#                                                         epochs_per_task=params['epochs_per_task'])\n",
    "from trainers.baselines import BaseMemoryContinualTrainer as ContinualTrainer\n",
    "\n",
    "# trainer = ContinualTrainer(algorithm, params, callbacks=[metric_manager_callback])\n",
    "\n",
    "trainer = FairContinualTrainer2(algorithm, params, callbacks=[metric_manager_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b8e3d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "if params['fairness_agg'] == \"mean\":\n",
    "    agg = np.mean\n",
    "elif params['fairness_agg'] == \"max\":\n",
    "    agg = np.max\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "fairness_metrics = [\"std\", \"EER\", \"EO\", \"DP\"]\n",
    "for metric in metric_manager_callback.meters:\n",
    "    if metric in fairness_metrics:\n",
    "        metric_manager_callback.meters[metric].agg = agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbbb73ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Task 1 -----------------------\n",
      "[1] Eval metrics for task 1 >> {'accuracy': 0.8008870159018193, 'loss': 0.0, 'EO': [0.37594035691394256, 0.34714210014017977], 'DP': None, 'accuracy_s0': 0.9828791478769658, 'accuracy_s1': 0.6213379193499047, 'classwise_accuracy': {8: array([773, 974]), 2: array([ 834, 1032])}}\n",
      "[2] Eval metrics for task 1 >> {'accuracy': 0.7882373891727552, 'loss': 0.0, 'EO': [0.5478443477380832, 0.2738089421880814], 'DP': None, 'accuracy_s0': 0.9939691121563303, 'accuracy_s1': 0.583142467193248, 'classwise_accuracy': {8: array([704, 974]), 2: array([ 881, 1032])}}\n",
      "[3] Eval metrics for task 1 >> {'accuracy': 0.800701972207631, 'loss': 0.0, 'EO': [0.49178558175623255, 0.28713916876810963], 'DP': None, 'accuracy_s0': 0.9959794081042201, 'accuracy_s1': 0.606517032842049, 'classwise_accuracy': {8: array([733, 974]), 2: array([ 876, 1032])}}\n",
      "training_task_end\n",
      "Reduce size of class 8 to 0 examplar\n",
      "Reduce size of class 2 to 0 examplar\n",
      "Reduce size of class 5 to 0 examplar\n",
      "Reduce size of class 6 to 0 examplar\n",
      "Reduce size of class 3 to 0 examplar\n",
      "Reduce size of class 1 to 0 examplar\n",
      "Reduce size of class 0 to 0 examplar\n",
      "Reduce size of class 7 to 0 examplar\n",
      "Reduce size of class 4 to 0 examplar\n",
      "Reduce size of class 9 to 0 examplar\n",
      "construct class 8 examplar:\n",
      "len(self.exemplar_dict[cls])=320\n",
      "construct class 2 examplar:\n",
      "len(self.exemplar_dict[cls])=320\n",
      "update_memory_after_train\n",
      "---------------------------- Task 2 -----------------------\n",
      "[4] Eval metrics for task 1 >> {'accuracy': 0.6847273291628861, 'loss': 0.0, 'EO': [0.7137772830010458, 0.5253244239665973], 'DP': None, 'accuracy_s0': 0.9959794081042201, 'accuracy_s1': 0.3764285546203986, 'classwise_accuracy': {8: array([626, 974]), 2: array([ 750, 1032])}}\n",
      "[4] Eval metrics for task 2 >> {'accuracy': 0.579770776187311, 'loss': 0.0, 'EO': [0.7364705882352941, 0.9936440677966102], 'DP': None, 'accuracy_s0': 1.0, 'accuracy_s1': 0.13494267198404786, 'classwise_accuracy': {5: array([579, 892]), 6: array([489, 958])}}\n",
      "[5] Eval metrics for task 1 >> {'accuracy': 0.6686812552727504, 'loss': 0.0, 'EO': [0.7179266605944068, 0.5839255581820983], 'DP': None, 'accuracy_s0': 0.9959794081042201, 'accuracy_s1': 0.3450532987159677, 'classwise_accuracy': {8: array([624, 974]), 2: array([ 719, 1032])}}\n",
      "[5] Eval metrics for task 2 >> {'accuracy': 0.5940744450789668, 'loss': 0.0, 'EO': [0.978813559322034, 0.691764705882353], 'DP': None, 'accuracy_s0': 1.0, 'accuracy_s1': 0.16471086739780658, 'classwise_accuracy': {6: array([496, 958]), 5: array([598, 892])}}\n",
      "[6] Eval metrics for task 1 >> {'accuracy': 0.6657742785285643, 'loss': 0.0, 'EO': [0.59526771319155, 0.7179266605944068], 'DP': None, 'accuracy_s0': 0.9959794081042201, 'accuracy_s1': 0.33938222121124173, 'classwise_accuracy': {2: array([ 713, 1032]), 8: array([624, 974])}}\n",
      "[6] Eval metrics for task 2 >> {'accuracy': 0.5984428976661018, 'loss': 0.0, 'EO': [0.6799999999999999, 0.972457627118644], 'DP': None, 'accuracy_s0': 1.0, 'accuracy_s1': 0.17377118644067796, 'classwise_accuracy': {5: array([603, 892]), 6: array([499, 958])}}\n",
      "training_task_end\n",
      "Reduce size of class 8 to 160 examplar\n",
      "Reduce size of class 2 to 160 examplar\n",
      "Reduce size of class 5 to 0 examplar\n",
      "Reduce size of class 6 to 0 examplar\n",
      "Reduce size of class 3 to 0 examplar\n",
      "Reduce size of class 1 to 0 examplar\n",
      "Reduce size of class 0 to 0 examplar\n",
      "Reduce size of class 7 to 0 examplar\n",
      "Reduce size of class 4 to 0 examplar\n",
      "Reduce size of class 9 to 0 examplar\n",
      "construct class 5 examplar:\n",
      "len(self.exemplar_dict[cls])=160\n",
      "construct class 6 examplar:\n",
      "len(self.exemplar_dict[cls])=160\n",
      "update_memory_after_train\n",
      "---------------------------- Task 3 -----------------------\n",
      "[7] Eval metrics for task 1 >> {'accuracy': 0.6148723397481815, 'loss': 0.0, 'EO': [0.6313799621928167, 0.8983824174341328], 'DP': None, 'accuracy_s0': 0.9989837398373984, 'accuracy_s1': 0.23410255002392363, 'classwise_accuracy': {2: array([ 698, 1032]), 8: array([539, 974])}}\n",
      "[7] Eval metrics for task 2 >> {'accuracy': 0.5737207092504002, 'loss': 0.0, 'EO': [0.7552941176470588, 1.0], 'DP': None, 'accuracy_s0': 1.0, 'accuracy_s1': 0.1223529411764706, 'classwise_accuracy': {5: array([571, 892]), 6: array([486, 958])}}\n",
      "[7] Eval metrics for task 3 >> {'accuracy': 0.48640031404021455, 'loss': 0.0, 'EO': [1.0, 1.0], 'DP': None, 'accuracy_s0': 1.0, 'accuracy_s1': 0.0, 'classwise_accuracy': {1: array([ 540, 1135]), 3: array([ 502, 1010])}}\n",
      "[8] Eval metrics for task 1 >> {'accuracy': 0.600360337774382, 'loss': 0.0, 'EO': [0.6559546313799622, 0.9315774381810208], 'DP': None, 'accuracy_s0': 0.9989837398373984, 'accuracy_s1': 0.20521770505690687, 'classwise_accuracy': {2: array([ 685, 1032]), 8: array([523, 974])}}\n",
      "[8] Eval metrics for task 2 >> {'accuracy': 0.5737207092504002, 'loss': 0.0, 'EO': [1.0, 0.7552941176470588], 'DP': None, 'accuracy_s0': 1.0, 'accuracy_s1': 0.1223529411764706, 'classwise_accuracy': {6: array([486, 958]), 5: array([571, 892])}}\n",
      "[8] Eval metrics for task 3 >> {'accuracy': 0.48640031404021455, 'loss': 0.0, 'EO': [1.0, 1.0], 'DP': None, 'accuracy_s0': 1.0, 'accuracy_s1': 0.0, 'classwise_accuracy': {1: array([ 540, 1135]), 3: array([ 502, 1010])}}\n",
      "[9] Eval metrics for task 1 >> {'accuracy': 0.5983358005825892, 'loss': 0.0, 'EO': [0.6578449905482042, 0.9378015045710623], 'DP': None, 'accuracy_s0': 0.9989837398373984, 'accuracy_s1': 0.20116049227776514, 'classwise_accuracy': {2: array([ 684, 1032]), 8: array([520, 974])}}\n",
      "[9] Eval metrics for task 2 >> {'accuracy': 0.5737207092504002, 'loss': 0.0, 'EO': [1.0, 0.7552941176470588], 'DP': None, 'accuracy_s0': 1.0, 'accuracy_s1': 0.1223529411764706, 'classwise_accuracy': {6: array([486, 958]), 5: array([571, 892])}}\n",
      "[9] Eval metrics for task 3 >> {'accuracy': 0.48640031404021455, 'loss': 0.0, 'EO': [1.0, 1.0], 'DP': None, 'accuracy_s0': 1.0, 'accuracy_s1': 0.0, 'classwise_accuracy': {1: array([ 540, 1135]), 3: array([ 502, 1010])}}\n",
      "training_task_end\n",
      "Reduce size of class 8 to 106 examplar\n",
      "Reduce size of class 2 to 106 examplar\n",
      "Reduce size of class 5 to 106 examplar\n",
      "Reduce size of class 6 to 106 examplar\n",
      "Reduce size of class 3 to 0 examplar\n",
      "Reduce size of class 1 to 0 examplar\n",
      "Reduce size of class 0 to 0 examplar\n",
      "Reduce size of class 7 to 0 examplar\n",
      "Reduce size of class 4 to 0 examplar\n",
      "Reduce size of class 9 to 0 examplar\n",
      "construct class 3 examplar:\n",
      "len(self.exemplar_dict[cls])=106\n",
      "construct class 1 examplar:\n",
      "len(self.exemplar_dict[cls])=106\n",
      "update_memory_after_train\n",
      "---------------------------- Task 4 -----------------------\n",
      "[10] Eval metrics for task 1 >> {'accuracy': 0.5558672779077727, 'loss': 0.0, 'EO': [0.8015122873345936, 0.9606230813345478], 'DP': None, 'accuracy_s0': 0.9989837398373984, 'accuracy_s1': 0.1179160555028277, 'classwise_accuracy': {2: array([ 608, 1032]), 8: array([509, 974])}}\n",
      "[10] Eval metrics for task 2 >> {'accuracy': 0.5154247451248397, 'loss': 0.0, 'EO': [1.0, 1.0], 'DP': None, 'accuracy_s0': 1.0, 'accuracy_s1': 0.0, 'classwise_accuracy': {5: array([467, 892]), 6: array([486, 958])}}\n",
      "[10] Eval metrics for task 3 >> {'accuracy': 0.48640031404021455, 'loss': 0.0, 'EO': [1.0, 1.0], 'DP': None, 'accuracy_s0': 1.0, 'accuracy_s1': 0.0, 'classwise_accuracy': {1: array([ 540, 1135]), 3: array([ 502, 1010])}}\n",
      "[10] Eval metrics for task 4 >> {'accuracy': 0.5373024696259827, 'loss': 0.0, 'EO': [0.893223819301848, 1.0], 'DP': None, 'accuracy_s0': 1.0, 'accuracy_s1': 0.053388090349075976, 'classwise_accuracy': {0: array([545, 980]), 7: array([ 533, 1028])}}\n",
      "[11] Eval metrics for task 1 >> {'accuracy': 0.5553539308851854, 'loss': 0.0, 'EO': [0.966804979253112, 0.8015122873345936], 'DP': None, 'accuracy_s0': 1.0, 'accuracy_s1': 0.1158413667061472, 'classwise_accuracy': {8: array([508, 974]), 2: array([ 608, 1032])}}\n",
      "[11] Eval metrics for task 2 >> {'accuracy': 0.5154247451248397, 'loss': 0.0, 'EO': [1.0, 1.0], 'DP': None, 'accuracy_s0': 1.0, 'accuracy_s1': 0.0, 'classwise_accuracy': {5: array([467, 892]), 6: array([486, 958])}}\n",
      "[11] Eval metrics for task 3 >> {'accuracy': 0.48640031404021455, 'loss': 0.0, 'EO': [1.0, 1.0], 'DP': None, 'accuracy_s0': 1.0, 'accuracy_s1': 0.0, 'classwise_accuracy': {3: array([ 502, 1010]), 1: array([ 540, 1135])}}\n",
      "[11] Eval metrics for task 4 >> {'accuracy': 0.5373024696259827, 'loss': 0.0, 'EO': [0.893223819301848, 1.0], 'DP': None, 'accuracy_s0': 1.0, 'accuracy_s1': 0.053388090349075976, 'classwise_accuracy': {0: array([545, 980]), 7: array([ 533, 1028])}}\n",
      "[12] Eval metrics for task 1 >> {'accuracy': 0.5528737484679178, 'loss': 0.0, 'EO': [0.8071833648393194, 0.970954356846473], 'DP': None, 'accuracy_s0': 1.0, 'accuracy_s1': 0.11093113915710376, 'classwise_accuracy': {2: array([ 605, 1032]), 8: array([506, 974])}}\n",
      "[12] Eval metrics for task 2 >> {'accuracy': 0.5154247451248397, 'loss': 0.0, 'EO': [1.0, 1.0], 'DP': None, 'accuracy_s0': 1.0, 'accuracy_s1': 0.0, 'classwise_accuracy': {5: array([467, 892]), 6: array([486, 958])}}\n",
      "[12] Eval metrics for task 3 >> {'accuracy': 0.48640031404021455, 'loss': 0.0, 'EO': [1.0, 1.0], 'DP': None, 'accuracy_s0': 1.0, 'accuracy_s1': 0.0, 'classwise_accuracy': {1: array([ 540, 1135]), 3: array([ 502, 1010])}}\n",
      "[12] Eval metrics for task 4 >> {'accuracy': 0.5373024696259827, 'loss': 0.0, 'EO': [0.893223819301848, 1.0], 'DP': None, 'accuracy_s0': 1.0, 'accuracy_s1': 0.053388090349075976, 'classwise_accuracy': {0: array([545, 980]), 7: array([ 533, 1028])}}\n",
      "training_task_end\n",
      "Reduce size of class 8 to 80 examplar\n",
      "Reduce size of class 2 to 80 examplar\n",
      "Reduce size of class 5 to 80 examplar\n",
      "Reduce size of class 6 to 80 examplar\n",
      "Reduce size of class 3 to 80 examplar\n",
      "Reduce size of class 1 to 80 examplar\n",
      "Reduce size of class 0 to 0 examplar\n",
      "Reduce size of class 7 to 0 examplar\n",
      "Reduce size of class 4 to 0 examplar\n",
      "Reduce size of class 9 to 0 examplar\n",
      "construct class 0 examplar:\n",
      "len(self.exemplar_dict[cls])=80\n",
      "construct class 7 examplar:\n",
      "len(self.exemplar_dict[cls])=80\n",
      "update_memory_after_train\n",
      "---------------------------- Task 5 -----------------------\n",
      "[13] Eval metrics for task 1 >> {'accuracy': 0.5148810945036053, 'loss': 0.0, 'EO': [0.941398865784499, 0.9854771784232366], 'DP': None, 'accuracy_s0': 1.0, 'accuracy_s1': 0.03656197789613221, 'classwise_accuracy': {2: array([ 534, 1032]), 8: array([499, 974])}}\n",
      "[13] Eval metrics for task 2 >> {'accuracy': 0.5154247451248397, 'loss': 0.0, 'EO': [1.0, 1.0], 'DP': None, 'accuracy_s0': 1.0, 'accuracy_s1': 0.0, 'classwise_accuracy': {5: array([467, 892]), 6: array([486, 958])}}\n",
      "[13] Eval metrics for task 3 >> {'accuracy': 0.48640031404021455, 'loss': 0.0, 'EO': [1.0, 1.0], 'DP': None, 'accuracy_s0': 1.0, 'accuracy_s1': 0.0, 'classwise_accuracy': {3: array([ 502, 1010]), 1: array([ 540, 1135])}}\n",
      "[13] Eval metrics for task 4 >> {'accuracy': 0.5332208369729214, 'loss': 0.0, 'EO': [1.0, 0.9096509240246407], 'DP': None, 'accuracy_s0': 1.0, 'accuracy_s1': 0.045174537987679675, 'classwise_accuracy': {7: array([ 533, 1028]), 0: array([537, 980])}}\n",
      "[13] Eval metrics for task 5 >> {'accuracy': 0.5071308326890975, 'loss': 0.0, 'EO': [0.990530303030303, 1.0], 'DP': None, 'accuracy_s0': 0.9952651515151515, 'accuracy_s1': 0.0, 'classwise_accuracy': {9: array([ 523, 1009]), 4: array([487, 982])}}\n",
      "[14] Eval metrics for task 1 >> {'accuracy': 0.51049177848877, 'loss': 0.0, 'EO': [0.9875518672199171, 0.9565217391304348], 'DP': None, 'accuracy_s0': 1.0, 'accuracy_s1': 0.0279631968248241, 'classwise_accuracy': {8: array([498, 974]), 2: array([ 526, 1032])}}\n",
      "[14] Eval metrics for task 2 >> {'accuracy': 0.5154247451248397, 'loss': 0.0, 'EO': [1.0, 1.0], 'DP': None, 'accuracy_s0': 1.0, 'accuracy_s1': 0.0, 'classwise_accuracy': {5: array([467, 892]), 6: array([486, 958])}}\n",
      "[14] Eval metrics for task 3 >> {'accuracy': 0.48640031404021455, 'loss': 0.0, 'EO': [1.0, 1.0], 'DP': None, 'accuracy_s0': 1.0, 'accuracy_s1': 0.0, 'classwise_accuracy': {1: array([ 540, 1135]), 3: array([ 502, 1010])}}\n",
      "[14] Eval metrics for task 4 >> {'accuracy': 0.5342412451361869, 'loss': 0.0, 'EO': [0.9055441478439425, 1.0], 'DP': None, 'accuracy_s0': 1.0, 'accuracy_s1': 0.04722792607802875, 'classwise_accuracy': {0: array([539, 980]), 7: array([ 533, 1028])}}\n",
      "[14] Eval metrics for task 5 >> {'accuracy': 0.5086174531053512, 'loss': 0.0, 'EO': [0.9962121212121212, 1.0], 'DP': None, 'accuracy_s0': 0.9981060606060606, 'accuracy_s1': 0.0, 'classwise_accuracy': {9: array([ 526, 1009]), 4: array([487, 982])}}\n",
      "[15] Eval metrics for task 1 >> {'accuracy': 0.5089517374210082, 'loss': 0.0, 'EO': [0.9565217391304348, 0.9937759336099585], 'DP': None, 'accuracy_s0': 1.0, 'accuracy_s1': 0.024851163629803354, 'classwise_accuracy': {2: array([ 526, 1032]), 8: array([495, 974])}}\n",
      "[15] Eval metrics for task 2 >> {'accuracy': 0.5154247451248397, 'loss': 0.0, 'EO': [1.0, 1.0], 'DP': None, 'accuracy_s0': 1.0, 'accuracy_s1': 0.0, 'classwise_accuracy': {5: array([467, 892]), 6: array([486, 958])}}\n",
      "[15] Eval metrics for task 3 >> {'accuracy': 0.48640031404021455, 'loss': 0.0, 'EO': [1.0, 1.0], 'DP': None, 'accuracy_s0': 1.0, 'accuracy_s1': 0.0, 'classwise_accuracy': {1: array([ 540, 1135]), 3: array([ 502, 1010])}}\n",
      "[15] Eval metrics for task 4 >> {'accuracy': 0.5337310410545542, 'loss': 0.0, 'EO': [0.9075975359342916, 1.0], 'DP': None, 'accuracy_s0': 1.0, 'accuracy_s1': 0.04620123203285421, 'classwise_accuracy': {0: array([538, 980]), 7: array([ 533, 1028])}}\n",
      "[15] Eval metrics for task 5 >> {'accuracy': 0.5096085333828537, 'loss': 0.0, 'EO': [1.0, 1.0], 'DP': None, 'accuracy_s0': 1.0, 'accuracy_s1': 0.0, 'classwise_accuracy': {4: array([487, 982]), 9: array([ 528, 1009])}}\n",
      "training_task_end\n",
      "Reduce size of class 8 to 64 examplar\n",
      "Reduce size of class 2 to 64 examplar\n",
      "Reduce size of class 5 to 64 examplar\n",
      "Reduce size of class 6 to 64 examplar\n",
      "Reduce size of class 3 to 64 examplar\n",
      "Reduce size of class 1 to 64 examplar\n",
      "Reduce size of class 0 to 64 examplar\n",
      "Reduce size of class 7 to 64 examplar\n",
      "Reduce size of class 4 to 0 examplar\n",
      "Reduce size of class 9 to 0 examplar\n",
      "construct class 4 examplar:\n",
      "len(self.exemplar_dict[cls])=64\n",
      "construct class 9 examplar:\n",
      "len(self.exemplar_dict[cls])=64\n",
      "update_memory_after_train\n",
      "final avg-acc 0.5108232742046941\n",
      "final avg-forget 0.09458495397482836\n"
     ]
    }
   ],
   "source": [
    "trainer.run()\n",
    "print(\"final avg-acc\", metric_manager_callback.meters['accuracy'].compute_final())\n",
    "print(\"final avg-forget\", metric_manager_callback.meters['forgetting'].compute_final())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c23954c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebde5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_manager_callback.meters['accuracy'].get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e893eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(metric_manager_callback.meters['accuracy'].compute_overall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82bd073",
   "metadata": {},
   "outputs": [],
   "source": [
    "[np.round(x, 3) for x in metric_manager_callback.meters['EO'].compute_overall()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7973e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(metric_manager_callback.meters['EO'].compute_overall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61271a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_id = 2\n",
    "\n",
    "print(f\"{task_id=}\")\n",
    "print(f\"sensitive samples / all samples = {(benchmark.trains[task_id].sensitives != benchmark.trains[task_id].targets).sum().item()} / {benchmark.trains[task_id].sensitives.shape[0]}\")\n",
    "\n",
    "updated_seq_indices = benchmark.seq_indices_train[task_id]\n",
    "print(f\"sensitive samples / selected samples = {(benchmark.trains[task_id].sensitives[updated_seq_indices] != benchmark.trains[task_id].targets[updated_seq_indices]).sum().item()} / {len(updated_seq_indices)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32febda",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_class = 2\n",
    "for i in range(2, 6):\n",
    "    incremental_step = i\n",
    "    print(f\"{incremental_step=}\")\n",
    "    one_idx = benchmark.trains[incremental_step].sample_weight > 0.9\n",
    "\n",
    "    print(f\"{2*i-2} : {(benchmark.trains[incremental_step].targets == (2*i-2)).sum().item()} --> {(benchmark.trains[incremental_step].targets[one_idx] == (2*i-2)).sum().item()}\")\n",
    "    print(f\"{2*i-1} : {(benchmark.trains[incremental_step].targets == (2*i-1)).sum().item()} --> {(benchmark.trains[incremental_step].targets[one_idx] == (2*i-1)).sum().item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0880e76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for eos in metric_manager_callback.meters['fairness'].get_data():\n",
    "    for eo in eos:\n",
    "        print(round(eo, 3),end=\" \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6233f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_manager_callback.meters['classwise_accuracy'].get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21212733",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
