{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0c3b92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_dir=./outputs/demo/dataset=CIFAR10/seed=10_epoch=50_lr=0.01_alpha=0.0_tau=1.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import cl_gym as cl\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "seed = 10\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.set_num_threads(8)\n",
    "\n",
    "def make_params() -> dict:\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    import uuid\n",
    "\n",
    "    params = {\n",
    "            # dataset\n",
    "            'dataset': \"CIFAR10\",\n",
    "            # 'dataset': \"FMNIST\",\n",
    "            'random_class_idx' : False,\n",
    "            'method': \"vanilla\",\n",
    "\n",
    "            # benchmark\n",
    "            'seed': seed,\n",
    "            'num_tasks': 5,\n",
    "            'epochs_per_task': 50,\n",
    "            # 'per_task_examples': np.inf,\n",
    "            'per_task_examples': 200000,\n",
    "            'per_task_memory_examples': 64,\n",
    "            'batch_size_train': 256,\n",
    "            'batch_size_memory': 256,\n",
    "            # 'batch_size_memory': 256,\n",
    "            'batch_size_validation': 256,\n",
    "            'tau': 1.5,\n",
    "            # 'tau': 0.0,\n",
    "\n",
    "            # algorithm\n",
    "            'optimizer': 'sgd',\n",
    "            'learning_rate': 0.01,\n",
    "            'learning_rate_decay_epoch': [30, 50, 70, 90],\n",
    "            'momentum': 0.9,\n",
    "            'learning_rate_decay': 1.0,\n",
    "            'criterion': torch.nn.CrossEntropyLoss(),\n",
    "            'device': torch.device('cuda:6' if torch.cuda.is_available() else 'cpu'),\n",
    "             \n",
    "            # sample selection\n",
    "            'alpha':0.0,\n",
    "            'lambda': 0.0,\n",
    "            'lambda_old': 0.0,\n",
    "              }\n",
    "\n",
    "#     trial_id = str(uuid.uuid4())\n",
    "    trial_id = f\"demo/dataset={params['dataset']}/seed={params['seed']}_epoch={params['epochs_per_task']}_lr={params['learning_rate']}_alpha={params['alpha']}_tau={params['tau']}\"\n",
    "    params['trial_id'] = trial_id\n",
    "    params['output_dir'] = os.path.join(\"./outputs/{}\".format(trial_id))\n",
    "    print(f\"output_dir={params['output_dir']}\")\n",
    "    Path(params['output_dir']).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    return params\n",
    "\n",
    "params = make_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93b43ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from datasets import MNIST, FashionMNIST, BiasedMNIST, CIFAR10, CIFAR100\n",
    "if params['dataset'] == 'MNIST':\n",
    "    benchmark = MNIST(num_tasks=params['num_tasks'],\n",
    "                        per_task_memory_examples=params['per_task_memory_examples'],\n",
    "                        per_task_examples = params['per_task_examples'],\n",
    "                        joint = (params['method'] == \"joint\"),\n",
    "                        random_class_idx = params['random_class_idx'])\n",
    "    input_dim = (28, 28)\n",
    "elif params['dataset'] == 'FashionMNIST':\n",
    "    benchmark = FashionMNIST(num_tasks=params['num_tasks'],\n",
    "                                per_task_memory_examples=params['per_task_memory_examples'],\n",
    "                                per_task_examples = params['per_task_examples'],\n",
    "                                joint = (params['method'] == \"joint\"),\n",
    "                                random_class_idx = params['random_class_idx'])\n",
    "    input_dim = (28, 28)\n",
    "elif params['dataset'] == 'CIFAR10':\n",
    "    benchmark = CIFAR10(num_tasks=params['num_tasks'],\n",
    "                        per_task_memory_examples=params['per_task_memory_examples'],\n",
    "                        per_task_examples = params['per_task_examples'],\n",
    "                        joint = (params['method'] == \"joint\"),\n",
    "                        random_class_idx = params['random_class_idx'])\n",
    "    input_dim = (3, 32, 32)\n",
    "elif params['dataset'] == 'CIFAR100':        \n",
    "    benchmark = CIFAR100(num_tasks=params['num_tasks'],\n",
    "                            per_task_memory_examples=params['per_task_memory_examples'],\n",
    "                            per_task_examples = params['per_task_examples'],\n",
    "                            joint = (params['method'] == \"joint\"),\n",
    "                            random_class_idx = params['random_class_idx'])\n",
    "    input_dim = (3, 32, 32)\n",
    "elif params['dataset'] in [\"BiasedMNIST\"]:\n",
    "    benchmark = BiasedMNIST(num_tasks=params['num_tasks'],\n",
    "                            per_task_memory_examples=params['per_task_memory_examples'],\n",
    "                            per_task_examples = params['per_task_examples'],\n",
    "                            joint = (params['method'] == \"joint\"),\n",
    "                            random_class_idx = params['random_class_idx'])\n",
    "    input_dim = (3, 28, 28)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "class_idx = benchmark.class_idx\n",
    "num_classes = len(class_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20c7b886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modify resnet for cifar\n"
     ]
    }
   ],
   "source": [
    "from algorithms.imbalance import Heuristic2\n",
    "from metrics import MetricCollector2\n",
    "from backbones import MLP2Layers2\n",
    "\n",
    "from backbones.resnet import ResNet18\n",
    "\n",
    "\n",
    "# backbone = ResNet18(\n",
    "#     input_dim=input_dim, \n",
    "#     output_dim=num_classes,\n",
    "#     class_idx=class_idx,\n",
    "#     config=params\n",
    "#     ).to(params['device'])\n",
    "\n",
    "backbone = ResNet18(\n",
    "    input_dim=input_dim, \n",
    "    output_dim=num_classes,\n",
    "    class_idx=class_idx,\n",
    "    config=params\n",
    "    ).to(params['device'])\n",
    "\n",
    "algorithm = Heuristic2(backbone, benchmark, params, requires_memory=True)\n",
    "metric_manager_callback = MetricCollector2(num_tasks=params['num_tasks'],\n",
    "                                                        eval_interval='epoch',\n",
    "                                                        epochs_per_task=params['epochs_per_task'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8efa3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainers import ContinualTrainer\n",
    "\n",
    "trainer = ContinualTrainer(algorithm, params, callbacks=[metric_manager_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c315bf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Task 1 -----------------------\n",
      "[1] Eval metrics for task 1 >> {'accuracy': 0.821, 'loss': 0.0015542374849319457, 'std': 0.09600000000000003, 'EER': -1}\n",
      "[2] Eval metrics for task 1 >> {'accuracy': 0.8505, 'loss': 0.0013441222906112672, 'std': 0.08650000000000002, 'EER': -1}\n",
      "[3] Eval metrics for task 1 >> {'accuracy': 0.8835, 'loss': 0.001098384290933609, 'std': 0.04150000000000004, 'EER': -1}\n",
      "[4] Eval metrics for task 1 >> {'accuracy': 0.905, 'loss': 0.0009727678298950195, 'std': 0.013000000000000012, 'EER': -1}\n",
      "[5] Eval metrics for task 1 >> {'accuracy': 0.9145, 'loss': 0.0008592504635453224, 'std': 0.04149999999999998, 'EER': -1}\n",
      "[6] Eval metrics for task 1 >> {'accuracy': 0.927, 'loss': 0.0007724330499768257, 'std': 0.023999999999999966, 'EER': -1}\n",
      "[7] Eval metrics for task 1 >> {'accuracy': 0.872, 'loss': 0.0012186369150877, 'std': 0.10999999999999999, 'EER': -1}\n",
      "[8] Eval metrics for task 1 >> {'accuracy': 0.9239999999999999, 'loss': 0.0008102221190929413, 'std': 0.03799999999999998, 'EER': -1}\n",
      "[9] Eval metrics for task 1 >> {'accuracy': 0.9425, 'loss': 0.0006228669360280037, 'std': 0.013499999999999956, 'EER': -1}\n",
      "[10] Eval metrics for task 1 >> {'accuracy': 0.9435, 'loss': 0.0006541663408279419, 'std': 0.03049999999999997, 'EER': -1}\n",
      "[11] Eval metrics for task 1 >> {'accuracy': 0.9535, 'loss': 0.0005021771676838398, 'std': 0.004500000000000004, 'EER': -1}\n",
      "[12] Eval metrics for task 1 >> {'accuracy': 0.9495, 'loss': 0.0005349710024893284, 'std': 0.013499999999999956, 'EER': -1}\n",
      "[13] Eval metrics for task 1 >> {'accuracy': 0.9544999999999999, 'loss': 0.0005347102098166943, 'std': 0.005500000000000005, 'EER': -1}\n",
      "[14] Eval metrics for task 1 >> {'accuracy': 0.9615, 'loss': 0.00040383763238787654, 'std': 0.006500000000000006, 'EER': -1}\n",
      "[15] Eval metrics for task 1 >> {'accuracy': 0.9205, 'loss': 0.0010295420587062836, 'std': 0.07450000000000001, 'EER': -1}\n",
      "[16] Eval metrics for task 1 >> {'accuracy': 0.956, 'loss': 0.0004740884080529213, 'std': 0.007000000000000006, 'EER': -1}\n",
      "[17] Eval metrics for task 1 >> {'accuracy': 0.9644999999999999, 'loss': 0.00037283831648528574, 'std': 0.01150000000000001, 'EER': -1}\n",
      "[18] Eval metrics for task 1 >> {'accuracy': 0.959, 'loss': 0.0004592818133533001, 'std': 0.017000000000000015, 'EER': -1}\n",
      "[19] Eval metrics for task 1 >> {'accuracy': 0.966, 'loss': 0.0003582383552566171, 'std': 0.014000000000000012, 'EER': -1}\n",
      "[20] Eval metrics for task 1 >> {'accuracy': 0.96, 'loss': 0.0004337979666888714, 'std': 0.019000000000000017, 'EER': -1}\n",
      "[21] Eval metrics for task 1 >> {'accuracy': 0.9695, 'loss': 0.0003738541044294834, 'std': 0.006500000000000006, 'EER': -1}\n",
      "[22] Eval metrics for task 1 >> {'accuracy': 0.9610000000000001, 'loss': 0.00042475255206227304, 'std': 0.02699999999999997, 'EER': -1}\n",
      "[23] Eval metrics for task 1 >> {'accuracy': 0.9724999999999999, 'loss': 0.0002934701405465603, 'std': 0.0025000000000000022, 'EER': -1}\n",
      "[24] Eval metrics for task 1 >> {'accuracy': 0.967, 'loss': 0.00036090693809092046, 'std': 0.0050000000000000044, 'EER': -1}\n",
      "[25] Eval metrics for task 1 >> {'accuracy': 0.975, 'loss': 0.00028701317124068735, 'std': 0.0010000000000000009, 'EER': -1}\n",
      "[26] Eval metrics for task 1 >> {'accuracy': 0.9715, 'loss': 0.0003687286414206028, 'std': 0.0015000000000000013, 'EER': -1}\n",
      "[27] Eval metrics for task 1 >> {'accuracy': 0.9724999999999999, 'loss': 0.0003830532394349575, 'std': 0.0015000000000000013, 'EER': -1}\n",
      "[28] Eval metrics for task 1 >> {'accuracy': 0.972, 'loss': 0.0003108647773042321, 'std': 0.007000000000000006, 'EER': -1}\n",
      "[29] Eval metrics for task 1 >> {'accuracy': 0.9325, 'loss': 0.0009475812017917633, 'std': 0.04049999999999998, 'EER': -1}\n",
      "[30] Eval metrics for task 1 >> {'accuracy': 0.948, 'loss': 0.0008168460093438626, 'std': 0.034999999999999976, 'EER': -1}\n",
      "[31] Eval metrics for task 1 >> {'accuracy': 0.9410000000000001, 'loss': 0.000901186853647232, 'std': 0.04299999999999998, 'EER': -1}\n",
      "[32] Eval metrics for task 1 >> {'accuracy': 0.9425, 'loss': 0.000876957193017006, 'std': 0.04149999999999998, 'EER': -1}\n",
      "[33] Eval metrics for task 1 >> {'accuracy': 0.95, 'loss': 0.0007845024466514587, 'std': 0.02999999999999997, 'EER': -1}\n",
      "[34] Eval metrics for task 1 >> {'accuracy': 0.9445, 'loss': 0.000872126579284668, 'std': 0.04049999999999998, 'EER': -1}\n",
      "[35] Eval metrics for task 1 >> {'accuracy': 0.942, 'loss': 0.0008924752697348594, 'std': 0.04299999999999998, 'EER': -1}\n",
      "[36] Eval metrics for task 1 >> {'accuracy': 0.9390000000000001, 'loss': 0.0009520881697535515, 'std': 0.045999999999999985, 'EER': -1}\n",
      "[37] Eval metrics for task 1 >> {'accuracy': 0.9435, 'loss': 0.0008644357547163964, 'std': 0.04049999999999998, 'EER': -1}\n",
      "[38] Eval metrics for task 1 >> {'accuracy': 0.9515, 'loss': 0.0007570509016513825, 'std': 0.02849999999999997, 'EER': -1}\n",
      "[39] Eval metrics for task 1 >> {'accuracy': 0.9475, 'loss': 0.0008233070299029351, 'std': 0.03649999999999998, 'EER': -1}\n",
      "[40] Eval metrics for task 1 >> {'accuracy': 0.9470000000000001, 'loss': 0.0008493602201342582, 'std': 0.03699999999999998, 'EER': -1}\n",
      "[41] Eval metrics for task 1 >> {'accuracy': 0.9475, 'loss': 0.0008152196519076824, 'std': 0.03649999999999998, 'EER': -1}\n",
      "[42] Eval metrics for task 1 >> {'accuracy': 0.9415, 'loss': 0.0008951142840087414, 'std': 0.04349999999999998, 'EER': -1}\n",
      "[43] Eval metrics for task 1 >> {'accuracy': 0.9450000000000001, 'loss': 0.000874044619500637, 'std': 0.03899999999999998, 'EER': -1}\n",
      "[44] Eval metrics for task 1 >> {'accuracy': 0.944, 'loss': 0.0008662469312548638, 'std': 0.04099999999999998, 'EER': -1}\n",
      "[45] Eval metrics for task 1 >> {'accuracy': 0.9495, 'loss': 0.0008122915476560593, 'std': 0.03249999999999997, 'EER': -1}\n",
      "[46] Eval metrics for task 1 >> {'accuracy': 0.95, 'loss': 0.0007514705434441566, 'std': 0.02899999999999997, 'EER': -1}\n",
      "[47] Eval metrics for task 1 >> {'accuracy': 0.9410000000000001, 'loss': 0.0009208736419677734, 'std': 0.04299999999999998, 'EER': -1}\n",
      "[48] Eval metrics for task 1 >> {'accuracy': 0.9450000000000001, 'loss': 0.0008587613031268119, 'std': 0.03899999999999998, 'EER': -1}\n",
      "[49] Eval metrics for task 1 >> {'accuracy': 0.9490000000000001, 'loss': 0.0007111882157623768, 'std': 0.023999999999999966, 'EER': -1}\n",
      "[50] Eval metrics for task 1 >> {'accuracy': 0.9430000000000001, 'loss': 0.0008770229443907738, 'std': 0.04199999999999998, 'EER': -1}\n",
      "training_task_end\n",
      "---------------------------- Task 2 -----------------------\n",
      "[51] Eval metrics for task 1 >> {'accuracy': 0.5700000000000001, 'loss': 0.0051806774735450745, 'std': 0.059, 'EER': -1}\n",
      "[51] Eval metrics for task 2 >> {'accuracy': 0.3075, 'loss': 0.005889500260353089, 'std': 0.1225, 'EER': -1}\n",
      "[52] Eval metrics for task 1 >> {'accuracy': 0.7010000000000001, 'loss': 0.005667901575565338, 'std': 0.03199999999999997, 'EER': -1}\n",
      "[52] Eval metrics for task 2 >> {'accuracy': 0.4125, 'loss': 0.006369477272033692, 'std': 0.1975, 'EER': -1}\n",
      "[53] Eval metrics for task 1 >> {'accuracy': 0.4545, 'loss': 0.009608262896537781, 'std': 0.0685, 'EER': -1}\n",
      "[53] Eval metrics for task 2 >> {'accuracy': 0.5465, 'loss': 0.003813817858695984, 'std': 0.003500000000000003, 'EER': -1}\n",
      "[54] Eval metrics for task 1 >> {'accuracy': 0.47850000000000004, 'loss': 0.016627202987670897, 'std': 0.05650000000000002, 'EER': -1}\n",
      "[54] Eval metrics for task 2 >> {'accuracy': 0.5465, 'loss': 0.00416647744178772, 'std': 0.14449999999999996, 'EER': -1}\n",
      "[55] Eval metrics for task 1 >> {'accuracy': 0.526, 'loss': 0.012218567728996276, 'std': 0.0010000000000000009, 'EER': -1}\n",
      "[55] Eval metrics for task 2 >> {'accuracy': 0.383, 'loss': 0.004760908246040344, 'std': 0.068, 'EER': -1}\n",
      "[56] Eval metrics for task 1 >> {'accuracy': 0.6985, 'loss': 0.00768182909488678, 'std': 0.07450000000000001, 'EER': -1}\n",
      "[56] Eval metrics for task 2 >> {'accuracy': 0.2895, 'loss': 0.007426397621631622, 'std': 0.04150000000000001, 'EER': -1}\n",
      "[57] Eval metrics for task 1 >> {'accuracy': 0.636, 'loss': 0.007595404505729675, 'std': 0.07499999999999996, 'EER': -1}\n",
      "[57] Eval metrics for task 2 >> {'accuracy': 0.397, 'loss': 0.005049334526062012, 'std': 0.121, 'EER': -1}\n",
      "[58] Eval metrics for task 1 >> {'accuracy': 0.6799999999999999, 'loss': 0.007376397073268891, 'std': 0.07800000000000001, 'EER': -1}\n",
      "[58] Eval metrics for task 2 >> {'accuracy': 0.33199999999999996, 'loss': 0.00564709359407425, 'std': 0.047000000000000014, 'EER': -1}\n",
      "[59] Eval metrics for task 1 >> {'accuracy': 0.6925, 'loss': 0.006705179691314698, 'std': 0.03749999999999998, 'EER': -1}\n",
      "[59] Eval metrics for task 2 >> {'accuracy': 0.2805, 'loss': 0.0067338175773620605, 'std': 0.1125, 'EER': -1}\n",
      "[60] Eval metrics for task 1 >> {'accuracy': 0.6559999999999999, 'loss': 0.00693627542257309, 'std': 0.059, 'EER': -1}\n",
      "[60] Eval metrics for task 2 >> {'accuracy': 0.4185, 'loss': 0.005153531968593597, 'std': 0.16949999999999998, 'EER': -1}\n",
      "[61] Eval metrics for task 1 >> {'accuracy': 0.6419999999999999, 'loss': 0.00742542427778244, 'std': 0.07200000000000001, 'EER': -1}\n",
      "[61] Eval metrics for task 2 >> {'accuracy': 0.3855, 'loss': 0.005073355078697205, 'std': 0.10849999999999999, 'EER': -1}\n",
      "[62] Eval metrics for task 1 >> {'accuracy': 0.638, 'loss': 0.008756706058979035, 'std': 0.10099999999999998, 'EER': -1}\n",
      "[62] Eval metrics for task 2 >> {'accuracy': 0.3755, 'loss': 0.005119459390640259, 'std': 0.09549999999999997, 'EER': -1}\n",
      "[63] Eval metrics for task 1 >> {'accuracy': 0.482, 'loss': 0.015204825520515441, 'std': 0.126, 'EER': -1}\n",
      "[63] Eval metrics for task 2 >> {'accuracy': 0.3645, 'loss': 0.0061140238642692565, 'std': 0.19949999999999998, 'EER': -1}\n",
      "[64] Eval metrics for task 1 >> {'accuracy': 0.606, 'loss': 0.012372203230857848, 'std': 0.03300000000000003, 'EER': -1}\n",
      "[64] Eval metrics for task 2 >> {'accuracy': 0.39649999999999996, 'loss': 0.005269367516040802, 'std': 0.0955, 'EER': -1}\n",
      "[65] Eval metrics for task 1 >> {'accuracy': 0.585, 'loss': 0.01206416404247284, 'std': 0.04199999999999998, 'EER': -1}\n",
      "[65] Eval metrics for task 2 >> {'accuracy': 0.4795, 'loss': 0.004636914253234863, 'std': 0.24649999999999997, 'EER': -1}\n",
      "[66] Eval metrics for task 1 >> {'accuracy': 0.639, 'loss': 0.014832170128822326, 'std': 0.07400000000000001, 'EER': -1}\n",
      "[66] Eval metrics for task 2 >> {'accuracy': 0.45949999999999996, 'loss': 0.004557250022888183, 'std': 0.10349999999999998, 'EER': -1}\n",
      "[67] Eval metrics for task 1 >> {'accuracy': 0.669, 'loss': 0.007382222354412079, 'std': 0.119, 'EER': -1}\n",
      "[67] Eval metrics for task 2 >> {'accuracy': 0.457, 'loss': 0.004539954900741577, 'std': 0.068, 'EER': -1}\n",
      "[68] Eval metrics for task 1 >> {'accuracy': 0.6555, 'loss': 0.009623298645019531, 'std': 0.0675, 'EER': -1}\n",
      "[68] Eval metrics for task 2 >> {'accuracy': 0.42000000000000004, 'loss': 0.0048454924821853635, 'std': 0.04200000000000001, 'EER': -1}\n",
      "[69] Eval metrics for task 1 >> {'accuracy': 0.7290000000000001, 'loss': 0.007118978321552277, 'std': 0.04799999999999999, 'EER': -1}\n",
      "[69] Eval metrics for task 2 >> {'accuracy': 0.40549999999999997, 'loss': 0.006890574395656586, 'std': 0.19449999999999998, 'EER': -1}\n",
      "[70] Eval metrics for task 1 >> {'accuracy': 0.616, 'loss': 0.007932475209236145, 'std': 0.0010000000000000009, 'EER': -1}\n",
      "[70] Eval metrics for task 2 >> {'accuracy': 0.571, 'loss': 0.0037098529934883116, 'std': 0.08100000000000002, 'EER': -1}\n",
      "[71] Eval metrics for task 1 >> {'accuracy': 0.6805, 'loss': 0.007518726170063019, 'std': 0.03949999999999998, 'EER': -1}\n",
      "[71] Eval metrics for task 2 >> {'accuracy': 0.5780000000000001, 'loss': 0.004462037920951843, 'std': 0.20900000000000002, 'EER': -1}\n",
      "[72] Eval metrics for task 1 >> {'accuracy': 0.6995, 'loss': 0.007296314239501953, 'std': 0.045499999999999985, 'EER': -1}\n",
      "[72] Eval metrics for task 2 >> {'accuracy': 0.5265, 'loss': 0.005101308822631836, 'std': 0.2515, 'EER': -1}\n",
      "[73] Eval metrics for task 1 >> {'accuracy': 0.593, 'loss': 0.0076836649179458615, 'std': 0.03799999999999998, 'EER': -1}\n",
      "[73] Eval metrics for task 2 >> {'accuracy': 0.5695, 'loss': 0.0042784765362739565, 'std': 0.11050000000000001, 'EER': -1}\n",
      "[74] Eval metrics for task 1 >> {'accuracy': 0.5955, 'loss': 0.00831644320487976, 'std': 0.034499999999999975, 'EER': -1}\n",
      "[74] Eval metrics for task 2 >> {'accuracy': 0.5785, 'loss': 0.004178643465042114, 'std': 0.13049999999999998, 'EER': -1}\n",
      "[75] Eval metrics for task 1 >> {'accuracy': 0.6575, 'loss': 0.007405523180961609, 'std': 0.05449999999999999, 'EER': -1}\n",
      "[75] Eval metrics for task 2 >> {'accuracy': 0.537, 'loss': 0.004410144209861755, 'std': 0.14400000000000002, 'EER': -1}\n",
      "[76] Eval metrics for task 1 >> {'accuracy': 0.6795, 'loss': 0.006808120787143707, 'std': 0.07050000000000001, 'EER': -1}\n",
      "[76] Eval metrics for task 2 >> {'accuracy': 0.5505, 'loss': 0.004092600733041764, 'std': 0.11150000000000002, 'EER': -1}\n",
      "[77] Eval metrics for task 1 >> {'accuracy': 0.6719999999999999, 'loss': 0.007395368158817291, 'std': 0.09400000000000003, 'EER': -1}\n",
      "[77] Eval metrics for task 2 >> {'accuracy': 0.5605, 'loss': 0.004263853818178177, 'std': 0.21050000000000002, 'EER': -1}\n",
      "[78] Eval metrics for task 1 >> {'accuracy': 0.62, 'loss': 0.007409970283508301, 'std': 0.039000000000000035, 'EER': -1}\n",
      "[78] Eval metrics for task 2 >> {'accuracy': 0.574, 'loss': 0.004511370301246643, 'std': 0.28900000000000003, 'EER': -1}\n",
      "[79] Eval metrics for task 1 >> {'accuracy': 0.6625, 'loss': 0.007255626678466797, 'std': 0.03649999999999998, 'EER': -1}\n",
      "[79] Eval metrics for task 2 >> {'accuracy': 0.5945, 'loss': 0.004469927728176117, 'std': 0.20750000000000002, 'EER': -1}\n",
      "[80] Eval metrics for task 1 >> {'accuracy': 0.5935, 'loss': 0.0072904304265975954, 'std': 0.04249999999999998, 'EER': -1}\n",
      "[80] Eval metrics for task 2 >> {'accuracy': 0.639, 'loss': 0.003643452376127243, 'std': 0.17399999999999996, 'EER': -1}\n",
      "[81] Eval metrics for task 1 >> {'accuracy': 0.625, 'loss': 0.007264199018478393, 'std': 0.05300000000000005, 'EER': -1}\n",
      "[81] Eval metrics for task 2 >> {'accuracy': 0.6194999999999999, 'loss': 0.00397751435637474, 'std': 0.20249999999999999, 'EER': -1}\n",
      "[82] Eval metrics for task 1 >> {'accuracy': 0.5840000000000001, 'loss': 0.007161130428314209, 'std': 0.04799999999999999, 'EER': -1}\n",
      "[82] Eval metrics for task 2 >> {'accuracy': 0.644, 'loss': 0.003606682002544403, 'std': 0.18699999999999997, 'EER': -1}\n",
      "[83] Eval metrics for task 1 >> {'accuracy': 0.6255, 'loss': 0.007472125172615051, 'std': 0.03350000000000003, 'EER': -1}\n",
      "[83] Eval metrics for task 2 >> {'accuracy': 0.613, 'loss': 0.00406402114033699, 'std': 0.17500000000000002, 'EER': -1}\n",
      "[84] Eval metrics for task 1 >> {'accuracy': 0.5800000000000001, 'loss': 0.00746584540605545, 'std': 0.04499999999999999, 'EER': -1}\n",
      "[84] Eval metrics for task 2 >> {'accuracy': 0.6395, 'loss': 0.0035142309665679933, 'std': 0.16650000000000004, 'EER': -1}\n",
      "[85] Eval metrics for task 1 >> {'accuracy': 0.683, 'loss': 0.00706624311208725, 'std': 0.030999999999999972, 'EER': -1}\n",
      "[85] Eval metrics for task 2 >> {'accuracy': 0.575, 'loss': 0.00461271196603775, 'std': 0.191, 'EER': -1}\n",
      "[86] Eval metrics for task 1 >> {'accuracy': 0.654, 'loss': 0.007292273938655853, 'std': 0.03200000000000003, 'EER': -1}\n",
      "[86] Eval metrics for task 2 >> {'accuracy': 0.5815, 'loss': 0.004346934318542481, 'std': 0.1805, 'EER': -1}\n",
      "[87] Eval metrics for task 1 >> {'accuracy': 0.6699999999999999, 'loss': 0.007036044836044312, 'std': 0.067, 'EER': -1}\n",
      "[87] Eval metrics for task 2 >> {'accuracy': 0.599, 'loss': 0.004283030152320862, 'std': 0.19100000000000003, 'EER': -1}\n",
      "[88] Eval metrics for task 1 >> {'accuracy': 0.6545, 'loss': 0.006915117919445038, 'std': 0.05249999999999999, 'EER': -1}\n",
      "[88] Eval metrics for task 2 >> {'accuracy': 0.593, 'loss': 0.0041783380508422854, 'std': 0.17700000000000002, 'EER': -1}\n",
      "[89] Eval metrics for task 1 >> {'accuracy': 0.621, 'loss': 0.007318208038806916, 'std': 0.04400000000000004, 'EER': -1}\n",
      "[89] Eval metrics for task 2 >> {'accuracy': 0.628, 'loss': 0.003935770481824875, 'std': 0.18100000000000002, 'EER': -1}\n",
      "[90] Eval metrics for task 1 >> {'accuracy': 0.581, 'loss': 0.007112187922000885, 'std': 0.046999999999999986, 'EER': -1}\n",
      "[90] Eval metrics for task 2 >> {'accuracy': 0.6365000000000001, 'loss': 0.003605171799659729, 'std': 0.16050000000000003, 'EER': -1}\n",
      "[91] Eval metrics for task 1 >> {'accuracy': 0.6705, 'loss': 0.0072339544892311095, 'std': 0.03249999999999997, 'EER': -1}\n",
      "[91] Eval metrics for task 2 >> {'accuracy': 0.5845, 'loss': 0.0044873677790164945, 'std': 0.1815, 'EER': -1}\n",
      "[92] Eval metrics for task 1 >> {'accuracy': 0.657, 'loss': 0.00750294315814972, 'std': 0.033999999999999975, 'EER': -1}\n",
      "[92] Eval metrics for task 2 >> {'accuracy': 0.587, 'loss': 0.0043575667440891265, 'std': 0.191, 'EER': -1}\n",
      "[93] Eval metrics for task 1 >> {'accuracy': 0.621, 'loss': 0.007488428354263305, 'std': 0.040000000000000036, 'EER': -1}\n",
      "[93] Eval metrics for task 2 >> {'accuracy': 0.6135, 'loss': 0.0039475556910037995, 'std': 0.1475, 'EER': -1}\n",
      "[94] Eval metrics for task 1 >> {'accuracy': 0.629, 'loss': 0.007099755585193634, 'std': 0.062, 'EER': -1}\n",
      "[94] Eval metrics for task 2 >> {'accuracy': 0.618, 'loss': 0.0038835559189319612, 'std': 0.19400000000000003, 'EER': -1}\n",
      "[95] Eval metrics for task 1 >> {'accuracy': 0.698, 'loss': 0.006922964155673981, 'std': 0.032999999999999974, 'EER': -1}\n",
      "[95] Eval metrics for task 2 >> {'accuracy': 0.554, 'loss': 0.0048746218085289, 'std': 0.16599999999999998, 'EER': -1}\n",
      "[96] Eval metrics for task 1 >> {'accuracy': 0.6965, 'loss': 0.006897250890731812, 'std': 0.034499999999999975, 'EER': -1}\n",
      "[96] Eval metrics for task 2 >> {'accuracy': 0.5715, 'loss': 0.004610719233751297, 'std': 0.1845, 'EER': -1}\n",
      "[97] Eval metrics for task 1 >> {'accuracy': 0.7005, 'loss': 0.0067317731380462644, 'std': 0.04349999999999998, 'EER': -1}\n",
      "[97] Eval metrics for task 2 >> {'accuracy': 0.5575, 'loss': 0.004753623127937317, 'std': 0.17149999999999999, 'EER': -1}\n",
      "[98] Eval metrics for task 1 >> {'accuracy': 0.6419999999999999, 'loss': 0.006976130843162537, 'std': 0.045999999999999985, 'EER': -1}\n",
      "[98] Eval metrics for task 2 >> {'accuracy': 0.6015, 'loss': 0.0041339493691921235, 'std': 0.20350000000000001, 'EER': -1}\n",
      "[99] Eval metrics for task 1 >> {'accuracy': 0.6535, 'loss': 0.007087073028087616, 'std': 0.05249999999999999, 'EER': -1}\n",
      "[99] Eval metrics for task 2 >> {'accuracy': 0.6005, 'loss': 0.004164503276348114, 'std': 0.18850000000000003, 'EER': -1}\n",
      "[100] Eval metrics for task 1 >> {'accuracy': 0.591, 'loss': 0.006977776110172272, 'std': 0.046999999999999986, 'EER': -1}\n",
      "[100] Eval metrics for task 2 >> {'accuracy': 0.629, 'loss': 0.003664837121963501, 'std': 0.18799999999999997, 'EER': -1}\n",
      "training_task_end\n",
      "---------------------------- Task 3 -----------------------\n",
      "[101] Eval metrics for task 1 >> {'accuracy': 0.483, 'loss': 0.018214626312255858, 'std': 0.027999999999999997, 'EER': -1}\n",
      "[101] Eval metrics for task 2 >> {'accuracy': 0.45099999999999996, 'loss': 0.0062497581839561465, 'std': 0.037000000000000005, 'EER': -1}\n",
      "[101] Eval metrics for task 3 >> {'accuracy': 0.20650000000000002, 'loss': 0.005713719606399536, 'std': 0.07450000000000001, 'EER': -1}\n",
      "[102] Eval metrics for task 1 >> {'accuracy': 0.47150000000000003, 'loss': 0.017557459950447083, 'std': 0.04150000000000001, 'EER': -1}\n",
      "[102] Eval metrics for task 2 >> {'accuracy': 0.36750000000000005, 'loss': 0.009390338778495788, 'std': 0.0915, 'EER': -1}\n",
      "[102] Eval metrics for task 3 >> {'accuracy': 0.35550000000000004, 'loss': 0.005810789704322815, 'std': 0.014499999999999985, 'EER': -1}\n",
      "[103] Eval metrics for task 1 >> {'accuracy': 0.361, 'loss': 0.031081034183502197, 'std': 0.05499999999999999, 'EER': -1}\n",
      "[103] Eval metrics for task 2 >> {'accuracy': 0.37949999999999995, 'loss': 0.010970234155654908, 'std': 0.0295, 'EER': -1}\n",
      "[103] Eval metrics for task 3 >> {'accuracy': 0.333, 'loss': 0.005928833544254303, 'std': 0.064, 'EER': -1}\n",
      "[104] Eval metrics for task 1 >> {'accuracy': 0.52, 'loss': 0.021121818542480467, 'std': 0.07699999999999999, 'EER': -1}\n",
      "[104] Eval metrics for task 2 >> {'accuracy': 0.45299999999999996, 'loss': 0.010498754024505615, 'std': 0.037000000000000005, 'EER': -1}\n",
      "[104] Eval metrics for task 3 >> {'accuracy': 0.20900000000000002, 'loss': 0.008330809414386749, 'std': 0.02500000000000001, 'EER': -1}\n",
      "[105] Eval metrics for task 1 >> {'accuracy': 0.417, 'loss': 0.027920748710632323, 'std': 0.007000000000000006, 'EER': -1}\n",
      "[105] Eval metrics for task 2 >> {'accuracy': 0.411, 'loss': 0.011100595593452453, 'std': 0.0, 'EER': -1}\n",
      "[105] Eval metrics for task 3 >> {'accuracy': 0.2975, 'loss': 0.007019051015377044, 'std': 0.1195, 'EER': -1}\n",
      "[106] Eval metrics for task 1 >> {'accuracy': 0.47050000000000003, 'loss': 0.025731440305709837, 'std': 0.047500000000000014, 'EER': -1}\n",
      "[106] Eval metrics for task 2 >> {'accuracy': 0.42000000000000004, 'loss': 0.01250191366672516, 'std': 0.08399999999999999, 'EER': -1}\n",
      "[106] Eval metrics for task 3 >> {'accuracy': 0.309, 'loss': 0.006928468108177185, 'std': 0.02300000000000002, 'EER': -1}\n",
      "[107] Eval metrics for task 1 >> {'accuracy': 0.47550000000000003, 'loss': 0.023421719312667847, 'std': 0.06750000000000003, 'EER': -1}\n",
      "[107] Eval metrics for task 2 >> {'accuracy': 0.3565, 'loss': 0.014116824626922608, 'std': 0.0675, 'EER': -1}\n",
      "[107] Eval metrics for task 3 >> {'accuracy': 0.4445, 'loss': 0.005248572945594787, 'std': 0.0015000000000000013, 'EER': -1}\n",
      "[108] Eval metrics for task 1 >> {'accuracy': 0.41700000000000004, 'loss': 0.02874887728691101, 'std': 0.023999999999999994, 'EER': -1}\n",
      "[108] Eval metrics for task 2 >> {'accuracy': 0.389, 'loss': 0.01309014642238617, 'std': 0.008000000000000007, 'EER': -1}\n",
      "[108] Eval metrics for task 3 >> {'accuracy': 0.40800000000000003, 'loss': 0.005910205662250519, 'std': 0.026999999999999996, 'EER': -1}\n",
      "[109] Eval metrics for task 1 >> {'accuracy': 0.437, 'loss': 0.02569753074645996, 'std': 0.013000000000000012, 'EER': -1}\n",
      "[109] Eval metrics for task 2 >> {'accuracy': 0.39749999999999996, 'loss': 0.013197084069252013, 'std': 0.03950000000000001, 'EER': -1}\n",
      "[109] Eval metrics for task 3 >> {'accuracy': 0.444, 'loss': 0.005674043715000153, 'std': 0.02200000000000002, 'EER': -1}\n",
      "[110] Eval metrics for task 1 >> {'accuracy': 0.4385, 'loss': 0.02599950647354126, 'std': 0.04949999999999999, 'EER': -1}\n",
      "[110] Eval metrics for task 2 >> {'accuracy': 0.3355, 'loss': 0.01418705701828003, 'std': 0.05350000000000002, 'EER': -1}\n",
      "[110] Eval metrics for task 3 >> {'accuracy': 0.488, 'loss': 0.005093929827213287, 'std': 0.11199999999999999, 'EER': -1}\n",
      "[111] Eval metrics for task 1 >> {'accuracy': 0.4365, 'loss': 0.021288968801498415, 'std': 0.024500000000000022, 'EER': -1}\n",
      "[111] Eval metrics for task 2 >> {'accuracy': 0.31, 'loss': 0.015080252647399902, 'std': 0.035999999999999976, 'EER': -1}\n",
      "[111] Eval metrics for task 3 >> {'accuracy': 0.49949999999999994, 'loss': 0.004922414064407348, 'std': 0.06549999999999997, 'EER': -1}\n",
      "[112] Eval metrics for task 1 >> {'accuracy': 0.42100000000000004, 'loss': 0.02439470934867859, 'std': 0.016999999999999987, 'EER': -1}\n",
      "[112] Eval metrics for task 2 >> {'accuracy': 0.301, 'loss': 0.017735046863555908, 'std': 0.06999999999999999, 'EER': -1}\n",
      "[112] Eval metrics for task 3 >> {'accuracy': 0.44799999999999995, 'loss': 0.005794633746147156, 'std': 0.151, 'EER': -1}\n",
      "[113] Eval metrics for task 1 >> {'accuracy': 0.462, 'loss': 0.02718457841873169, 'std': 0.09400000000000003, 'EER': -1}\n",
      "[113] Eval metrics for task 2 >> {'accuracy': 0.343, 'loss': 0.016567105054855348, 'std': 0.062, 'EER': -1}\n",
      "[113] Eval metrics for task 3 >> {'accuracy': 0.48250000000000004, 'loss': 0.005595626890659332, 'std': 0.048500000000000015, 'EER': -1}\n",
      "[114] Eval metrics for task 1 >> {'accuracy': 0.485, 'loss': 0.02584463095664978, 'std': 0.04400000000000001, 'EER': -1}\n",
      "[114] Eval metrics for task 2 >> {'accuracy': 0.373, 'loss': 0.01575132966041565, 'std': 0.10599999999999998, 'EER': -1}\n",
      "[114] Eval metrics for task 3 >> {'accuracy': 0.4175, 'loss': 0.0063799026608467105, 'std': 0.0325, 'EER': -1}\n",
      "[115] Eval metrics for task 1 >> {'accuracy': 0.4345, 'loss': 0.024138627290725707, 'std': 0.02250000000000002, 'EER': -1}\n",
      "[115] Eval metrics for task 2 >> {'accuracy': 0.4505, 'loss': 0.010881185650825501, 'std': 0.0325, 'EER': -1}\n",
      "[115] Eval metrics for task 3 >> {'accuracy': 0.33899999999999997, 'loss': 0.0073314648270607, 'std': 0.092, 'EER': -1}\n",
      "[116] Eval metrics for task 1 >> {'accuracy': 0.44799999999999995, 'loss': 0.023367010831832884, 'std': 0.034, 'EER': -1}\n",
      "[116] Eval metrics for task 2 >> {'accuracy': 0.362, 'loss': 0.017854652643203735, 'std': 0.132, 'EER': -1}\n",
      "[116] Eval metrics for task 3 >> {'accuracy': 0.42200000000000004, 'loss': 0.0062520306706428525, 'std': 0.027999999999999997, 'EER': -1}\n",
      "[117] Eval metrics for task 1 >> {'accuracy': 0.388, 'loss': 0.027848513126373292, 'std': 0.0050000000000000044, 'EER': -1}\n",
      "[117] Eval metrics for task 2 >> {'accuracy': 0.2925, 'loss': 0.015952992796897887, 'std': 0.0825, 'EER': -1}\n",
      "[117] Eval metrics for task 3 >> {'accuracy': 0.6155, 'loss': 0.0037353935539722444, 'std': 0.05349999999999999, 'EER': -1}\n",
      "[118] Eval metrics for task 1 >> {'accuracy': 0.438, 'loss': 0.02190584421157837, 'std': 0.034999999999999976, 'EER': -1}\n",
      "[118] Eval metrics for task 2 >> {'accuracy': 0.4185, 'loss': 0.01408620250225067, 'std': 0.10650000000000001, 'EER': -1}\n",
      "[118] Eval metrics for task 3 >> {'accuracy': 0.4425, 'loss': 0.00613925302028656, 'std': 0.0685, 'EER': -1}\n",
      "[119] Eval metrics for task 1 >> {'accuracy': 0.443, 'loss': 0.026953628540039062, 'std': 0.03899999999999998, 'EER': -1}\n",
      "[119] Eval metrics for task 2 >> {'accuracy': 0.3765, 'loss': 0.014525846242904664, 'std': 0.034499999999999975, 'EER': -1}\n",
      "[119] Eval metrics for task 3 >> {'accuracy': 0.49, 'loss': 0.00533463329076767, 'std': 0.05000000000000002, 'EER': -1}\n",
      "[120] Eval metrics for task 1 >> {'accuracy': 0.46950000000000003, 'loss': 0.02976226282119751, 'std': 0.007499999999999979, 'EER': -1}\n",
      "[120] Eval metrics for task 2 >> {'accuracy': 0.39949999999999997, 'loss': 0.014820728302001953, 'std': 0.05250000000000002, 'EER': -1}\n",
      "[120] Eval metrics for task 3 >> {'accuracy': 0.4155, 'loss': 0.006819612145423889, 'std': 0.13350000000000004, 'EER': -1}\n",
      "[121] Eval metrics for task 1 >> {'accuracy': 0.4585, 'loss': 0.026334221601486206, 'std': 0.014499999999999985, 'EER': -1}\n",
      "[121] Eval metrics for task 2 >> {'accuracy': 0.3045, 'loss': 0.017904221415519714, 'std': 0.09150000000000001, 'EER': -1}\n",
      "[121] Eval metrics for task 3 >> {'accuracy': 0.535, 'loss': 0.00490531200170517, 'std': 0.08099999999999999, 'EER': -1}\n",
      "[122] Eval metrics for task 1 >> {'accuracy': 0.46399999999999997, 'loss': 0.021301586866378786, 'std': 0.017999999999999988, 'EER': -1}\n",
      "[122] Eval metrics for task 2 >> {'accuracy': 0.40349999999999997, 'loss': 0.014221259593963623, 'std': 0.04150000000000001, 'EER': -1}\n",
      "[122] Eval metrics for task 3 >> {'accuracy': 0.46, 'loss': 0.005893454849720001, 'std': 0.061, 'EER': -1}\n",
      "[123] Eval metrics for task 1 >> {'accuracy': 0.507, 'loss': 0.02010072898864746, 'std': 0.0040000000000000036, 'EER': -1}\n",
      "[123] Eval metrics for task 2 >> {'accuracy': 0.4075, 'loss': 0.013869407773017883, 'std': 0.07149999999999998, 'EER': -1}\n",
      "[123] Eval metrics for task 3 >> {'accuracy': 0.4625, 'loss': 0.006133217632770538, 'std': 0.08450000000000002, 'EER': -1}\n",
      "[124] Eval metrics for task 1 >> {'accuracy': 0.39949999999999997, 'loss': 0.027094913482666017, 'std': 0.03950000000000001, 'EER': -1}\n",
      "[124] Eval metrics for task 2 >> {'accuracy': 0.4135, 'loss': 0.014377943396568298, 'std': 0.04450000000000001, 'EER': -1}\n",
      "[124] Eval metrics for task 3 >> {'accuracy': 0.4445, 'loss': 0.006670767307281494, 'std': 0.12149999999999997, 'EER': -1}\n",
      "[125] Eval metrics for task 1 >> {'accuracy': 0.426, 'loss': 0.03001993155479431, 'std': 0.05099999999999999, 'EER': -1}\n",
      "[125] Eval metrics for task 2 >> {'accuracy': 0.4, 'loss': 0.014513857126235962, 'std': 0.03900000000000001, 'EER': -1}\n",
      "[125] Eval metrics for task 3 >> {'accuracy': 0.45100000000000007, 'loss': 0.00597618979215622, 'std': 0.10900000000000001, 'EER': -1}\n",
      "[126] Eval metrics for task 1 >> {'accuracy': 0.3855, 'loss': 0.027089747428894043, 'std': 0.0015000000000000013, 'EER': -1}\n",
      "[126] Eval metrics for task 2 >> {'accuracy': 0.34299999999999997, 'loss': 0.015123577356338501, 'std': 0.060000000000000026, 'EER': -1}\n",
      "[126] Eval metrics for task 3 >> {'accuracy': 0.59, 'loss': 0.00399678984284401, 'std': 0.010000000000000009, 'EER': -1}\n",
      "[127] Eval metrics for task 1 >> {'accuracy': 0.372, 'loss': 0.03029054617881775, 'std': 0.10199999999999998, 'EER': -1}\n",
      "[127] Eval metrics for task 2 >> {'accuracy': 0.337, 'loss': 0.01744485890865326, 'std': 0.0040000000000000036, 'EER': -1}\n",
      "[127] Eval metrics for task 3 >> {'accuracy': 0.528, 'loss': 0.005114542722702026, 'std': 0.05199999999999999, 'EER': -1}\n",
      "[128] Eval metrics for task 1 >> {'accuracy': 0.5105, 'loss': 0.020554614782333374, 'std': 0.055499999999999966, 'EER': -1}\n",
      "[128] Eval metrics for task 2 >> {'accuracy': 0.4475, 'loss': 0.01138034176826477, 'std': 0.11450000000000002, 'EER': -1}\n",
      "[128] Eval metrics for task 3 >> {'accuracy': 0.4535, 'loss': 0.005643545567989349, 'std': 0.09950000000000003, 'EER': -1}\n",
      "[129] Eval metrics for task 1 >> {'accuracy': 0.49450000000000005, 'loss': 0.026001590967178346, 'std': 0.058500000000000024, 'EER': -1}\n",
      "[129] Eval metrics for task 2 >> {'accuracy': 0.45099999999999996, 'loss': 0.012500773787498474, 'std': 0.028999999999999998, 'EER': -1}\n",
      "[129] Eval metrics for task 3 >> {'accuracy': 0.3865, 'loss': 0.00790284413099289, 'std': 0.1715, 'EER': -1}\n",
      "[130] Eval metrics for task 1 >> {'accuracy': 0.5589999999999999, 'loss': 0.022744587063789366, 'std': 0.02699999999999997, 'EER': -1}\n",
      "[130] Eval metrics for task 2 >> {'accuracy': 0.417, 'loss': 0.013597413659095765, 'std': 0.066, 'EER': -1}\n",
      "[130] Eval metrics for task 3 >> {'accuracy': 0.473, 'loss': 0.005681026518344879, 'std': 0.05700000000000002, 'EER': -1}\n",
      "[131] Eval metrics for task 1 >> {'accuracy': 0.579, 'loss': 0.02138169276714325, 'std': 0.02999999999999997, 'EER': -1}\n",
      "[131] Eval metrics for task 2 >> {'accuracy': 0.427, 'loss': 0.013249614596366883, 'std': 0.05299999999999999, 'EER': -1}\n",
      "[131] Eval metrics for task 3 >> {'accuracy': 0.4525, 'loss': 0.006093631446361542, 'std': 0.0605, 'EER': -1}\n",
      "[132] Eval metrics for task 1 >> {'accuracy': 0.5515, 'loss': 0.023503068447113036, 'std': 0.03249999999999997, 'EER': -1}\n",
      "[132] Eval metrics for task 2 >> {'accuracy': 0.402, 'loss': 0.013434187889099121, 'std': 0.06699999999999998, 'EER': -1}\n",
      "[132] Eval metrics for task 3 >> {'accuracy': 0.485, 'loss': 0.005691864490509033, 'std': 0.09099999999999997, 'EER': -1}\n",
      "[133] Eval metrics for task 1 >> {'accuracy': 0.5640000000000001, 'loss': 0.02280887162685394, 'std': 0.035999999999999976, 'EER': -1}\n",
      "[133] Eval metrics for task 2 >> {'accuracy': 0.422, 'loss': 0.013442877650260926, 'std': 0.056999999999999995, 'EER': -1}\n",
      "[133] Eval metrics for task 3 >> {'accuracy': 0.459, 'loss': 0.006048947334289551, 'std': 0.066, 'EER': -1}\n",
      "[134] Eval metrics for task 1 >> {'accuracy': 0.562, 'loss': 0.021634520769119262, 'std': 0.03199999999999997, 'EER': -1}\n",
      "[134] Eval metrics for task 2 >> {'accuracy': 0.4155, 'loss': 0.013436338901519775, 'std': 0.049500000000000016, 'EER': -1}\n",
      "[134] Eval metrics for task 3 >> {'accuracy': 0.471, 'loss': 0.005764430105686188, 'std': 0.061000000000000026, 'EER': -1}\n",
      "[135] Eval metrics for task 1 >> {'accuracy': 0.5585, 'loss': 0.02356697082519531, 'std': 0.04349999999999998, 'EER': -1}\n",
      "[135] Eval metrics for task 2 >> {'accuracy': 0.424, 'loss': 0.01338253092765808, 'std': 0.07100000000000001, 'EER': -1}\n",
      "[135] Eval metrics for task 3 >> {'accuracy': 0.4595, 'loss': 0.005989562094211578, 'std': 0.0685, 'EER': -1}\n",
      "[136] Eval metrics for task 1 >> {'accuracy': 0.5445, 'loss': 0.022558143258094788, 'std': 0.025499999999999967, 'EER': -1}\n",
      "[136] Eval metrics for task 2 >> {'accuracy': 0.40249999999999997, 'loss': 0.013167587637901306, 'std': 0.07449999999999998, 'EER': -1}\n",
      "[136] Eval metrics for task 3 >> {'accuracy': 0.495, 'loss': 0.005353336095809937, 'std': 0.08099999999999999, 'EER': -1}\n",
      "[137] Eval metrics for task 1 >> {'accuracy': 0.5595, 'loss': 0.02371585154533386, 'std': 0.03949999999999998, 'EER': -1}\n",
      "[137] Eval metrics for task 2 >> {'accuracy': 0.4085, 'loss': 0.01373720920085907, 'std': 0.05650000000000002, 'EER': -1}\n",
      "[137] Eval metrics for task 3 >> {'accuracy': 0.475, 'loss': 0.005730343759059906, 'std': 0.06800000000000003, 'EER': -1}\n",
      "[138] Eval metrics for task 1 >> {'accuracy': 0.5535, 'loss': 0.023618419647216796, 'std': 0.046499999999999986, 'EER': -1}\n",
      "[138] Eval metrics for task 2 >> {'accuracy': 0.4, 'loss': 0.013850270986557008, 'std': 0.067, 'EER': -1}\n",
      "[138] Eval metrics for task 3 >> {'accuracy': 0.488, 'loss': 0.005585327744483948, 'std': 0.07799999999999999, 'EER': -1}\n",
      "[139] Eval metrics for task 1 >> {'accuracy': 0.5565, 'loss': 0.020408761620521545, 'std': 0.02949999999999997, 'EER': -1}\n",
      "[139] Eval metrics for task 2 >> {'accuracy': 0.416, 'loss': 0.013061350345611572, 'std': 0.056999999999999995, 'EER': -1}\n",
      "[139] Eval metrics for task 3 >> {'accuracy': 0.47750000000000004, 'loss': 0.005634889245033264, 'std': 0.06750000000000003, 'EER': -1}\n",
      "[140] Eval metrics for task 1 >> {'accuracy': 0.5615, 'loss': 0.024104351997375487, 'std': 0.02849999999999997, 'EER': -1}\n",
      "[140] Eval metrics for task 2 >> {'accuracy': 0.414, 'loss': 0.01348971438407898, 'std': 0.061, 'EER': -1}\n",
      "[140] Eval metrics for task 3 >> {'accuracy': 0.4685, 'loss': 0.005823281288146973, 'std': 0.07050000000000001, 'EER': -1}\n",
      "[141] Eval metrics for task 1 >> {'accuracy': 0.5595, 'loss': 0.023665886640548705, 'std': 0.03249999999999997, 'EER': -1}\n",
      "[141] Eval metrics for task 2 >> {'accuracy': 0.4155, 'loss': 0.013391754984855652, 'std': 0.057499999999999996, 'EER': -1}\n",
      "[141] Eval metrics for task 3 >> {'accuracy': 0.465, 'loss': 0.005999478101730346, 'std': 0.07500000000000001, 'EER': -1}\n",
      "[142] Eval metrics for task 1 >> {'accuracy': 0.5660000000000001, 'loss': 0.02049815380573273, 'std': 0.01799999999999996, 'EER': -1}\n",
      "[142] Eval metrics for task 2 >> {'accuracy': 0.41600000000000004, 'loss': 0.013481162548065185, 'std': 0.049000000000000016, 'EER': -1}\n",
      "[142] Eval metrics for task 3 >> {'accuracy': 0.467, 'loss': 0.005896969258785248, 'std': 0.07, 'EER': -1}\n",
      "[143] Eval metrics for task 1 >> {'accuracy': 0.558, 'loss': 0.022766780376434325, 'std': 0.019999999999999962, 'EER': -1}\n",
      "[143] Eval metrics for task 2 >> {'accuracy': 0.4095, 'loss': 0.013481410145759582, 'std': 0.0595, 'EER': -1}\n",
      "[143] Eval metrics for task 3 >> {'accuracy': 0.47600000000000003, 'loss': 0.005797428667545319, 'std': 0.07800000000000001, 'EER': -1}\n",
      "[144] Eval metrics for task 1 >> {'accuracy': 0.5449999999999999, 'loss': 0.026330054521560668, 'std': 0.04899999999999999, 'EER': -1}\n",
      "[144] Eval metrics for task 2 >> {'accuracy': 0.3955, 'loss': 0.0137312833070755, 'std': 0.07250000000000001, 'EER': -1}\n",
      "[144] Eval metrics for task 3 >> {'accuracy': 0.493, 'loss': 0.005478063464164734, 'std': 0.086, 'EER': -1}\n",
      "[145] Eval metrics for task 1 >> {'accuracy': 0.5589999999999999, 'loss': 0.022342954635620117, 'std': 0.035999999999999976, 'EER': -1}\n",
      "[145] Eval metrics for task 2 >> {'accuracy': 0.40800000000000003, 'loss': 0.013590502381324768, 'std': 0.07399999999999998, 'EER': -1}\n",
      "[145] Eval metrics for task 3 >> {'accuracy': 0.47900000000000004, 'loss': 0.005659909248352051, 'std': 0.07400000000000001, 'EER': -1}\n",
      "[146] Eval metrics for task 1 >> {'accuracy': 0.5549999999999999, 'loss': 0.026102258205413818, 'std': 0.03699999999999998, 'EER': -1}\n",
      "[146] Eval metrics for task 2 >> {'accuracy': 0.39, 'loss': 0.014262404561042786, 'std': 0.07500000000000001, 'EER': -1}\n",
      "[146] Eval metrics for task 3 >> {'accuracy': 0.503, 'loss': 0.0053680892586708065, 'std': 0.07499999999999998, 'EER': -1}\n",
      "[147] Eval metrics for task 1 >> {'accuracy': 0.5515, 'loss': 0.021930760860443117, 'std': 0.033499999999999974, 'EER': -1}\n",
      "[147] Eval metrics for task 2 >> {'accuracy': 0.405, 'loss': 0.013288630723953247, 'std': 0.05700000000000002, 'EER': -1}\n",
      "[147] Eval metrics for task 3 >> {'accuracy': 0.48650000000000004, 'loss': 0.005552485823631287, 'std': 0.06850000000000003, 'EER': -1}\n",
      "[148] Eval metrics for task 1 >> {'accuracy': 0.563, 'loss': 0.02048258101940155, 'std': 0.022999999999999965, 'EER': -1}\n",
      "[148] Eval metrics for task 2 >> {'accuracy': 0.42, 'loss': 0.013137691259384155, 'std': 0.05399999999999999, 'EER': -1}\n",
      "[148] Eval metrics for task 3 >> {'accuracy': 0.4665, 'loss': 0.005829135715961456, 'std': 0.0665, 'EER': -1}\n",
      "[149] Eval metrics for task 1 >> {'accuracy': 0.5740000000000001, 'loss': 0.020877939462661744, 'std': 0.035999999999999976, 'EER': -1}\n",
      "[149] Eval metrics for task 2 >> {'accuracy': 0.4275, 'loss': 0.01326684582233429, 'std': 0.056499999999999995, 'EER': -1}\n",
      "[149] Eval metrics for task 3 >> {'accuracy': 0.45, 'loss': 0.006183403611183166, 'std': 0.059, 'EER': -1}\n",
      "[150] Eval metrics for task 1 >> {'accuracy': 0.558, 'loss': 0.025910812854766846, 'std': 0.04499999999999999, 'EER': -1}\n",
      "[150] Eval metrics for task 2 >> {'accuracy': 0.4105, 'loss': 0.013710277080535889, 'std': 0.05350000000000002, 'EER': -1}\n",
      "[150] Eval metrics for task 3 >> {'accuracy': 0.47650000000000003, 'loss': 0.005750355541706085, 'std': 0.06450000000000003, 'EER': -1}\n",
      "training_task_end\n",
      "---------------------------- Task 4 -----------------------\n",
      "[151] Eval metrics for task 1 >> {'accuracy': 0.513, 'loss': 0.01267872440814972, 'std': 0.10699999999999998, 'EER': -1}\n",
      "[151] Eval metrics for task 2 >> {'accuracy': 0.308, 'loss': 0.011355350255966186, 'std': 0.055999999999999994, 'EER': -1}\n",
      "[151] Eval metrics for task 3 >> {'accuracy': 0.05, 'loss': 0.010085135221481323, 'std': 0.05, 'EER': -1}\n",
      "[151] Eval metrics for task 4 >> {'accuracy': 0.4615, 'loss': 0.0053989292383193966, 'std': 0.05350000000000002, 'EER': -1}\n",
      "[152] Eval metrics for task 1 >> {'accuracy': 0.34650000000000003, 'loss': 0.018722876429557802, 'std': 0.0995, 'EER': -1}\n",
      "[152] Eval metrics for task 2 >> {'accuracy': 0.1835, 'loss': 0.020338279008865357, 'std': 0.0835, 'EER': -1}\n",
      "[152] Eval metrics for task 3 >> {'accuracy': 0.405, 'loss': 0.00726857703924179, 'std': 0.097, 'EER': -1}\n",
      "[152] Eval metrics for task 4 >> {'accuracy': 0.654, 'loss': 0.003746698468923569, 'std': 0.031000000000000028, 'EER': -1}\n",
      "[153] Eval metrics for task 1 >> {'accuracy': 0.3275, 'loss': 0.02192178773880005, 'std': 0.22050000000000003, 'EER': -1}\n",
      "[153] Eval metrics for task 2 >> {'accuracy': 0.1845, 'loss': 0.025559099674224855, 'std': 0.0345, 'EER': -1}\n",
      "[153] Eval metrics for task 3 >> {'accuracy': 0.4605, 'loss': 0.007665787577629089, 'std': 0.12249999999999997, 'EER': -1}\n",
      "[153] Eval metrics for task 4 >> {'accuracy': 0.7075, 'loss': 0.0033000150322914125, 'std': 0.09350000000000003, 'EER': -1}\n",
      "[154] Eval metrics for task 1 >> {'accuracy': 0.339, 'loss': 0.019803112268447876, 'std': 0.105, 'EER': -1}\n",
      "[154] Eval metrics for task 2 >> {'accuracy': 0.1815, 'loss': 0.0251358060836792, 'std': 0.0765, 'EER': -1}\n",
      "[154] Eval metrics for task 3 >> {'accuracy': 0.39549999999999996, 'loss': 0.009225812077522278, 'std': 0.0315, 'EER': -1}\n",
      "[154] Eval metrics for task 4 >> {'accuracy': 0.745, 'loss': 0.0027109859585762023, 'std': 0.020000000000000018, 'EER': -1}\n",
      "[155] Eval metrics for task 1 >> {'accuracy': 0.3525, 'loss': 0.018483241558074952, 'std': 0.12849999999999998, 'EER': -1}\n",
      "[155] Eval metrics for task 2 >> {'accuracy': 0.086, 'loss': 0.030670347452163696, 'std': 0.016999999999999994, 'EER': -1}\n",
      "[155] Eval metrics for task 3 >> {'accuracy': 0.2875, 'loss': 0.011847745418548584, 'std': 0.12649999999999997, 'EER': -1}\n",
      "[155] Eval metrics for task 4 >> {'accuracy': 0.867, 'loss': 0.0015510065108537674, 'std': 0.014000000000000012, 'EER': -1}\n",
      "[156] Eval metrics for task 1 >> {'accuracy': 0.368, 'loss': 0.019332213878631592, 'std': 0.10499999999999998, 'EER': -1}\n",
      "[156] Eval metrics for task 2 >> {'accuracy': 0.161, 'loss': 0.02757068967819214, 'std': 0.0030000000000000027, 'EER': -1}\n",
      "[156] Eval metrics for task 3 >> {'accuracy': 0.456, 'loss': 0.008643632113933564, 'std': 0.065, 'EER': -1}\n",
      "[156] Eval metrics for task 4 >> {'accuracy': 0.7755000000000001, 'loss': 0.0024453749656677248, 'std': 0.025500000000000023, 'EER': -1}\n",
      "[157] Eval metrics for task 1 >> {'accuracy': 0.4415, 'loss': 0.01742151403427124, 'std': 0.05149999999999999, 'EER': -1}\n",
      "[157] Eval metrics for task 2 >> {'accuracy': 0.179, 'loss': 0.029145316123962404, 'std': 0.10499999999999998, 'EER': -1}\n",
      "[157] Eval metrics for task 3 >> {'accuracy': 0.4175, 'loss': 0.010513478398323058, 'std': 0.01050000000000001, 'EER': -1}\n",
      "[157] Eval metrics for task 4 >> {'accuracy': 0.6950000000000001, 'loss': 0.003353737086057663, 'std': 0.07500000000000001, 'EER': -1}\n",
      "[158] Eval metrics for task 1 >> {'accuracy': 0.4475, 'loss': 0.017403985500335693, 'std': 0.058499999999999996, 'EER': -1}\n",
      "[158] Eval metrics for task 2 >> {'accuracy': 0.16649999999999998, 'loss': 0.02808978247642517, 'std': 0.0725, 'EER': -1}\n",
      "[158] Eval metrics for task 3 >> {'accuracy': 0.47050000000000003, 'loss': 0.009273062348365784, 'std': 0.07350000000000001, 'EER': -1}\n",
      "[158] Eval metrics for task 4 >> {'accuracy': 0.7335, 'loss': 0.002955249220132828, 'std': 0.05149999999999999, 'EER': -1}\n",
      "[159] Eval metrics for task 1 >> {'accuracy': 0.395, 'loss': 0.020534822463989258, 'std': 0.15900000000000003, 'EER': -1}\n",
      "[159] Eval metrics for task 2 >> {'accuracy': 0.1875, 'loss': 0.02798665237426758, 'std': 0.04250000000000001, 'EER': -1}\n",
      "[159] Eval metrics for task 3 >> {'accuracy': 0.4375, 'loss': 0.009982856035232544, 'std': 0.0995, 'EER': -1}\n",
      "[159] Eval metrics for task 4 >> {'accuracy': 0.7595000000000001, 'loss': 0.0027314314246177675, 'std': 0.025500000000000023, 'EER': -1}\n",
      "[160] Eval metrics for task 1 >> {'accuracy': 0.47000000000000003, 'loss': 0.016989896416664124, 'std': 0.07, 'EER': -1}\n",
      "[160] Eval metrics for task 2 >> {'accuracy': 0.16649999999999998, 'loss': 0.030150601625442506, 'std': 0.0465, 'EER': -1}\n",
      "[160] Eval metrics for task 3 >> {'accuracy': 0.389, 'loss': 0.01165212082862854, 'std': 0.056999999999999995, 'EER': -1}\n",
      "[160] Eval metrics for task 4 >> {'accuracy': 0.6765000000000001, 'loss': 0.0035720202624797822, 'std': 0.004500000000000004, 'EER': -1}\n",
      "[161] Eval metrics for task 1 >> {'accuracy': 0.47700000000000004, 'loss': 0.01907242274284363, 'std': 0.07800000000000001, 'EER': -1}\n",
      "[161] Eval metrics for task 2 >> {'accuracy': 0.163, 'loss': 0.029964856386184693, 'std': 0.027999999999999997, 'EER': -1}\n",
      "[161] Eval metrics for task 3 >> {'accuracy': 0.45199999999999996, 'loss': 0.01045049774646759, 'std': 0.031, 'EER': -1}\n",
      "[161] Eval metrics for task 4 >> {'accuracy': 0.7330000000000001, 'loss': 0.0028538884818553926, 'std': 0.064, 'EER': -1}\n",
      "[162] Eval metrics for task 1 >> {'accuracy': 0.40700000000000003, 'loss': 0.019995518445968627, 'std': 0.026999999999999996, 'EER': -1}\n",
      "[162] Eval metrics for task 2 >> {'accuracy': 0.179, 'loss': 0.029460207462310792, 'std': 0.06799999999999999, 'EER': -1}\n",
      "[162] Eval metrics for task 3 >> {'accuracy': 0.361, 'loss': 0.012913211703300476, 'std': 0.01999999999999999, 'EER': -1}\n",
      "[162] Eval metrics for task 4 >> {'accuracy': 0.646, 'loss': 0.0038518418967723846, 'std': 0.015000000000000013, 'EER': -1}\n",
      "[163] Eval metrics for task 1 >> {'accuracy': 0.4495, 'loss': 0.018425345182418822, 'std': 0.09850000000000003, 'EER': -1}\n",
      "[163] Eval metrics for task 2 >> {'accuracy': 0.1575, 'loss': 0.030877524137496948, 'std': 0.04550000000000001, 'EER': -1}\n",
      "[163] Eval metrics for task 3 >> {'accuracy': 0.46799999999999997, 'loss': 0.010445069670677185, 'std': 0.10799999999999998, 'EER': -1}\n",
      "[163] Eval metrics for task 4 >> {'accuracy': 0.7435, 'loss': 0.0028013947606086733, 'std': 0.029500000000000026, 'EER': -1}\n",
      "[164] Eval metrics for task 1 >> {'accuracy': 0.3755, 'loss': 0.017970548868179323, 'std': 0.10849999999999999, 'EER': -1}\n",
      "[164] Eval metrics for task 2 >> {'accuracy': 0.1535, 'loss': 0.03053410744667053, 'std': 0.0345, 'EER': -1}\n",
      "[164] Eval metrics for task 3 >> {'accuracy': 0.39149999999999996, 'loss': 0.011951958060264587, 'std': 0.02149999999999999, 'EER': -1}\n",
      "[164] Eval metrics for task 4 >> {'accuracy': 0.768, 'loss': 0.0025598061084747313, 'std': 0.006000000000000005, 'EER': -1}\n",
      "[165] Eval metrics for task 1 >> {'accuracy': 0.4855, 'loss': 0.01621513068675995, 'std': 0.09149999999999997, 'EER': -1}\n",
      "[165] Eval metrics for task 2 >> {'accuracy': 0.1785, 'loss': 0.030776896238327026, 'std': 0.026499999999999996, 'EER': -1}\n",
      "[165] Eval metrics for task 3 >> {'accuracy': 0.385, 'loss': 0.012619721055030822, 'std': 0.04899999999999999, 'EER': -1}\n",
      "[165] Eval metrics for task 4 >> {'accuracy': 0.7464999999999999, 'loss': 0.0027985009253025054, 'std': 0.03250000000000003, 'EER': -1}\n",
      "[166] Eval metrics for task 1 >> {'accuracy': 0.4135, 'loss': 0.019105885982513428, 'std': 0.0895, 'EER': -1}\n",
      "[166] Eval metrics for task 2 >> {'accuracy': 0.20900000000000002, 'loss': 0.02974512028694153, 'std': 0.07200000000000001, 'EER': -1}\n",
      "[166] Eval metrics for task 3 >> {'accuracy': 0.4545, 'loss': 0.01039139699935913, 'std': 0.02049999999999999, 'EER': -1}\n",
      "[166] Eval metrics for task 4 >> {'accuracy': 0.7475, 'loss': 0.0027445283830165863, 'std': 0.03150000000000003, 'EER': -1}\n",
      "[167] Eval metrics for task 1 >> {'accuracy': 0.438, 'loss': 0.017020597577095033, 'std': 0.044999999999999984, 'EER': -1}\n",
      "[167] Eval metrics for task 2 >> {'accuracy': 0.181, 'loss': 0.02955753493309021, 'std': 0.07100000000000001, 'EER': -1}\n",
      "[167] Eval metrics for task 3 >> {'accuracy': 0.47150000000000003, 'loss': 0.010666625380516052, 'std': 0.01949999999999999, 'EER': -1}\n",
      "[167] Eval metrics for task 4 >> {'accuracy': 0.6935, 'loss': 0.0036263047456741334, 'std': 0.00649999999999995, 'EER': -1}\n",
      "[168] Eval metrics for task 1 >> {'accuracy': 0.402, 'loss': 0.018334299325942993, 'std': 0.07899999999999999, 'EER': -1}\n",
      "[168] Eval metrics for task 2 >> {'accuracy': 0.1925, 'loss': 0.02866795015335083, 'std': 0.0495, 'EER': -1}\n",
      "[168] Eval metrics for task 3 >> {'accuracy': 0.43, 'loss': 0.011087787985801697, 'std': 0.015000000000000013, 'EER': -1}\n",
      "[168] Eval metrics for task 4 >> {'accuracy': 0.7375, 'loss': 0.0031280449628829955, 'std': 0.049500000000000044, 'EER': -1}\n",
      "[169] Eval metrics for task 1 >> {'accuracy': 0.41700000000000004, 'loss': 0.018583495259284974, 'std': 0.089, 'EER': -1}\n",
      "[169] Eval metrics for task 2 >> {'accuracy': 0.1985, 'loss': 0.029067867040634156, 'std': 0.03949999999999999, 'EER': -1}\n",
      "[169] Eval metrics for task 3 >> {'accuracy': 0.427, 'loss': 0.01113384997844696, 'std': 0.008000000000000007, 'EER': -1}\n",
      "[169] Eval metrics for task 4 >> {'accuracy': 0.748, 'loss': 0.0027505646646022795, 'std': 0.006000000000000005, 'EER': -1}\n",
      "[170] Eval metrics for task 1 >> {'accuracy': 0.4455, 'loss': 0.01856038212776184, 'std': 0.04749999999999999, 'EER': -1}\n",
      "[170] Eval metrics for task 2 >> {'accuracy': 0.201, 'loss': 0.029339380025863646, 'std': 0.063, 'EER': -1}\n",
      "[170] Eval metrics for task 3 >> {'accuracy': 0.429, 'loss': 0.011581179022789002, 'std': 0.0010000000000000009, 'EER': -1}\n",
      "[170] Eval metrics for task 4 >> {'accuracy': 0.7004999999999999, 'loss': 0.003286584436893463, 'std': 0.003500000000000003, 'EER': -1}\n",
      "[171] Eval metrics for task 1 >> {'accuracy': 0.3585, 'loss': 0.020706712484359742, 'std': 0.1185, 'EER': -1}\n",
      "[171] Eval metrics for task 2 >> {'accuracy': 0.2115, 'loss': 0.029569763898849487, 'std': 0.0925, 'EER': -1}\n",
      "[171] Eval metrics for task 3 >> {'accuracy': 0.388, 'loss': 0.012038477778434753, 'std': 0.04799999999999999, 'EER': -1}\n",
      "[171] Eval metrics for task 4 >> {'accuracy': 0.8095, 'loss': 0.0022095357179641724, 'std': 0.011499999999999955, 'EER': -1}\n",
      "[172] Eval metrics for task 1 >> {'accuracy': 0.4515, 'loss': 0.01904680848121643, 'std': 0.09650000000000003, 'EER': -1}\n",
      "[172] Eval metrics for task 2 >> {'accuracy': 0.168, 'loss': 0.031738368988037106, 'std': 0.056, 'EER': -1}\n",
      "[172] Eval metrics for task 3 >> {'accuracy': 0.43, 'loss': 0.010944074869155884, 'std': 0.013000000000000012, 'EER': -1}\n",
      "[172] Eval metrics for task 4 >> {'accuracy': 0.7945, 'loss': 0.002364856719970703, 'std': 0.03949999999999998, 'EER': -1}\n",
      "[173] Eval metrics for task 1 >> {'accuracy': 0.474, 'loss': 0.019015775203704833, 'std': 0.017999999999999988, 'EER': -1}\n",
      "[173] Eval metrics for task 2 >> {'accuracy': 0.178, 'loss': 0.033113887786865234, 'std': 0.08700000000000001, 'EER': -1}\n",
      "[173] Eval metrics for task 3 >> {'accuracy': 0.4165, 'loss': 0.012952742099761962, 'std': 0.07449999999999998, 'EER': -1}\n",
      "[173] Eval metrics for task 4 >> {'accuracy': 0.736, 'loss': 0.003083337843418121, 'std': 0.03400000000000003, 'EER': -1}\n",
      "[174] Eval metrics for task 1 >> {'accuracy': 0.4545, 'loss': 0.01965694177150726, 'std': 0.09850000000000003, 'EER': -1}\n",
      "[174] Eval metrics for task 2 >> {'accuracy': 0.207, 'loss': 0.03019731855392456, 'std': 0.092, 'EER': -1}\n",
      "[174] Eval metrics for task 3 >> {'accuracy': 0.435, 'loss': 0.011784278512001038, 'std': 0.08300000000000002, 'EER': -1}\n",
      "[174] Eval metrics for task 4 >> {'accuracy': 0.781, 'loss': 0.002661280184984207, 'std': 0.019000000000000017, 'EER': -1}\n",
      "[175] Eval metrics for task 1 >> {'accuracy': 0.4245, 'loss': 0.021435368537902833, 'std': 0.024499999999999994, 'EER': -1}\n",
      "[175] Eval metrics for task 2 >> {'accuracy': 0.1585, 'loss': 0.03409387969970703, 'std': 0.08349999999999999, 'EER': -1}\n",
      "[175] Eval metrics for task 3 >> {'accuracy': 0.359, 'loss': 0.014407686471939086, 'std': 0.04400000000000001, 'EER': -1}\n",
      "[175] Eval metrics for task 4 >> {'accuracy': 0.7785, 'loss': 0.002557427883148193, 'std': 0.05249999999999999, 'EER': -1}\n",
      "[176] Eval metrics for task 1 >> {'accuracy': 0.47250000000000003, 'loss': 0.01841633200645447, 'std': 0.007499999999999979, 'EER': -1}\n",
      "[176] Eval metrics for task 2 >> {'accuracy': 0.19749999999999998, 'loss': 0.032907042741775513, 'std': 0.09349999999999999, 'EER': -1}\n",
      "[176] Eval metrics for task 3 >> {'accuracy': 0.385, 'loss': 0.014130728125572204, 'std': 0.033, 'EER': -1}\n",
      "[176] Eval metrics for task 4 >> {'accuracy': 0.677, 'loss': 0.004235230654478073, 'std': 0.05299999999999999, 'EER': -1}\n",
      "[177] Eval metrics for task 1 >> {'accuracy': 0.4135, 'loss': 0.021333754062652588, 'std': 0.0645, 'EER': -1}\n",
      "[177] Eval metrics for task 2 >> {'accuracy': 0.238, 'loss': 0.0281918363571167, 'std': 0.04799999999999999, 'EER': -1}\n",
      "[177] Eval metrics for task 3 >> {'accuracy': 0.43, 'loss': 0.013753429889678955, 'std': 0.06, 'EER': -1}\n",
      "[177] Eval metrics for task 4 >> {'accuracy': 0.7304999999999999, 'loss': 0.003340904742479324, 'std': 0.03150000000000003, 'EER': -1}\n",
      "[178] Eval metrics for task 1 >> {'accuracy': 0.401, 'loss': 0.020668201446533203, 'std': 0.034, 'EER': -1}\n",
      "[178] Eval metrics for task 2 >> {'accuracy': 0.21, 'loss': 0.028785873174667357, 'std': 0.07699999999999999, 'EER': -1}\n",
      "[178] Eval metrics for task 3 >> {'accuracy': 0.46699999999999997, 'loss': 0.011657428622245789, 'std': 0.04000000000000001, 'EER': -1}\n",
      "[178] Eval metrics for task 4 >> {'accuracy': 0.6539999999999999, 'loss': 0.00414139974117279, 'std': 0.034999999999999976, 'EER': -1}\n",
      "[179] Eval metrics for task 1 >> {'accuracy': 0.4625, 'loss': 0.016066664099693297, 'std': 0.1445, 'EER': -1}\n",
      "[179] Eval metrics for task 2 >> {'accuracy': 0.158, 'loss': 0.031573286294937136, 'std': 0.08099999999999999, 'EER': -1}\n",
      "[179] Eval metrics for task 3 >> {'accuracy': 0.337, 'loss': 0.014278127551078797, 'std': 0.12100000000000001, 'EER': -1}\n",
      "[179] Eval metrics for task 4 >> {'accuracy': 0.8445, 'loss': 0.0017447326630353928, 'std': 0.014500000000000013, 'EER': -1}\n",
      "[180] Eval metrics for task 1 >> {'accuracy': 0.35500000000000004, 'loss': 0.02128302788734436, 'std': 0.196, 'EER': -1}\n",
      "[180] Eval metrics for task 2 >> {'accuracy': 0.07100000000000001, 'loss': 0.0390856294631958, 'std': 0.024, 'EER': -1}\n",
      "[180] Eval metrics for task 3 >> {'accuracy': 0.1885, 'loss': 0.018096645355224608, 'std': 0.04050000000000001, 'EER': -1}\n",
      "[180] Eval metrics for task 4 >> {'accuracy': 0.9255, 'loss': 0.0008820443227887154, 'std': 0.01849999999999996, 'EER': -1}\n",
      "[181] Eval metrics for task 1 >> {'accuracy': 0.34500000000000003, 'loss': 0.02161409616470337, 'std': 0.21000000000000002, 'EER': -1}\n",
      "[181] Eval metrics for task 2 >> {'accuracy': 0.0675, 'loss': 0.038692808628082276, 'std': 0.019499999999999997, 'EER': -1}\n",
      "[181] Eval metrics for task 3 >> {'accuracy': 0.2005, 'loss': 0.016956857800483702, 'std': 0.0295, 'EER': -1}\n",
      "[181] Eval metrics for task 4 >> {'accuracy': 0.933, 'loss': 0.0008299435563385487, 'std': 0.01599999999999996, 'EER': -1}\n",
      "[182] Eval metrics for task 1 >> {'accuracy': 0.3365, 'loss': 0.0224060435295105, 'std': 0.20650000000000002, 'EER': -1}\n",
      "[182] Eval metrics for task 2 >> {'accuracy': 0.069, 'loss': 0.038960782051086426, 'std': 0.018999999999999996, 'EER': -1}\n",
      "[182] Eval metrics for task 3 >> {'accuracy': 0.186, 'loss': 0.01745853590965271, 'std': 0.026999999999999996, 'EER': -1}\n",
      "[182] Eval metrics for task 4 >> {'accuracy': 0.9375, 'loss': 0.0008187762275338173, 'std': 0.01849999999999996, 'EER': -1}\n",
      "[183] Eval metrics for task 1 >> {'accuracy': 0.3595, 'loss': 0.021413197755813598, 'std': 0.21949999999999997, 'EER': -1}\n",
      "[183] Eval metrics for task 2 >> {'accuracy': 0.0765, 'loss': 0.03776807641983032, 'std': 0.023500000000000004, 'EER': -1}\n",
      "[183] Eval metrics for task 3 >> {'accuracy': 0.20600000000000002, 'loss': 0.016521086931228637, 'std': 0.02800000000000001, 'EER': -1}\n",
      "[183] Eval metrics for task 4 >> {'accuracy': 0.9335, 'loss': 0.0008669554740190506, 'std': 0.023499999999999965, 'EER': -1}\n",
      "[184] Eval metrics for task 1 >> {'accuracy': 0.35050000000000003, 'loss': 0.021289530277252198, 'std': 0.1915, 'EER': -1}\n",
      "[184] Eval metrics for task 2 >> {'accuracy': 0.07150000000000001, 'loss': 0.03848278284072876, 'std': 0.0235, 'EER': -1}\n",
      "[184] Eval metrics for task 3 >> {'accuracy': 0.1995, 'loss': 0.017425741672515867, 'std': 0.02650000000000001, 'EER': -1}\n",
      "[184] Eval metrics for task 4 >> {'accuracy': 0.9255, 'loss': 0.0008787189498543739, 'std': 0.01649999999999996, 'EER': -1}\n",
      "[185] Eval metrics for task 1 >> {'accuracy': 0.34850000000000003, 'loss': 0.021714154958724977, 'std': 0.21250000000000002, 'EER': -1}\n",
      "[185] Eval metrics for task 2 >> {'accuracy': 0.07400000000000001, 'loss': 0.038524497032165525, 'std': 0.027000000000000003, 'EER': -1}\n",
      "[185] Eval metrics for task 3 >> {'accuracy': 0.2005, 'loss': 0.017003209590911866, 'std': 0.0305, 'EER': -1}\n",
      "[185] Eval metrics for task 4 >> {'accuracy': 0.9339999999999999, 'loss': 0.0008417708054184914, 'std': 0.01799999999999996, 'EER': -1}\n",
      "[186] Eval metrics for task 1 >> {'accuracy': 0.355, 'loss': 0.02138420581817627, 'std': 0.20999999999999996, 'EER': -1}\n",
      "[186] Eval metrics for task 2 >> {'accuracy': 0.076, 'loss': 0.038015167236328126, 'std': 0.023000000000000003, 'EER': -1}\n",
      "[186] Eval metrics for task 3 >> {'accuracy': 0.20350000000000001, 'loss': 0.016966337084770203, 'std': 0.03349999999999999, 'EER': -1}\n",
      "[186] Eval metrics for task 4 >> {'accuracy': 0.9285, 'loss': 0.0008665960654616355, 'std': 0.019499999999999962, 'EER': -1}\n",
      "[187] Eval metrics for task 1 >> {'accuracy': 0.34650000000000003, 'loss': 0.021506097078323363, 'std': 0.20350000000000004, 'EER': -1}\n",
      "[187] Eval metrics for task 2 >> {'accuracy': 0.07250000000000001, 'loss': 0.038383114337921145, 'std': 0.025500000000000002, 'EER': -1}\n",
      "[187] Eval metrics for task 3 >> {'accuracy': 0.1895, 'loss': 0.017499776363372802, 'std': 0.0335, 'EER': -1}\n",
      "[187] Eval metrics for task 4 >> {'accuracy': 0.929, 'loss': 0.0008412892371416091, 'std': 0.01699999999999996, 'EER': -1}\n",
      "[188] Eval metrics for task 1 >> {'accuracy': 0.333, 'loss': 0.02238491678237915, 'std': 0.2, 'EER': -1}\n",
      "[188] Eval metrics for task 2 >> {'accuracy': 0.0625, 'loss': 0.04051322841644287, 'std': 0.028499999999999998, 'EER': -1}\n",
      "[188] Eval metrics for task 3 >> {'accuracy': 0.1645, 'loss': 0.018960595607757567, 'std': 0.024499999999999994, 'EER': -1}\n",
      "[188] Eval metrics for task 4 >> {'accuracy': 0.9405, 'loss': 0.0007745148167014122, 'std': 0.011499999999999955, 'EER': -1}\n",
      "[189] Eval metrics for task 1 >> {'accuracy': 0.34800000000000003, 'loss': 0.021654311180114745, 'std': 0.21000000000000002, 'EER': -1}\n",
      "[189] Eval metrics for task 2 >> {'accuracy': 0.07300000000000001, 'loss': 0.03838069009780884, 'std': 0.025, 'EER': -1}\n",
      "[189] Eval metrics for task 3 >> {'accuracy': 0.1955, 'loss': 0.017014557242393494, 'std': 0.026499999999999996, 'EER': -1}\n",
      "[189] Eval metrics for task 4 >> {'accuracy': 0.9355, 'loss': 0.0008321454152464867, 'std': 0.019499999999999962, 'EER': -1}\n",
      "[190] Eval metrics for task 1 >> {'accuracy': 0.337, 'loss': 0.022174232482910155, 'std': 0.20900000000000002, 'EER': -1}\n",
      "[190] Eval metrics for task 2 >> {'accuracy': 0.069, 'loss': 0.03878693151473999, 'std': 0.024, 'EER': -1}\n",
      "[190] Eval metrics for task 3 >> {'accuracy': 0.197, 'loss': 0.016985229015350344, 'std': 0.034, 'EER': -1}\n",
      "[190] Eval metrics for task 4 >> {'accuracy': 0.937, 'loss': 0.0008215380907058715, 'std': 0.01599999999999996, 'EER': -1}\n",
      "[191] Eval metrics for task 1 >> {'accuracy': 0.3415, 'loss': 0.0218960816860199, 'std': 0.20550000000000002, 'EER': -1}\n",
      "[191] Eval metrics for task 2 >> {'accuracy': 0.0685, 'loss': 0.03877352809906006, 'std': 0.0225, 'EER': -1}\n",
      "[191] Eval metrics for task 3 >> {'accuracy': 0.192, 'loss': 0.017208537340164184, 'std': 0.031, 'EER': -1}\n",
      "[191] Eval metrics for task 4 >> {'accuracy': 0.9345, 'loss': 0.0008273622319102288, 'std': 0.020499999999999963, 'EER': -1}\n",
      "[192] Eval metrics for task 1 >> {'accuracy': 0.3395, 'loss': 0.022489365577697755, 'std': 0.21350000000000002, 'EER': -1}\n",
      "[192] Eval metrics for task 2 >> {'accuracy': 0.062, 'loss': 0.040305941104888915, 'std': 0.026999999999999996, 'EER': -1}\n",
      "[192] Eval metrics for task 3 >> {'accuracy': 0.1795, 'loss': 0.017896506786346435, 'std': 0.023500000000000007, 'EER': -1}\n",
      "[192] Eval metrics for task 4 >> {'accuracy': 0.9395, 'loss': 0.0007670322954654693, 'std': 0.01649999999999996, 'EER': -1}\n",
      "[193] Eval metrics for task 1 >> {'accuracy': 0.35050000000000003, 'loss': 0.021275508880615236, 'std': 0.19450000000000003, 'EER': -1}\n",
      "[193] Eval metrics for task 2 >> {'accuracy': 0.07350000000000001, 'loss': 0.03818937158584595, 'std': 0.0235, 'EER': -1}\n",
      "[193] Eval metrics for task 3 >> {'accuracy': 0.198, 'loss': 0.017413588047027587, 'std': 0.039999999999999994, 'EER': -1}\n",
      "[193] Eval metrics for task 4 >> {'accuracy': 0.9235, 'loss': 0.0008751485720276832, 'std': 0.015499999999999958, 'EER': -1}\n",
      "[194] Eval metrics for task 1 >> {'accuracy': 0.341, 'loss': 0.021624502658843994, 'std': 0.2, 'EER': -1}\n",
      "[194] Eval metrics for task 2 >> {'accuracy': 0.07250000000000001, 'loss': 0.03827248048782349, 'std': 0.0235, 'EER': -1}\n",
      "[194] Eval metrics for task 3 >> {'accuracy': 0.194, 'loss': 0.017229885816574097, 'std': 0.033, 'EER': -1}\n",
      "[194] Eval metrics for task 4 >> {'accuracy': 0.9325, 'loss': 0.0008373546749353409, 'std': 0.019499999999999962, 'EER': -1}\n",
      "[195] Eval metrics for task 1 >> {'accuracy': 0.35550000000000004, 'loss': 0.020880720138549805, 'std': 0.18450000000000003, 'EER': -1}\n",
      "[195] Eval metrics for task 2 >> {'accuracy': 0.082, 'loss': 0.03772023105621338, 'std': 0.026, 'EER': -1}\n",
      "[195] Eval metrics for task 3 >> {'accuracy': 0.202, 'loss': 0.017259910345077515, 'std': 0.02500000000000001, 'EER': -1}\n",
      "[195] Eval metrics for task 4 >> {'accuracy': 0.9215, 'loss': 0.0009260993152856827, 'std': 0.019499999999999962, 'EER': -1}\n",
      "[196] Eval metrics for task 1 >> {'accuracy': 0.34850000000000003, 'loss': 0.021309646129608156, 'std': 0.1965, 'EER': -1}\n",
      "[196] Eval metrics for task 2 >> {'accuracy': 0.07250000000000001, 'loss': 0.03856108713150024, 'std': 0.0245, 'EER': -1}\n",
      "[196] Eval metrics for task 3 >> {'accuracy': 0.191, 'loss': 0.01776118779182434, 'std': 0.035, 'EER': -1}\n",
      "[196] Eval metrics for task 4 >> {'accuracy': 0.9265000000000001, 'loss': 0.0008669105544686317, 'std': 0.009500000000000008, 'EER': -1}\n",
      "[197] Eval metrics for task 1 >> {'accuracy': 0.3415, 'loss': 0.02141746401786804, 'std': 0.1925, 'EER': -1}\n",
      "[197] Eval metrics for task 2 >> {'accuracy': 0.0735, 'loss': 0.03793882513046264, 'std': 0.022500000000000003, 'EER': -1}\n",
      "[197] Eval metrics for task 3 >> {'accuracy': 0.1945, 'loss': 0.01720628046989441, 'std': 0.0315, 'EER': -1}\n",
      "[197] Eval metrics for task 4 >> {'accuracy': 0.9295, 'loss': 0.0008497077822685242, 'std': 0.01649999999999996, 'EER': -1}\n",
      "[198] Eval metrics for task 1 >> {'accuracy': 0.359, 'loss': 0.02142599630355835, 'std': 0.209, 'EER': -1}\n",
      "[198] Eval metrics for task 2 >> {'accuracy': 0.07100000000000001, 'loss': 0.0389043083190918, 'std': 0.026000000000000002, 'EER': -1}\n",
      "[198] Eval metrics for task 3 >> {'accuracy': 0.2005, 'loss': 0.017094053506851198, 'std': 0.021500000000000005, 'EER': -1}\n",
      "[198] Eval metrics for task 4 >> {'accuracy': 0.9315, 'loss': 0.0008654251769185066, 'std': 0.022499999999999964, 'EER': -1}\n",
      "[199] Eval metrics for task 1 >> {'accuracy': 0.3325, 'loss': 0.02239938759803772, 'std': 0.20950000000000002, 'EER': -1}\n",
      "[199] Eval metrics for task 2 >> {'accuracy': 0.0675, 'loss': 0.03936917543411255, 'std': 0.0275, 'EER': -1}\n",
      "[199] Eval metrics for task 3 >> {'accuracy': 0.177, 'loss': 0.01785351872444153, 'std': 0.028999999999999998, 'EER': -1}\n",
      "[199] Eval metrics for task 4 >> {'accuracy': 0.9395, 'loss': 0.0007798144519329071, 'std': 0.01649999999999996, 'EER': -1}\n",
      "[200] Eval metrics for task 1 >> {'accuracy': 0.3335, 'loss': 0.02206836819648743, 'std': 0.1995, 'EER': -1}\n",
      "[200] Eval metrics for task 2 >> {'accuracy': 0.0695, 'loss': 0.038830464839935304, 'std': 0.025500000000000002, 'EER': -1}\n",
      "[200] Eval metrics for task 3 >> {'accuracy': 0.1825, 'loss': 0.01777704620361328, 'std': 0.027499999999999997, 'EER': -1}\n",
      "[200] Eval metrics for task 4 >> {'accuracy': 0.9355, 'loss': 0.0007994886413216591, 'std': 0.013499999999999956, 'EER': -1}\n",
      "training_task_end\n",
      "---------------------------- Task 5 -----------------------\n",
      "[201] Eval metrics for task 1 >> {'accuracy': 0.34099999999999997, 'loss': 0.011554725646972656, 'std': 0.033, 'EER': -1}\n",
      "[201] Eval metrics for task 2 >> {'accuracy': 0.1295, 'loss': 0.009829320430755616, 'std': 0.048499999999999995, 'EER': -1}\n",
      "[201] Eval metrics for task 3 >> {'accuracy': 0.0005, 'loss': 0.011565356969833374, 'std': 0.0005, 'EER': -1}\n",
      "[201] Eval metrics for task 4 >> {'accuracy': 0.0, 'loss': 0.011948758363723755, 'std': 0.0, 'EER': -1}\n",
      "[201] Eval metrics for task 5 >> {'accuracy': 0.5815, 'loss': 0.004779235720634461, 'std': 0.03849999999999998, 'EER': -1}\n",
      "[202] Eval metrics for task 1 >> {'accuracy': 0.33799999999999997, 'loss': 0.012270914435386658, 'std': 0.0069999999999999785, 'EER': -1}\n",
      "[202] Eval metrics for task 2 >> {'accuracy': 0.167, 'loss': 0.016632158637046816, 'std': 0.027999999999999997, 'EER': -1}\n",
      "[202] Eval metrics for task 3 >> {'accuracy': 0.2475, 'loss': 0.011661131262779236, 'std': 0.0775, 'EER': -1}\n",
      "[202] Eval metrics for task 4 >> {'accuracy': 0.119, 'loss': 0.007995501697063446, 'std': 0.11599999999999999, 'EER': -1}\n",
      "[202] Eval metrics for task 5 >> {'accuracy': 0.6955, 'loss': 0.004373791337013245, 'std': 0.09650000000000003, 'EER': -1}\n",
      "[203] Eval metrics for task 1 >> {'accuracy': 0.201, 'loss': 0.020084263324737547, 'std': 0.007999999999999993, 'EER': -1}\n",
      "[203] Eval metrics for task 2 >> {'accuracy': 0.2155, 'loss': 0.021682722091674805, 'std': 0.038500000000000006, 'EER': -1}\n",
      "[203] Eval metrics for task 3 >> {'accuracy': 0.2915, 'loss': 0.01589474654197693, 'std': 0.1665, 'EER': -1}\n",
      "[203] Eval metrics for task 4 >> {'accuracy': 0.325, 'loss': 0.008637581706047058, 'std': 0.122, 'EER': -1}\n",
      "[203] Eval metrics for task 5 >> {'accuracy': 0.665, 'loss': 0.003702095299959183, 'std': 0.010000000000000009, 'EER': -1}\n",
      "[204] Eval metrics for task 1 >> {'accuracy': 0.20400000000000001, 'loss': 0.022198177576065063, 'std': 0.05600000000000001, 'EER': -1}\n",
      "[204] Eval metrics for task 2 >> {'accuracy': 0.157, 'loss': 0.026512738704681398, 'std': 0.013000000000000012, 'EER': -1}\n",
      "[204] Eval metrics for task 3 >> {'accuracy': 0.3065, 'loss': 0.016223020195961, 'std': 0.0795, 'EER': -1}\n",
      "[204] Eval metrics for task 4 >> {'accuracy': 0.40049999999999997, 'loss': 0.008956111073493957, 'std': 0.011499999999999982, 'EER': -1}\n",
      "[204] Eval metrics for task 5 >> {'accuracy': 0.7235, 'loss': 0.0029577578604221342, 'std': 0.004500000000000004, 'EER': -1}\n",
      "[205] Eval metrics for task 1 >> {'accuracy': 0.17450000000000002, 'loss': 0.023298018217086793, 'std': 0.0575, 'EER': -1}\n",
      "[205] Eval metrics for task 2 >> {'accuracy': 0.16649999999999998, 'loss': 0.030029847383499144, 'std': 0.014499999999999999, 'EER': -1}\n",
      "[205] Eval metrics for task 3 >> {'accuracy': 0.219, 'loss': 0.020603527784347535, 'std': 0.017999999999999988, 'EER': -1}\n",
      "[205] Eval metrics for task 4 >> {'accuracy': 0.444, 'loss': 0.008845333456993103, 'std': 0.08600000000000002, 'EER': -1}\n",
      "[205] Eval metrics for task 5 >> {'accuracy': 0.7164999999999999, 'loss': 0.0030977189540863036, 'std': 0.01050000000000001, 'EER': -1}\n",
      "[206] Eval metrics for task 1 >> {'accuracy': 0.151, 'loss': 0.02624584674835205, 'std': 0.113, 'EER': -1}\n",
      "[206] Eval metrics for task 2 >> {'accuracy': 0.1275, 'loss': 0.03222816848754883, 'std': 0.0245, 'EER': -1}\n",
      "[206] Eval metrics for task 3 >> {'accuracy': 0.23399999999999999, 'loss': 0.02206761121749878, 'std': 0.06, 'EER': -1}\n",
      "[206] Eval metrics for task 4 >> {'accuracy': 0.3595, 'loss': 0.010067808508872986, 'std': 0.05049999999999999, 'EER': -1}\n",
      "[206] Eval metrics for task 5 >> {'accuracy': 0.768, 'loss': 0.0024722760021686553, 'std': 0.04799999999999999, 'EER': -1}\n",
      "[207] Eval metrics for task 1 >> {'accuracy': 0.1325, 'loss': 0.027114758491516112, 'std': 0.1015, 'EER': -1}\n",
      "[207] Eval metrics for task 2 >> {'accuracy': 0.20700000000000002, 'loss': 0.027055214405059813, 'std': 0.043, 'EER': -1}\n",
      "[207] Eval metrics for task 3 >> {'accuracy': 0.2885, 'loss': 0.018726079225540163, 'std': 0.0795, 'EER': -1}\n",
      "[207] Eval metrics for task 4 >> {'accuracy': 0.41800000000000004, 'loss': 0.011218003749847412, 'std': 0.023999999999999994, 'EER': -1}\n",
      "[207] Eval metrics for task 5 >> {'accuracy': 0.7935000000000001, 'loss': 0.0022240476906299593, 'std': 0.0005000000000000004, 'EER': -1}\n",
      "[208] Eval metrics for task 1 >> {'accuracy': 0.178, 'loss': 0.022373836517333986, 'std': 0.059, 'EER': -1}\n",
      "[208] Eval metrics for task 2 >> {'accuracy': 0.1255, 'loss': 0.024363237142562867, 'std': 0.004500000000000004, 'EER': -1}\n",
      "[208] Eval metrics for task 3 >> {'accuracy': 0.2195, 'loss': 0.018197923421859743, 'std': 0.1665, 'EER': -1}\n",
      "[208] Eval metrics for task 4 >> {'accuracy': 0.23850000000000002, 'loss': 0.01247521674633026, 'std': 0.04050000000000001, 'EER': -1}\n",
      "[208] Eval metrics for task 5 >> {'accuracy': 0.757, 'loss': 0.002593559384346008, 'std': 0.05300000000000005, 'EER': -1}\n",
      "[209] Eval metrics for task 1 >> {'accuracy': 0.14100000000000001, 'loss': 0.021491705656051636, 'std': 0.008999999999999994, 'EER': -1}\n",
      "[209] Eval metrics for task 2 >> {'accuracy': 0.1175, 'loss': 0.024736926794052125, 'std': 0.025499999999999995, 'EER': -1}\n",
      "[209] Eval metrics for task 3 >> {'accuracy': 0.21600000000000003, 'loss': 0.016328543305397035, 'std': 0.054000000000000006, 'EER': -1}\n",
      "[209] Eval metrics for task 4 >> {'accuracy': 0.32799999999999996, 'loss': 0.010863763689994812, 'std': 0.04100000000000001, 'EER': -1}\n",
      "[209] Eval metrics for task 5 >> {'accuracy': 0.823, 'loss': 0.0019359433054924012, 'std': 0.0040000000000000036, 'EER': -1}\n",
      "[210] Eval metrics for task 1 >> {'accuracy': 0.1855, 'loss': 0.022517064094543456, 'std': 0.0635, 'EER': -1}\n",
      "[210] Eval metrics for task 2 >> {'accuracy': 0.111, 'loss': 0.029314512252807616, 'std': 0.010999999999999996, 'EER': -1}\n",
      "[210] Eval metrics for task 3 >> {'accuracy': 0.2405, 'loss': 0.018470186948776245, 'std': 0.05149999999999999, 'EER': -1}\n",
      "[210] Eval metrics for task 4 >> {'accuracy': 0.398, 'loss': 0.010306588530540466, 'std': 0.0040000000000000036, 'EER': -1}\n",
      "[210] Eval metrics for task 5 >> {'accuracy': 0.819, 'loss': 0.0020299113392829894, 'std': 0.012999999999999956, 'EER': -1}\n",
      "[211] Eval metrics for task 1 >> {'accuracy': 0.212, 'loss': 0.02274635338783264, 'std': 0.152, 'EER': -1}\n",
      "[211] Eval metrics for task 2 >> {'accuracy': 0.1315, 'loss': 0.028439260005950928, 'std': 0.0225, 'EER': -1}\n",
      "[211] Eval metrics for task 3 >> {'accuracy': 0.14500000000000002, 'loss': 0.02027088522911072, 'std': 0.007999999999999993, 'EER': -1}\n",
      "[211] Eval metrics for task 4 >> {'accuracy': 0.38849999999999996, 'loss': 0.010311672806739808, 'std': 0.04450000000000001, 'EER': -1}\n",
      "[211] Eval metrics for task 5 >> {'accuracy': 0.8514999999999999, 'loss': 0.0017589329332113265, 'std': 0.03550000000000003, 'EER': -1}\n",
      "[212] Eval metrics for task 1 >> {'accuracy': 0.1725, 'loss': 0.024226232767105102, 'std': 0.006499999999999992, 'EER': -1}\n",
      "[212] Eval metrics for task 2 >> {'accuracy': 0.10750000000000001, 'loss': 0.029252877473831176, 'std': 0.027500000000000004, 'EER': -1}\n",
      "[212] Eval metrics for task 3 >> {'accuracy': 0.1785, 'loss': 0.018789904594421387, 'std': 0.036500000000000005, 'EER': -1}\n",
      "[212] Eval metrics for task 4 >> {'accuracy': 0.3045, 'loss': 0.013166123986244201, 'std': 0.003500000000000003, 'EER': -1}\n",
      "[212] Eval metrics for task 5 >> {'accuracy': 0.784, 'loss': 0.0024313189685344697, 'std': 0.025000000000000022, 'EER': -1}\n",
      "[213] Eval metrics for task 1 >> {'accuracy': 0.17149999999999999, 'loss': 0.023212409734725954, 'std': 0.021500000000000005, 'EER': -1}\n",
      "[213] Eval metrics for task 2 >> {'accuracy': 0.129, 'loss': 0.029924997329711912, 'std': 0.006000000000000005, 'EER': -1}\n",
      "[213] Eval metrics for task 3 >> {'accuracy': 0.1855, 'loss': 0.020444111108779906, 'std': 0.08950000000000001, 'EER': -1}\n",
      "[213] Eval metrics for task 4 >> {'accuracy': 0.3655, 'loss': 0.010394380927085877, 'std': 0.015500000000000014, 'EER': -1}\n",
      "[213] Eval metrics for task 5 >> {'accuracy': 0.819, 'loss': 0.0019969232231378557, 'std': 0.04199999999999998, 'EER': -1}\n",
      "[214] Eval metrics for task 1 >> {'accuracy': 0.1535, 'loss': 0.023700763940811158, 'std': 0.0015000000000000013, 'EER': -1}\n",
      "[214] Eval metrics for task 2 >> {'accuracy': 0.119, 'loss': 0.0296296808719635, 'std': 0.032, 'EER': -1}\n",
      "[214] Eval metrics for task 3 >> {'accuracy': 0.1845, 'loss': 0.02026572799682617, 'std': 0.005500000000000005, 'EER': -1}\n",
      "[214] Eval metrics for task 4 >> {'accuracy': 0.3625, 'loss': 0.012391175270080566, 'std': 0.0015000000000000013, 'EER': -1}\n",
      "[214] Eval metrics for task 5 >> {'accuracy': 0.8109999999999999, 'loss': 0.0020693185776472093, 'std': 0.014999999999999958, 'EER': -1}\n",
      "[215] Eval metrics for task 1 >> {'accuracy': 0.1615, 'loss': 0.023416780710220336, 'std': 0.050499999999999996, 'EER': -1}\n",
      "[215] Eval metrics for task 2 >> {'accuracy': 0.1005, 'loss': 0.03122490644454956, 'std': 0.009500000000000001, 'EER': -1}\n",
      "[215] Eval metrics for task 3 >> {'accuracy': 0.1345, 'loss': 0.023479669809341432, 'std': 0.008499999999999994, 'EER': -1}\n",
      "[215] Eval metrics for task 4 >> {'accuracy': 0.34750000000000003, 'loss': 0.01359076690673828, 'std': 0.00849999999999998, 'EER': -1}\n",
      "[215] Eval metrics for task 5 >> {'accuracy': 0.8445, 'loss': 0.001791722685098648, 'std': 0.02150000000000002, 'EER': -1}\n",
      "[216] Eval metrics for task 1 >> {'accuracy': 0.1765, 'loss': 0.030431622743606567, 'std': 0.1185, 'EER': -1}\n",
      "[216] Eval metrics for task 2 >> {'accuracy': 0.10800000000000001, 'loss': 0.04307753562927246, 'std': 0.030000000000000006, 'EER': -1}\n",
      "[216] Eval metrics for task 3 >> {'accuracy': 0.20700000000000002, 'loss': 0.025139026880264283, 'std': 0.020000000000000004, 'EER': -1}\n",
      "[216] Eval metrics for task 4 >> {'accuracy': 0.45999999999999996, 'loss': 0.01002254331111908, 'std': 0.037000000000000005, 'EER': -1}\n",
      "[216] Eval metrics for task 5 >> {'accuracy': 0.808, 'loss': 0.0023534600734710694, 'std': 0.006999999999999951, 'EER': -1}\n",
      "[217] Eval metrics for task 1 >> {'accuracy': 0.20700000000000002, 'loss': 0.02059014058113098, 'std': 0.039999999999999994, 'EER': -1}\n",
      "[217] Eval metrics for task 2 >> {'accuracy': 0.1255, 'loss': 0.02673689317703247, 'std': 0.010500000000000002, 'EER': -1}\n",
      "[217] Eval metrics for task 3 >> {'accuracy': 0.1335, 'loss': 0.020938282012939454, 'std': 0.0325, 'EER': -1}\n",
      "[217] Eval metrics for task 4 >> {'accuracy': 0.27949999999999997, 'loss': 0.01356930124759674, 'std': 0.02049999999999999, 'EER': -1}\n",
      "[217] Eval metrics for task 5 >> {'accuracy': 0.8534999999999999, 'loss': 0.0017627699077129365, 'std': 0.03750000000000003, 'EER': -1}\n",
      "[218] Eval metrics for task 1 >> {'accuracy': 0.1325, 'loss': 0.026101244926452636, 'std': 0.019499999999999997, 'EER': -1}\n",
      "[218] Eval metrics for task 2 >> {'accuracy': 0.122, 'loss': 0.032164987087249755, 'std': 0.009000000000000001, 'EER': -1}\n",
      "[218] Eval metrics for task 3 >> {'accuracy': 0.1805, 'loss': 0.020962591171264647, 'std': 0.0315, 'EER': -1}\n",
      "[218] Eval metrics for task 4 >> {'accuracy': 0.35050000000000003, 'loss': 0.011513927578926086, 'std': 0.07849999999999999, 'EER': -1}\n",
      "[218] Eval metrics for task 5 >> {'accuracy': 0.8634999999999999, 'loss': 0.0015716010183095932, 'std': 0.04150000000000004, 'EER': -1}\n",
      "[219] Eval metrics for task 1 >> {'accuracy': 0.0775, 'loss': 0.028456945180892944, 'std': 0.0015000000000000013, 'EER': -1}\n",
      "[219] Eval metrics for task 2 >> {'accuracy': 0.133, 'loss': 0.029210400104522704, 'std': 0.069, 'EER': -1}\n",
      "[219] Eval metrics for task 3 >> {'accuracy': 0.2105, 'loss': 0.01905071759223938, 'std': 0.005500000000000005, 'EER': -1}\n",
      "[219] Eval metrics for task 4 >> {'accuracy': 0.285, 'loss': 0.01434384274482727, 'std': 0.078, 'EER': -1}\n",
      "[219] Eval metrics for task 5 >> {'accuracy': 0.865, 'loss': 0.0014769862443208695, 'std': 0.025000000000000022, 'EER': -1}\n",
      "[220] Eval metrics for task 1 >> {'accuracy': 0.217, 'loss': 0.022598698616027833, 'std': 0.03, 'EER': -1}\n",
      "[220] Eval metrics for task 2 >> {'accuracy': 0.21000000000000002, 'loss': 0.02570946168899536, 'std': 0.045, 'EER': -1}\n",
      "[220] Eval metrics for task 3 >> {'accuracy': 0.20550000000000002, 'loss': 0.020457876443862915, 'std': 0.07350000000000001, 'EER': -1}\n",
      "[220] Eval metrics for task 4 >> {'accuracy': 0.3325, 'loss': 0.015211592555046081, 'std': 0.003500000000000003, 'EER': -1}\n",
      "[220] Eval metrics for task 5 >> {'accuracy': 0.759, 'loss': 0.002666069895029068, 'std': 0.01100000000000001, 'EER': -1}\n",
      "[221] Eval metrics for task 1 >> {'accuracy': 0.123, 'loss': 0.025741801977157593, 'std': 0.038, 'EER': -1}\n",
      "[221] Eval metrics for task 2 >> {'accuracy': 0.127, 'loss': 0.029105612277984617, 'std': 0.0020000000000000018, 'EER': -1}\n",
      "[221] Eval metrics for task 3 >> {'accuracy': 0.22749999999999998, 'loss': 0.019005147218704225, 'std': 0.06749999999999999, 'EER': -1}\n",
      "[221] Eval metrics for task 4 >> {'accuracy': 0.373, 'loss': 0.011840526700019836, 'std': 0.014000000000000012, 'EER': -1}\n",
      "[221] Eval metrics for task 5 >> {'accuracy': 0.8534999999999999, 'loss': 0.0015514716804027556, 'std': 0.038500000000000034, 'EER': -1}\n",
      "[222] Eval metrics for task 1 >> {'accuracy': 0.1825, 'loss': 0.026704822540283203, 'std': 0.023499999999999993, 'EER': -1}\n",
      "[222] Eval metrics for task 2 >> {'accuracy': 0.16399999999999998, 'loss': 0.03127912497520447, 'std': 0.012999999999999998, 'EER': -1}\n",
      "[222] Eval metrics for task 3 >> {'accuracy': 0.20450000000000002, 'loss': 0.022699528694152833, 'std': 0.0675, 'EER': -1}\n",
      "[222] Eval metrics for task 4 >> {'accuracy': 0.403, 'loss': 0.01168564212322235, 'std': 0.049000000000000016, 'EER': -1}\n",
      "[222] Eval metrics for task 5 >> {'accuracy': 0.8125, 'loss': 0.0020707200318574905, 'std': 0.07150000000000001, 'EER': -1}\n",
      "[223] Eval metrics for task 1 >> {'accuracy': 0.272, 'loss': 0.021502835988998412, 'std': 0.007000000000000006, 'EER': -1}\n",
      "[223] Eval metrics for task 2 >> {'accuracy': 0.1765, 'loss': 0.030143634557723998, 'std': 0.010499999999999995, 'EER': -1}\n",
      "[223] Eval metrics for task 3 >> {'accuracy': 0.267, 'loss': 0.018912983417510985, 'std': 0.01999999999999999, 'EER': -1}\n",
      "[223] Eval metrics for task 4 >> {'accuracy': 0.39, 'loss': 0.011973772406578063, 'std': 0.014000000000000012, 'EER': -1}\n",
      "[223] Eval metrics for task 5 >> {'accuracy': 0.725, 'loss': 0.003121012181043625, 'std': 0.10599999999999998, 'EER': -1}\n",
      "[224] Eval metrics for task 1 >> {'accuracy': 0.1555, 'loss': 0.024000064611434935, 'std': 0.013500000000000012, 'EER': -1}\n",
      "[224] Eval metrics for task 2 >> {'accuracy': 0.13, 'loss': 0.030383120775222778, 'std': 0.007000000000000006, 'EER': -1}\n",
      "[224] Eval metrics for task 3 >> {'accuracy': 0.16149999999999998, 'loss': 0.022183004140853883, 'std': 0.011499999999999996, 'EER': -1}\n",
      "[224] Eval metrics for task 4 >> {'accuracy': 0.3465, 'loss': 0.012184314489364623, 'std': 0.0005000000000000004, 'EER': -1}\n",
      "[224] Eval metrics for task 5 >> {'accuracy': 0.827, 'loss': 0.0018683627843856811, 'std': 0.07300000000000001, 'EER': -1}\n",
      "[225] Eval metrics for task 1 >> {'accuracy': 0.1505, 'loss': 0.024925323486328126, 'std': 0.06749999999999999, 'EER': -1}\n",
      "[225] Eval metrics for task 2 >> {'accuracy': 0.1725, 'loss': 0.02861922025680542, 'std': 0.0455, 'EER': -1}\n",
      "[225] Eval metrics for task 3 >> {'accuracy': 0.1935, 'loss': 0.02262492346763611, 'std': 0.024499999999999994, 'EER': -1}\n",
      "[225] Eval metrics for task 4 >> {'accuracy': 0.4185, 'loss': 0.01159405255317688, 'std': 0.03950000000000001, 'EER': -1}\n",
      "[225] Eval metrics for task 5 >> {'accuracy': 0.8175, 'loss': 0.0019087082743644715, 'std': 0.03049999999999997, 'EER': -1}\n",
      "[226] Eval metrics for task 1 >> {'accuracy': 0.146, 'loss': 0.025760666608810424, 'std': 0.067, 'EER': -1}\n",
      "[226] Eval metrics for task 2 >> {'accuracy': 0.127, 'loss': 0.03136016631126404, 'std': 0.0010000000000000009, 'EER': -1}\n",
      "[226] Eval metrics for task 3 >> {'accuracy': 0.187, 'loss': 0.02099233627319336, 'std': 0.01200000000000001, 'EER': -1}\n",
      "[226] Eval metrics for task 4 >> {'accuracy': 0.37649999999999995, 'loss': 0.01126166033744812, 'std': 0.0305, 'EER': -1}\n",
      "[226] Eval metrics for task 5 >> {'accuracy': 0.8765000000000001, 'loss': 0.001404855638742447, 'std': 0.027500000000000024, 'EER': -1}\n",
      "[227] Eval metrics for task 1 >> {'accuracy': 0.1935, 'loss': 0.02177958059310913, 'std': 0.011499999999999996, 'EER': -1}\n",
      "[227] Eval metrics for task 2 >> {'accuracy': 0.14150000000000001, 'loss': 0.030964130878448487, 'std': 0.018500000000000003, 'EER': -1}\n",
      "[227] Eval metrics for task 3 >> {'accuracy': 0.16649999999999998, 'loss': 0.023474279642105102, 'std': 0.018500000000000003, 'EER': -1}\n",
      "[227] Eval metrics for task 4 >> {'accuracy': 0.404, 'loss': 0.011840113639831543, 'std': 0.004999999999999977, 'EER': -1}\n",
      "[227] Eval metrics for task 5 >> {'accuracy': 0.8, 'loss': 0.0021156448870897292, 'std': 0.034999999999999976, 'EER': -1}\n",
      "[228] Eval metrics for task 1 >> {'accuracy': 0.17250000000000001, 'loss': 0.0229732608795166, 'std': 0.061500000000000006, 'EER': -1}\n",
      "[228] Eval metrics for task 2 >> {'accuracy': 0.1615, 'loss': 0.02898046636581421, 'std': 0.0025000000000000022, 'EER': -1}\n",
      "[228] Eval metrics for task 3 >> {'accuracy': 0.1795, 'loss': 0.022960579633712768, 'std': 0.056499999999999995, 'EER': -1}\n",
      "[228] Eval metrics for task 4 >> {'accuracy': 0.344, 'loss': 0.01379412829875946, 'std': 0.038000000000000006, 'EER': -1}\n",
      "[228] Eval metrics for task 5 >> {'accuracy': 0.843, 'loss': 0.0016007932424545288, 'std': 0.030999999999999972, 'EER': -1}\n",
      "[229] Eval metrics for task 1 >> {'accuracy': 0.2425, 'loss': 0.02166981077194214, 'std': 0.04749999999999999, 'EER': -1}\n",
      "[229] Eval metrics for task 2 >> {'accuracy': 0.153, 'loss': 0.031052666902542114, 'std': 0.028999999999999998, 'EER': -1}\n",
      "[229] Eval metrics for task 3 >> {'accuracy': 0.2385, 'loss': 0.021434015989303588, 'std': 0.029500000000000012, 'EER': -1}\n",
      "[229] Eval metrics for task 4 >> {'accuracy': 0.315, 'loss': 0.01654062581062317, 'std': 0.02200000000000002, 'EER': -1}\n",
      "[229] Eval metrics for task 5 >> {'accuracy': 0.7925, 'loss': 0.002255077451467514, 'std': 0.044499999999999984, 'EER': -1}\n",
      "[230] Eval metrics for task 1 >> {'accuracy': 0.1975, 'loss': 0.023500279903411865, 'std': 0.03749999999999999, 'EER': -1}\n",
      "[230] Eval metrics for task 2 >> {'accuracy': 0.14100000000000001, 'loss': 0.031460391044616696, 'std': 0.043, 'EER': -1}\n",
      "[230] Eval metrics for task 3 >> {'accuracy': 0.20650000000000002, 'loss': 0.022250486850738525, 'std': 0.0175, 'EER': -1}\n",
      "[230] Eval metrics for task 4 >> {'accuracy': 0.2555, 'loss': 0.018377955436706544, 'std': 0.008500000000000008, 'EER': -1}\n",
      "[230] Eval metrics for task 5 >> {'accuracy': 0.8360000000000001, 'loss': 0.0018382572531700134, 'std': 0.033999999999999975, 'EER': -1}\n",
      "[231] Eval metrics for task 1 >> {'accuracy': 0.2105, 'loss': 0.02294000506401062, 'std': 0.036500000000000005, 'EER': -1}\n",
      "[231] Eval metrics for task 2 >> {'accuracy': 0.1495, 'loss': 0.030842566728591918, 'std': 0.0395, 'EER': -1}\n",
      "[231] Eval metrics for task 3 >> {'accuracy': 0.214, 'loss': 0.02198428153991699, 'std': 0.02099999999999999, 'EER': -1}\n",
      "[231] Eval metrics for task 4 >> {'accuracy': 0.276, 'loss': 0.017823817491531373, 'std': 0.009999999999999981, 'EER': -1}\n",
      "[231] Eval metrics for task 5 >> {'accuracy': 0.815, 'loss': 0.0020093774497509003, 'std': 0.04099999999999998, 'EER': -1}\n",
      "[232] Eval metrics for task 1 >> {'accuracy': 0.2275, 'loss': 0.02274349570274353, 'std': 0.05350000000000002, 'EER': -1}\n",
      "[232] Eval metrics for task 2 >> {'accuracy': 0.168, 'loss': 0.030771212100982666, 'std': 0.034, 'EER': -1}\n",
      "[232] Eval metrics for task 3 >> {'accuracy': 0.2675, 'loss': 0.020338853120803833, 'std': 0.05450000000000001, 'EER': -1}\n",
      "[232] Eval metrics for task 4 >> {'accuracy': 0.326, 'loss': 0.016126771092414855, 'std': 0.007000000000000006, 'EER': -1}\n",
      "[232] Eval metrics for task 5 >> {'accuracy': 0.8025, 'loss': 0.0021457790285348893, 'std': 0.04349999999999998, 'EER': -1}\n",
      "[233] Eval metrics for task 1 >> {'accuracy': 0.23600000000000002, 'loss': 0.022458317995071413, 'std': 0.04000000000000001, 'EER': -1}\n",
      "[233] Eval metrics for task 2 >> {'accuracy': 0.1725, 'loss': 0.030116697072982788, 'std': 0.02750000000000001, 'EER': -1}\n",
      "[233] Eval metrics for task 3 >> {'accuracy': 0.2605, 'loss': 0.02064063787460327, 'std': 0.0495, 'EER': -1}\n",
      "[233] Eval metrics for task 4 >> {'accuracy': 0.329, 'loss': 0.016120919227600096, 'std': 0.01100000000000001, 'EER': -1}\n",
      "[233] Eval metrics for task 5 >> {'accuracy': 0.7925, 'loss': 0.0022889489233493803, 'std': 0.04349999999999998, 'EER': -1}\n",
      "[234] Eval metrics for task 1 >> {'accuracy': 0.23950000000000002, 'loss': 0.02205905604362488, 'std': 0.03950000000000001, 'EER': -1}\n",
      "[234] Eval metrics for task 2 >> {'accuracy': 0.1655, 'loss': 0.03003944206237793, 'std': 0.0335, 'EER': -1}\n",
      "[234] Eval metrics for task 3 >> {'accuracy': 0.248, 'loss': 0.02133728361129761, 'std': 0.032000000000000015, 'EER': -1}\n",
      "[234] Eval metrics for task 4 >> {'accuracy': 0.3155, 'loss': 0.016730391025543214, 'std': 0.004500000000000004, 'EER': -1}\n",
      "[234] Eval metrics for task 5 >> {'accuracy': 0.7985, 'loss': 0.0022596953511238096, 'std': 0.04149999999999998, 'EER': -1}\n",
      "[235] Eval metrics for task 1 >> {'accuracy': 0.202, 'loss': 0.023620103120803832, 'std': 0.044, 'EER': -1}\n",
      "[235] Eval metrics for task 2 >> {'accuracy': 0.1455, 'loss': 0.031502836227416994, 'std': 0.030499999999999992, 'EER': -1}\n",
      "[235] Eval metrics for task 3 >> {'accuracy': 0.20950000000000002, 'loss': 0.021783726692199707, 'std': 0.014499999999999999, 'EER': -1}\n",
      "[235] Eval metrics for task 4 >> {'accuracy': 0.2835, 'loss': 0.017152562618255617, 'std': 0.007499999999999979, 'EER': -1}\n",
      "[235] Eval metrics for task 5 >> {'accuracy': 0.8300000000000001, 'loss': 0.0018612390905618668, 'std': 0.03799999999999998, 'EER': -1}\n",
      "[236] Eval metrics for task 1 >> {'accuracy': 0.22000000000000003, 'loss': 0.02257826256752014, 'std': 0.049, 'EER': -1}\n",
      "[236] Eval metrics for task 2 >> {'accuracy': 0.1505, 'loss': 0.031099908113479614, 'std': 0.033499999999999995, 'EER': -1}\n",
      "[236] Eval metrics for task 3 >> {'accuracy': 0.2375, 'loss': 0.021175355672836304, 'std': 0.029500000000000012, 'EER': -1}\n",
      "[236] Eval metrics for task 4 >> {'accuracy': 0.3015, 'loss': 0.016415721774101256, 'std': 0.006500000000000006, 'EER': -1}\n",
      "[236] Eval metrics for task 5 >> {'accuracy': 0.8175, 'loss': 0.002006962761282921, 'std': 0.04249999999999998, 'EER': -1}\n",
      "[237] Eval metrics for task 1 >> {'accuracy': 0.2415, 'loss': 0.022366234064102174, 'std': 0.046499999999999986, 'EER': -1}\n",
      "[237] Eval metrics for task 2 >> {'accuracy': 0.1795, 'loss': 0.029826979875564576, 'std': 0.0335, 'EER': -1}\n",
      "[237] Eval metrics for task 3 >> {'accuracy': 0.277, 'loss': 0.02037560200691223, 'std': 0.046, 'EER': -1}\n",
      "[237] Eval metrics for task 4 >> {'accuracy': 0.334, 'loss': 0.016346319794654847, 'std': 0.0030000000000000027, 'EER': -1}\n",
      "[237] Eval metrics for task 5 >> {'accuracy': 0.7835, 'loss': 0.0023443882167339327, 'std': 0.03749999999999998, 'EER': -1}\n",
      "[238] Eval metrics for task 1 >> {'accuracy': 0.2235, 'loss': 0.02252614164352417, 'std': 0.05150000000000002, 'EER': -1}\n",
      "[238] Eval metrics for task 2 >> {'accuracy': 0.161, 'loss': 0.030606196403503417, 'std': 0.024999999999999994, 'EER': -1}\n",
      "[238] Eval metrics for task 3 >> {'accuracy': 0.2465, 'loss': 0.02102994704246521, 'std': 0.041499999999999995, 'EER': -1}\n",
      "[238] Eval metrics for task 4 >> {'accuracy': 0.317, 'loss': 0.015977672934532165, 'std': 0.0030000000000000027, 'EER': -1}\n",
      "[238] Eval metrics for task 5 >> {'accuracy': 0.8140000000000001, 'loss': 0.0020057666301727295, 'std': 0.04799999999999999, 'EER': -1}\n",
      "[239] Eval metrics for task 1 >> {'accuracy': 0.23349999999999999, 'loss': 0.022498492240905762, 'std': 0.05049999999999999, 'EER': -1}\n",
      "[239] Eval metrics for task 2 >> {'accuracy': 0.1585, 'loss': 0.031347312450408935, 'std': 0.035500000000000004, 'EER': -1}\n",
      "[239] Eval metrics for task 3 >> {'accuracy': 0.2415, 'loss': 0.02132957863807678, 'std': 0.02850000000000001, 'EER': -1}\n",
      "[239] Eval metrics for task 4 >> {'accuracy': 0.3145, 'loss': 0.01668118977546692, 'std': 0.0005000000000000004, 'EER': -1}\n",
      "[239] Eval metrics for task 5 >> {'accuracy': 0.8029999999999999, 'loss': 0.002171189859509468, 'std': 0.04999999999999999, 'EER': -1}\n",
      "[240] Eval metrics for task 1 >> {'accuracy': 0.23349999999999999, 'loss': 0.02279094958305359, 'std': 0.04949999999999999, 'EER': -1}\n",
      "[240] Eval metrics for task 2 >> {'accuracy': 0.16699999999999998, 'loss': 0.031121907949447632, 'std': 0.02500000000000001, 'EER': -1}\n",
      "[240] Eval metrics for task 3 >> {'accuracy': 0.2435, 'loss': 0.021766063451766966, 'std': 0.030500000000000013, 'EER': -1}\n",
      "[240] Eval metrics for task 4 >> {'accuracy': 0.3105, 'loss': 0.017032315969467162, 'std': 0.007500000000000007, 'EER': -1}\n",
      "[240] Eval metrics for task 5 >> {'accuracy': 0.8025, 'loss': 0.002186139225959778, 'std': 0.044499999999999984, 'EER': -1}\n",
      "[241] Eval metrics for task 1 >> {'accuracy': 0.2175, 'loss': 0.022947155714035033, 'std': 0.04450000000000001, 'EER': -1}\n",
      "[241] Eval metrics for task 2 >> {'accuracy': 0.1575, 'loss': 0.031162055492401124, 'std': 0.0335, 'EER': -1}\n",
      "[241] Eval metrics for task 3 >> {'accuracy': 0.23600000000000002, 'loss': 0.02152380585670471, 'std': 0.04000000000000001, 'EER': -1}\n",
      "[241] Eval metrics for task 4 >> {'accuracy': 0.294, 'loss': 0.017157412767410278, 'std': 0.0050000000000000044, 'EER': -1}\n",
      "[241] Eval metrics for task 5 >> {'accuracy': 0.8195, 'loss': 0.0019959478378295896, 'std': 0.046499999999999986, 'EER': -1}\n",
      "[242] Eval metrics for task 1 >> {'accuracy': 0.2015, 'loss': 0.02344966769218445, 'std': 0.042499999999999996, 'EER': -1}\n",
      "[242] Eval metrics for task 2 >> {'accuracy': 0.1375, 'loss': 0.032200258016586304, 'std': 0.03749999999999999, 'EER': -1}\n",
      "[242] Eval metrics for task 3 >> {'accuracy': 0.20350000000000001, 'loss': 0.022148879051208496, 'std': 0.0165, 'EER': -1}\n",
      "[242] Eval metrics for task 4 >> {'accuracy': 0.277, 'loss': 0.01737993049621582, 'std': 0.004999999999999977, 'EER': -1}\n",
      "[242] Eval metrics for task 5 >> {'accuracy': 0.8400000000000001, 'loss': 0.0017900748848915101, 'std': 0.04299999999999998, 'EER': -1}\n",
      "[243] Eval metrics for task 1 >> {'accuracy': 0.2165, 'loss': 0.022839160919189454, 'std': 0.037500000000000006, 'EER': -1}\n",
      "[243] Eval metrics for task 2 >> {'accuracy': 0.1465, 'loss': 0.031575015306472776, 'std': 0.0375, 'EER': -1}\n",
      "[243] Eval metrics for task 3 >> {'accuracy': 0.22, 'loss': 0.021688843250274658, 'std': 0.022999999999999993, 'EER': -1}\n",
      "[243] Eval metrics for task 4 >> {'accuracy': 0.2905, 'loss': 0.017315968990325926, 'std': 0.012499999999999983, 'EER': -1}\n",
      "[243] Eval metrics for task 5 >> {'accuracy': 0.815, 'loss': 0.0020639918744564056, 'std': 0.045999999999999985, 'EER': -1}\n",
      "[244] Eval metrics for task 1 >> {'accuracy': 0.20900000000000002, 'loss': 0.023041005849838255, 'std': 0.044, 'EER': -1}\n",
      "[244] Eval metrics for task 2 >> {'accuracy': 0.1515, 'loss': 0.031198355197906494, 'std': 0.028499999999999998, 'EER': -1}\n",
      "[244] Eval metrics for task 3 >> {'accuracy': 0.2315, 'loss': 0.021265145301818847, 'std': 0.0305, 'EER': -1}\n",
      "[244] Eval metrics for task 4 >> {'accuracy': 0.3055, 'loss': 0.01637214946746826, 'std': 0.004500000000000004, 'EER': -1}\n",
      "[244] Eval metrics for task 5 >> {'accuracy': 0.8185, 'loss': 0.0019937313348054888, 'std': 0.04749999999999999, 'EER': -1}\n",
      "[245] Eval metrics for task 1 >> {'accuracy': 0.2465, 'loss': 0.02242059564590454, 'std': 0.045499999999999985, 'EER': -1}\n",
      "[245] Eval metrics for task 2 >> {'accuracy': 0.1795, 'loss': 0.030127787113189697, 'std': 0.0345, 'EER': -1}\n",
      "[245] Eval metrics for task 3 >> {'accuracy': 0.2675, 'loss': 0.021082056522369386, 'std': 0.042499999999999996, 'EER': -1}\n",
      "[245] Eval metrics for task 4 >> {'accuracy': 0.3165, 'loss': 0.01727180624008179, 'std': 0.01050000000000001, 'EER': -1}\n",
      "[245] Eval metrics for task 5 >> {'accuracy': 0.7855, 'loss': 0.0023647319972515107, 'std': 0.04049999999999998, 'EER': -1}\n",
      "[246] Eval metrics for task 1 >> {'accuracy': 0.21150000000000002, 'loss': 0.022953797340393066, 'std': 0.0455, 'EER': -1}\n",
      "[246] Eval metrics for task 2 >> {'accuracy': 0.1505, 'loss': 0.031030734539031983, 'std': 0.028499999999999998, 'EER': -1}\n",
      "[246] Eval metrics for task 3 >> {'accuracy': 0.2335, 'loss': 0.02108158326148987, 'std': 0.038500000000000006, 'EER': -1}\n",
      "[246] Eval metrics for task 4 >> {'accuracy': 0.3, 'loss': 0.016256461024284363, 'std': 0.01200000000000001, 'EER': -1}\n",
      "[246] Eval metrics for task 5 >> {'accuracy': 0.8225, 'loss': 0.0019526255130767822, 'std': 0.044499999999999984, 'EER': -1}\n",
      "[247] Eval metrics for task 1 >> {'accuracy': 0.2335, 'loss': 0.022624688148498537, 'std': 0.036500000000000005, 'EER': -1}\n",
      "[247] Eval metrics for task 2 >> {'accuracy': 0.1675, 'loss': 0.03049165344238281, 'std': 0.028499999999999998, 'EER': -1}\n",
      "[247] Eval metrics for task 3 >> {'accuracy': 0.2455, 'loss': 0.021419513463974, 'std': 0.03550000000000002, 'EER': -1}\n",
      "[247] Eval metrics for task 4 >> {'accuracy': 0.3125, 'loss': 0.016786898493766786, 'std': 0.004500000000000004, 'EER': -1}\n",
      "[247] Eval metrics for task 5 >> {'accuracy': 0.8, 'loss': 0.002228053241968155, 'std': 0.045999999999999985, 'EER': -1}\n",
      "[248] Eval metrics for task 1 >> {'accuracy': 0.21250000000000002, 'loss': 0.023290846824645998, 'std': 0.042499999999999996, 'EER': -1}\n",
      "[248] Eval metrics for task 2 >> {'accuracy': 0.1575, 'loss': 0.031235663175582885, 'std': 0.0305, 'EER': -1}\n",
      "[248] Eval metrics for task 3 >> {'accuracy': 0.2385, 'loss': 0.0216036856174469, 'std': 0.0595, 'EER': -1}\n",
      "[248] Eval metrics for task 4 >> {'accuracy': 0.296, 'loss': 0.01704462254047394, 'std': 0.010000000000000009, 'EER': -1}\n",
      "[248] Eval metrics for task 5 >> {'accuracy': 0.8165, 'loss': 0.0019851555526256563, 'std': 0.044499999999999984, 'EER': -1}\n",
      "[249] Eval metrics for task 1 >> {'accuracy': 0.21150000000000002, 'loss': 0.023389355659484863, 'std': 0.0435, 'EER': -1}\n",
      "[249] Eval metrics for task 2 >> {'accuracy': 0.1575, 'loss': 0.030858553409576415, 'std': 0.027499999999999997, 'EER': -1}\n",
      "[249] Eval metrics for task 3 >> {'accuracy': 0.2285, 'loss': 0.021569092988967895, 'std': 0.026499999999999996, 'EER': -1}\n",
      "[249] Eval metrics for task 4 >> {'accuracy': 0.295, 'loss': 0.017034824013710023, 'std': 0.0040000000000000036, 'EER': -1}\n",
      "[249] Eval metrics for task 5 >> {'accuracy': 0.821, 'loss': 0.001967778503894806, 'std': 0.03999999999999998, 'EER': -1}\n",
      "[250] Eval metrics for task 1 >> {'accuracy': 0.20450000000000002, 'loss': 0.023485629320144655, 'std': 0.0495, 'EER': -1}\n",
      "[250] Eval metrics for task 2 >> {'accuracy': 0.1415, 'loss': 0.031937875270843505, 'std': 0.0365, 'EER': -1}\n",
      "[250] Eval metrics for task 3 >> {'accuracy': 0.2155, 'loss': 0.021783442974090576, 'std': 0.02049999999999999, 'EER': -1}\n",
      "[250] Eval metrics for task 4 >> {'accuracy': 0.28500000000000003, 'loss': 0.01701105058193207, 'std': 0.009999999999999981, 'EER': -1}\n",
      "[250] Eval metrics for task 5 >> {'accuracy': 0.8320000000000001, 'loss': 0.0018203087300062179, 'std': 0.03999999999999998, 'EER': -1}\n",
      "training_task_end\n",
      "final avg-acc 0.3357\n",
      "final avg-forget 0.534375\n"
     ]
    }
   ],
   "source": [
    "trainer.run()\n",
    "print(\"final avg-acc\", metric_manager_callback.meters['accuracy'].compute_final())\n",
    "print(\"final avg-forget\", metric_manager_callback.meters['forgetting'].compute_final())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9801a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ebfb58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.019000000000000017, 0.05088888888888891, 0.277625, 0.19852]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_manager_callback.meters['EER'].get_eer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06af72df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.04199999999999998,\n",
       " 0.13833835332256922,\n",
       " 0.08157954536660661,\n",
       " 0.3491230979181985,\n",
       " 0.2546220925214464]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_manager_callback.meters['std'].get_std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a893b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7039ed8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.943, 0.   , 0.   , 0.   , 0.   ],\n",
       "       [0.591, 0.629, 0.   , 0.   , 0.   ],\n",
       "       [0.558, 0.41 , 0.477, 0.   , 0.   ],\n",
       "       [0.334, 0.07 , 0.182, 0.936, 0.   ],\n",
       "       [0.205, 0.142, 0.216, 0.285, 0.832]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_manager_callback.meters['accuracy'].get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "173c4765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9430000000000001, 0.61, 0.4816666666666667, 0.38025, 0.3357]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_manager_callback.meters['accuracy'].compute_overall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "706ad34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.5501233333333333\n",
      "EER:0.10920677777777779\n",
      "std:0.17313261782576414\n"
     ]
    }
   ],
   "source": [
    "print(f\"accuracy:{np.mean(metric_manager_callback.meters['accuracy'].compute_overall())}\")\n",
    "print(f\"EER:{np.mean(metric_manager_callback.meters['EER'].compute_overall())}\")\n",
    "print(f\"std:{np.mean(metric_manager_callback.meters['std'].compute_overall())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b848e47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
