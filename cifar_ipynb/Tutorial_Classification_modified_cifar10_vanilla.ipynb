{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0c3b92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_dir=./outputs/demo/dataset=CIFAR10/seed=0_epoch=50_lr=0.01_alpha=0.0_tau=2.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import cl_gym as cl\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "seed = 10\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.set_num_threads(8)\n",
    "\n",
    "def make_params() -> dict:\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    import uuid\n",
    "\n",
    "    params = {\n",
    "            # dataset\n",
    "            'dataset': \"CIFAR10\",\n",
    "            # 'dataset': \"FMNIST\",\n",
    "            'random_class_idx' : False,\n",
    "            'method': \"vanilla\",\n",
    "\n",
    "            # benchmark\n",
    "            'seed': seed,\n",
    "            'num_tasks': 5,\n",
    "            'epochs_per_task': 50,\n",
    "            # 'per_task_examples': np.inf,\n",
    "            'per_task_examples': 200000,\n",
    "            'per_task_memory_examples': 64,\n",
    "            'batch_size_train': 256,\n",
    "            'batch_size_memory': 256,\n",
    "            # 'batch_size_memory': 256,\n",
    "            'batch_size_validation': 256,\n",
    "            'tau': 2.0,\n",
    "            # 'tau': 0.0,\n",
    "\n",
    "            # algorithm\n",
    "            'optimizer': 'sgd',\n",
    "            'learning_rate': 0.01,\n",
    "            'learning_rate_decay_epoch': [30, 50, 70, 90],\n",
    "            'momentum': 0.9,\n",
    "            'learning_rate_decay': 1.0,\n",
    "            'criterion': torch.nn.CrossEntropyLoss(),\n",
    "            'device': torch.device('cuda:5' if torch.cuda.is_available() else 'cpu'),\n",
    "             \n",
    "            # sample selection\n",
    "            'alpha':0.0,\n",
    "            'lambda': 0.0,\n",
    "            'lambda_old': 0.0,\n",
    "              }\n",
    "\n",
    "#     trial_id = str(uuid.uuid4())\n",
    "    trial_id = f\"demo/dataset={params['dataset']}/seed={params['seed']}_epoch={params['epochs_per_task']}_lr={params['learning_rate']}_alpha={params['alpha']}_tau={params['tau']}\"\n",
    "    params['trial_id'] = trial_id\n",
    "    params['output_dir'] = os.path.join(\"./outputs/{}\".format(trial_id))\n",
    "    print(f\"output_dir={params['output_dir']}\")\n",
    "    Path(params['output_dir']).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    return params\n",
    "\n",
    "params = make_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93b43ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from datasets import MNIST, FashionMNIST, BiasedMNIST, CIFAR10, CIFAR100\n",
    "if params['dataset'] == 'MNIST':\n",
    "    benchmark = MNIST(num_tasks=params['num_tasks'],\n",
    "                        per_task_memory_examples=params['per_task_memory_examples'],\n",
    "                        per_task_examples = params['per_task_examples'],\n",
    "                        joint = (params['method'] == \"joint\"),\n",
    "                        random_class_idx = params['random_class_idx'])\n",
    "    input_dim = (28, 28)\n",
    "elif params['dataset'] == 'FashionMNIST':\n",
    "    benchmark = FashionMNIST(num_tasks=params['num_tasks'],\n",
    "                                per_task_memory_examples=params['per_task_memory_examples'],\n",
    "                                per_task_examples = params['per_task_examples'],\n",
    "                                joint = (params['method'] == \"joint\"),\n",
    "                                random_class_idx = params['random_class_idx'])\n",
    "    input_dim = (28, 28)\n",
    "elif params['dataset'] == 'CIFAR10':\n",
    "    benchmark = CIFAR10(num_tasks=params['num_tasks'],\n",
    "                        per_task_memory_examples=params['per_task_memory_examples'],\n",
    "                        per_task_examples = params['per_task_examples'],\n",
    "                        joint = (params['method'] == \"joint\"),\n",
    "                        random_class_idx = params['random_class_idx'])\n",
    "    input_dim = (3, 32, 32)\n",
    "elif params['dataset'] == 'CIFAR100':        \n",
    "    benchmark = CIFAR100(num_tasks=params['num_tasks'],\n",
    "                            per_task_memory_examples=params['per_task_memory_examples'],\n",
    "                            per_task_examples = params['per_task_examples'],\n",
    "                            joint = (params['method'] == \"joint\"),\n",
    "                            random_class_idx = params['random_class_idx'])\n",
    "    input_dim = (3, 32, 32)\n",
    "elif params['dataset'] in [\"BiasedMNIST\"]:\n",
    "    benchmark = BiasedMNIST(num_tasks=params['num_tasks'],\n",
    "                            per_task_memory_examples=params['per_task_memory_examples'],\n",
    "                            per_task_examples = params['per_task_examples'],\n",
    "                            joint = (params['method'] == \"joint\"),\n",
    "                            random_class_idx = params['random_class_idx'])\n",
    "    input_dim = (3, 28, 28)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "class_idx = benchmark.class_idx\n",
    "num_classes = len(class_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20c7b886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modify resnet for cifar\n"
     ]
    }
   ],
   "source": [
    "from algorithms.imbalance import Heuristic2\n",
    "from metrics import MetricCollector2\n",
    "from backbones import MLP2Layers2\n",
    "\n",
    "from backbones.resnet import ResNet18\n",
    "\n",
    "\n",
    "# backbone = ResNet18(\n",
    "#     input_dim=input_dim, \n",
    "#     output_dim=num_classes,\n",
    "#     class_idx=class_idx,\n",
    "#     config=params\n",
    "#     ).to(params['device'])\n",
    "\n",
    "backbone = ResNet18(\n",
    "    input_dim=input_dim, \n",
    "    output_dim=num_classes,\n",
    "    class_idx=class_idx,\n",
    "    config=params\n",
    "    ).to(params['device'])\n",
    "\n",
    "algorithm = Heuristic2(backbone, benchmark, params, requires_memory=True)\n",
    "metric_manager_callback = MetricCollector2(num_tasks=params['num_tasks'],\n",
    "                                                        eval_interval='epoch',\n",
    "                                                        epochs_per_task=params['epochs_per_task'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8efa3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainers import ContinualTrainer\n",
    "\n",
    "trainer = ContinualTrainer(algorithm, params, callbacks=[metric_manager_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c315bf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Task 1 -----------------------\n",
      "[1] Eval metrics for task 1 >> {'accuracy': 0.8495, 'loss': 0.0013676766008138656, 'std': 0.0615, 'EER': -1}\n",
      "[2] Eval metrics for task 1 >> {'accuracy': 0.895, 'loss': 0.000996992401778698, 'std': 0.02400000000000002, 'EER': -1}\n",
      "[3] Eval metrics for task 1 >> {'accuracy': 0.913, 'loss': 0.0008939114734530449, 'std': 0.02300000000000002, 'EER': -1}\n",
      "[4] Eval metrics for task 1 >> {'accuracy': 0.9305000000000001, 'loss': 0.0007453939691185952, 'std': 0.0005000000000000004, 'EER': -1}\n",
      "[5] Eval metrics for task 1 >> {'accuracy': 0.9325000000000001, 'loss': 0.0007099601924419404, 'std': 0.0015000000000000013, 'EER': -1}\n",
      "[6] Eval metrics for task 1 >> {'accuracy': 0.9405, 'loss': 0.0006763599701225758, 'std': 0.01849999999999996, 'EER': -1}\n",
      "[7] Eval metrics for task 1 >> {'accuracy': 0.8855, 'loss': 0.001130737043917179, 'std': 0.09549999999999997, 'EER': -1}\n",
      "[8] Eval metrics for task 1 >> {'accuracy': 0.9430000000000001, 'loss': 0.0006606693528592586, 'std': 0.009999999999999953, 'EER': -1}\n"
     ]
    }
   ],
   "source": [
    "trainer.run()\n",
    "print(\"final avg-acc\", metric_manager_callback.meters['accuracy'].compute_final())\n",
    "print(\"final avg-forget\", metric_manager_callback.meters['forgetting'].compute_final())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9801a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebfb58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.11625, 0.1426666666666667, 0.182375, 0.17112]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_manager_callback.meters['EER'].get_eer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06af72df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.03049999999999997,\n",
       " 0.30450646544860094,\n",
       " 0.16718452878979762,\n",
       " 0.21805614959225525,\n",
       " 0.2343910407844122]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_manager_callback.meters['std'].get_std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a893b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7039ed8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.944, 0.   , 0.   , 0.   , 0.   ],\n",
       "       [0.158, 0.39 , 0.   , 0.   , 0.   ],\n",
       "       [0.126, 0.495, 0.222, 0.   , 0.   ],\n",
       "       [0.097, 0.117, 0.31 , 0.634, 0.   ],\n",
       "       [0.084, 0.068, 0.14 , 0.225, 0.664]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_manager_callback.meters['accuracy'].get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173c4765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9435, 0.27375, 0.281, 0.289625, 0.23620000000000002]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_manager_callback.meters['accuracy'].compute_overall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706ad34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.40481500000000004\n",
      "EER:0.12248233333333333\n",
      "std:0.1909276369230132\n"
     ]
    }
   ],
   "source": [
    "print(f\"accuracy:{np.mean(metric_manager_callback.meters['accuracy'].compute_overall())}\")\n",
    "print(f\"EER:{np.mean(metric_manager_callback.meters['EER'].compute_overall())}\")\n",
    "print(f\"std:{np.mean(metric_manager_callback.meters['std'].compute_overall())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b848e47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
