{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0c3b92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_dir=./outputs/demo/dataset=CIFAR10/seed=10_epoch=50_lr=0.01_alpha=0.0_tau=1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import cl_gym as cl\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "seed = 10\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.set_num_threads(8)\n",
    "\n",
    "def make_params() -> dict:\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    import uuid\n",
    "\n",
    "    params = {\n",
    "            # dataset\n",
    "            'dataset': \"CIFAR10\",\n",
    "            # 'dataset': \"FMNIST\",\n",
    "            'random_class_idx' : False,\n",
    "            'method': \"vanilla\",\n",
    "\n",
    "            # benchmark\n",
    "            'seed': seed,\n",
    "            'num_tasks': 5,\n",
    "            'epochs_per_task': 50,\n",
    "            # 'per_task_examples': np.inf,\n",
    "            'per_task_examples': 200000,\n",
    "            'per_task_memory_examples': 64,\n",
    "            'batch_size_train': 256,\n",
    "            'batch_size_memory': 256,\n",
    "            # 'batch_size_memory': 256,\n",
    "            'batch_size_validation': 256,\n",
    "            'tau': 1.0,\n",
    "            # 'tau': 0.0,\n",
    "\n",
    "            # algorithm\n",
    "            'optimizer': 'sgd',\n",
    "            'learning_rate': 0.01,\n",
    "            'learning_rate_decay_epoch': [30, 50, 70, 90],\n",
    "            'momentum': 0.9,\n",
    "            'learning_rate_decay': 1.0,\n",
    "            'criterion': torch.nn.CrossEntropyLoss(),\n",
    "            'device': torch.device('cuda:5' if torch.cuda.is_available() else 'cpu'),\n",
    "             \n",
    "            # sample selection\n",
    "            'alpha':0.0,\n",
    "            'lambda': 0.0,\n",
    "            'lambda_old': 0.0,\n",
    "              }\n",
    "\n",
    "#     trial_id = str(uuid.uuid4())\n",
    "    trial_id = f\"demo/dataset={params['dataset']}/seed={params['seed']}_epoch={params['epochs_per_task']}_lr={params['learning_rate']}_alpha={params['alpha']}_tau={params['tau']}\"\n",
    "    params['trial_id'] = trial_id\n",
    "    params['output_dir'] = os.path.join(\"./outputs/{}\".format(trial_id))\n",
    "    print(f\"output_dir={params['output_dir']}\")\n",
    "    Path(params['output_dir']).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    return params\n",
    "\n",
    "params = make_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93b43ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from datasets import MNIST, FashionMNIST, BiasedMNIST, CIFAR10, CIFAR100\n",
    "if params['dataset'] == 'MNIST':\n",
    "    benchmark = MNIST(num_tasks=params['num_tasks'],\n",
    "                        per_task_memory_examples=params['per_task_memory_examples'],\n",
    "                        per_task_examples = params['per_task_examples'],\n",
    "                        joint = (params['method'] == \"joint\"),\n",
    "                        random_class_idx = params['random_class_idx'])\n",
    "    input_dim = (28, 28)\n",
    "elif params['dataset'] == 'FashionMNIST':\n",
    "    benchmark = FashionMNIST(num_tasks=params['num_tasks'],\n",
    "                                per_task_memory_examples=params['per_task_memory_examples'],\n",
    "                                per_task_examples = params['per_task_examples'],\n",
    "                                joint = (params['method'] == \"joint\"),\n",
    "                                random_class_idx = params['random_class_idx'])\n",
    "    input_dim = (28, 28)\n",
    "elif params['dataset'] == 'CIFAR10':\n",
    "    benchmark = CIFAR10(num_tasks=params['num_tasks'],\n",
    "                        per_task_memory_examples=params['per_task_memory_examples'],\n",
    "                        per_task_examples = params['per_task_examples'],\n",
    "                        joint = (params['method'] == \"joint\"),\n",
    "                        random_class_idx = params['random_class_idx'])\n",
    "    input_dim = (3, 32, 32)\n",
    "elif params['dataset'] == 'CIFAR100':        \n",
    "    benchmark = CIFAR100(num_tasks=params['num_tasks'],\n",
    "                            per_task_memory_examples=params['per_task_memory_examples'],\n",
    "                            per_task_examples = params['per_task_examples'],\n",
    "                            joint = (params['method'] == \"joint\"),\n",
    "                            random_class_idx = params['random_class_idx'])\n",
    "    input_dim = (3, 32, 32)\n",
    "elif params['dataset'] in [\"BiasedMNIST\"]:\n",
    "    benchmark = BiasedMNIST(num_tasks=params['num_tasks'],\n",
    "                            per_task_memory_examples=params['per_task_memory_examples'],\n",
    "                            per_task_examples = params['per_task_examples'],\n",
    "                            joint = (params['method'] == \"joint\"),\n",
    "                            random_class_idx = params['random_class_idx'])\n",
    "    input_dim = (3, 28, 28)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "class_idx = benchmark.class_idx\n",
    "num_classes = len(class_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20c7b886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modify resnet for cifar\n"
     ]
    }
   ],
   "source": [
    "from algorithms.imbalance import Heuristic2\n",
    "from metrics import MetricCollector2\n",
    "from backbones import MLP2Layers2\n",
    "\n",
    "from backbones.resnet import ResNet18\n",
    "\n",
    "\n",
    "# backbone = ResNet18(\n",
    "#     input_dim=input_dim, \n",
    "#     output_dim=num_classes,\n",
    "#     class_idx=class_idx,\n",
    "#     config=params\n",
    "#     ).to(params['device'])\n",
    "\n",
    "backbone = ResNet18(\n",
    "    input_dim=input_dim, \n",
    "    output_dim=num_classes,\n",
    "    class_idx=class_idx,\n",
    "    config=params\n",
    "    ).to(params['device'])\n",
    "\n",
    "algorithm = Heuristic2(backbone, benchmark, params, requires_memory=True)\n",
    "metric_manager_callback = MetricCollector2(num_tasks=params['num_tasks'],\n",
    "                                                        eval_interval='epoch',\n",
    "                                                        epochs_per_task=params['epochs_per_task'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8efa3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainers import ContinualTrainer\n",
    "\n",
    "trainer = ContinualTrainer(algorithm, params, callbacks=[metric_manager_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c315bf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Task 1 -----------------------\n",
      "[1] Eval metrics for task 1 >> {'accuracy': 0.821, 'loss': 0.0015542374849319457, 'std': 0.09600000000000003, 'EER': -1}\n",
      "[2] Eval metrics for task 1 >> {'accuracy': 0.8505, 'loss': 0.0013441222906112672, 'std': 0.08650000000000002, 'EER': -1}\n",
      "[3] Eval metrics for task 1 >> {'accuracy': 0.8835, 'loss': 0.001098384290933609, 'std': 0.04150000000000004, 'EER': -1}\n",
      "[4] Eval metrics for task 1 >> {'accuracy': 0.905, 'loss': 0.0009727678298950195, 'std': 0.013000000000000012, 'EER': -1}\n",
      "[5] Eval metrics for task 1 >> {'accuracy': 0.9145, 'loss': 0.0008592504635453224, 'std': 0.04149999999999998, 'EER': -1}\n",
      "[6] Eval metrics for task 1 >> {'accuracy': 0.927, 'loss': 0.0007724330499768257, 'std': 0.023999999999999966, 'EER': -1}\n",
      "[7] Eval metrics for task 1 >> {'accuracy': 0.872, 'loss': 0.0012186369150877, 'std': 0.10999999999999999, 'EER': -1}\n",
      "[8] Eval metrics for task 1 >> {'accuracy': 0.9239999999999999, 'loss': 0.0008102221190929413, 'std': 0.03799999999999998, 'EER': -1}\n",
      "[9] Eval metrics for task 1 >> {'accuracy': 0.9425, 'loss': 0.0006228669360280037, 'std': 0.013499999999999956, 'EER': -1}\n",
      "[10] Eval metrics for task 1 >> {'accuracy': 0.9435, 'loss': 0.0006541663408279419, 'std': 0.03049999999999997, 'EER': -1}\n",
      "[11] Eval metrics for task 1 >> {'accuracy': 0.9535, 'loss': 0.0005021771676838398, 'std': 0.004500000000000004, 'EER': -1}\n",
      "[12] Eval metrics for task 1 >> {'accuracy': 0.9495, 'loss': 0.0005349710024893284, 'std': 0.013499999999999956, 'EER': -1}\n",
      "[13] Eval metrics for task 1 >> {'accuracy': 0.9544999999999999, 'loss': 0.0005347102098166943, 'std': 0.005500000000000005, 'EER': -1}\n",
      "[14] Eval metrics for task 1 >> {'accuracy': 0.9615, 'loss': 0.00040383763238787654, 'std': 0.006500000000000006, 'EER': -1}\n",
      "[15] Eval metrics for task 1 >> {'accuracy': 0.9205, 'loss': 0.0010295420587062836, 'std': 0.07450000000000001, 'EER': -1}\n",
      "[16] Eval metrics for task 1 >> {'accuracy': 0.956, 'loss': 0.0004740884080529213, 'std': 0.007000000000000006, 'EER': -1}\n",
      "[17] Eval metrics for task 1 >> {'accuracy': 0.9644999999999999, 'loss': 0.00037283831648528574, 'std': 0.01150000000000001, 'EER': -1}\n",
      "[18] Eval metrics for task 1 >> {'accuracy': 0.959, 'loss': 0.0004592818133533001, 'std': 0.017000000000000015, 'EER': -1}\n",
      "[19] Eval metrics for task 1 >> {'accuracy': 0.966, 'loss': 0.0003582383552566171, 'std': 0.014000000000000012, 'EER': -1}\n",
      "[20] Eval metrics for task 1 >> {'accuracy': 0.96, 'loss': 0.0004337979666888714, 'std': 0.019000000000000017, 'EER': -1}\n",
      "[21] Eval metrics for task 1 >> {'accuracy': 0.9695, 'loss': 0.0003738541044294834, 'std': 0.006500000000000006, 'EER': -1}\n",
      "[22] Eval metrics for task 1 >> {'accuracy': 0.9610000000000001, 'loss': 0.00042475255206227304, 'std': 0.02699999999999997, 'EER': -1}\n",
      "[23] Eval metrics for task 1 >> {'accuracy': 0.9724999999999999, 'loss': 0.0002934701405465603, 'std': 0.0025000000000000022, 'EER': -1}\n",
      "[24] Eval metrics for task 1 >> {'accuracy': 0.967, 'loss': 0.00036090693809092046, 'std': 0.0050000000000000044, 'EER': -1}\n",
      "[25] Eval metrics for task 1 >> {'accuracy': 0.975, 'loss': 0.00028701317124068735, 'std': 0.0010000000000000009, 'EER': -1}\n",
      "[26] Eval metrics for task 1 >> {'accuracy': 0.9715, 'loss': 0.0003687286414206028, 'std': 0.0015000000000000013, 'EER': -1}\n",
      "[27] Eval metrics for task 1 >> {'accuracy': 0.9724999999999999, 'loss': 0.0003830532394349575, 'std': 0.0015000000000000013, 'EER': -1}\n",
      "[28] Eval metrics for task 1 >> {'accuracy': 0.972, 'loss': 0.0003108647773042321, 'std': 0.007000000000000006, 'EER': -1}\n",
      "[29] Eval metrics for task 1 >> {'accuracy': 0.9325, 'loss': 0.0009475812017917633, 'std': 0.04049999999999998, 'EER': -1}\n",
      "[30] Eval metrics for task 1 >> {'accuracy': 0.948, 'loss': 0.0008168460093438626, 'std': 0.034999999999999976, 'EER': -1}\n",
      "[31] Eval metrics for task 1 >> {'accuracy': 0.9410000000000001, 'loss': 0.000901186853647232, 'std': 0.04299999999999998, 'EER': -1}\n",
      "[32] Eval metrics for task 1 >> {'accuracy': 0.9425, 'loss': 0.000876957193017006, 'std': 0.04149999999999998, 'EER': -1}\n",
      "[33] Eval metrics for task 1 >> {'accuracy': 0.95, 'loss': 0.0007845024466514587, 'std': 0.02999999999999997, 'EER': -1}\n",
      "[34] Eval metrics for task 1 >> {'accuracy': 0.9445, 'loss': 0.000872126579284668, 'std': 0.04049999999999998, 'EER': -1}\n",
      "[35] Eval metrics for task 1 >> {'accuracy': 0.942, 'loss': 0.0008924752697348594, 'std': 0.04299999999999998, 'EER': -1}\n",
      "[36] Eval metrics for task 1 >> {'accuracy': 0.9390000000000001, 'loss': 0.0009520881697535515, 'std': 0.045999999999999985, 'EER': -1}\n",
      "[37] Eval metrics for task 1 >> {'accuracy': 0.9435, 'loss': 0.0008644357547163964, 'std': 0.04049999999999998, 'EER': -1}\n",
      "[38] Eval metrics for task 1 >> {'accuracy': 0.9515, 'loss': 0.0007570509016513825, 'std': 0.02849999999999997, 'EER': -1}\n",
      "[39] Eval metrics for task 1 >> {'accuracy': 0.9475, 'loss': 0.0008233070299029351, 'std': 0.03649999999999998, 'EER': -1}\n",
      "[40] Eval metrics for task 1 >> {'accuracy': 0.9470000000000001, 'loss': 0.0008493602201342582, 'std': 0.03699999999999998, 'EER': -1}\n",
      "[41] Eval metrics for task 1 >> {'accuracy': 0.9475, 'loss': 0.0008152196519076824, 'std': 0.03649999999999998, 'EER': -1}\n",
      "[42] Eval metrics for task 1 >> {'accuracy': 0.9415, 'loss': 0.0008951142840087414, 'std': 0.04349999999999998, 'EER': -1}\n",
      "[43] Eval metrics for task 1 >> {'accuracy': 0.9450000000000001, 'loss': 0.000874044619500637, 'std': 0.03899999999999998, 'EER': -1}\n",
      "[44] Eval metrics for task 1 >> {'accuracy': 0.944, 'loss': 0.0008662469312548638, 'std': 0.04099999999999998, 'EER': -1}\n",
      "[45] Eval metrics for task 1 >> {'accuracy': 0.9495, 'loss': 0.0008122915476560593, 'std': 0.03249999999999997, 'EER': -1}\n",
      "[46] Eval metrics for task 1 >> {'accuracy': 0.95, 'loss': 0.0007514705434441566, 'std': 0.02899999999999997, 'EER': -1}\n",
      "[47] Eval metrics for task 1 >> {'accuracy': 0.9410000000000001, 'loss': 0.0009208736419677734, 'std': 0.04299999999999998, 'EER': -1}\n",
      "[48] Eval metrics for task 1 >> {'accuracy': 0.9450000000000001, 'loss': 0.0008587613031268119, 'std': 0.03899999999999998, 'EER': -1}\n",
      "[49] Eval metrics for task 1 >> {'accuracy': 0.9490000000000001, 'loss': 0.0007111882157623768, 'std': 0.023999999999999966, 'EER': -1}\n",
      "[50] Eval metrics for task 1 >> {'accuracy': 0.9430000000000001, 'loss': 0.0008770229443907738, 'std': 0.04199999999999998, 'EER': -1}\n",
      "training_task_end\n",
      "---------------------------- Task 2 -----------------------\n",
      "[51] Eval metrics for task 1 >> {'accuracy': 0.6285000000000001, 'loss': 0.005349838376045227, 'std': 0.05450000000000005, 'EER': -1}\n",
      "[51] Eval metrics for task 2 >> {'accuracy': 0.35450000000000004, 'loss': 0.005235307633876801, 'std': 0.11150000000000002, 'EER': -1}\n",
      "[52] Eval metrics for task 1 >> {'accuracy': 0.4145, 'loss': 0.026288629531860352, 'std': 0.07449999999999998, 'EER': -1}\n",
      "[52] Eval metrics for task 2 >> {'accuracy': 0.5820000000000001, 'loss': 0.003572920024394989, 'std': 0.035999999999999976, 'EER': -1}\n",
      "[53] Eval metrics for task 1 >> {'accuracy': 0.517, 'loss': 0.008395237445831299, 'std': 0.14800000000000002, 'EER': -1}\n",
      "[53] Eval metrics for task 2 >> {'accuracy': 0.495, 'loss': 0.004179057002067566, 'std': 0.017000000000000015, 'EER': -1}\n",
      "[54] Eval metrics for task 1 >> {'accuracy': 0.56, 'loss': 0.009006749153137207, 'std': 0.092, 'EER': -1}\n",
      "[54] Eval metrics for task 2 >> {'accuracy': 0.394, 'loss': 0.0050483387112617495, 'std': 0.129, 'EER': -1}\n",
      "[55] Eval metrics for task 1 >> {'accuracy': 0.506, 'loss': 0.02784788703918457, 'std': 0.07999999999999999, 'EER': -1}\n",
      "[55] Eval metrics for task 2 >> {'accuracy': 0.3065, 'loss': 0.008434754967689514, 'std': 0.1565, 'EER': -1}\n",
      "[56] Eval metrics for task 1 >> {'accuracy': 0.728, 'loss': 0.006777760624885559, 'std': 0.03600000000000003, 'EER': -1}\n",
      "[56] Eval metrics for task 2 >> {'accuracy': 0.228, 'loss': 0.007428978085517884, 'std': 0.114, 'EER': -1}\n",
      "[57] Eval metrics for task 1 >> {'accuracy': 0.547, 'loss': 0.008347998142242432, 'std': 0.08299999999999999, 'EER': -1}\n",
      "[57] Eval metrics for task 2 >> {'accuracy': 0.3995, 'loss': 0.005183379411697388, 'std': 0.056499999999999995, 'EER': -1}\n",
      "[58] Eval metrics for task 1 >> {'accuracy': 0.4605, 'loss': 0.00985415506362915, 'std': 0.09650000000000003, 'EER': -1}\n",
      "[58] Eval metrics for task 2 >> {'accuracy': 0.4, 'loss': 0.005128620624542236, 'std': 0.013999999999999985, 'EER': -1}\n",
      "[59] Eval metrics for task 1 >> {'accuracy': 0.639, 'loss': 0.00666189855337143, 'std': 0.009000000000000008, 'EER': -1}\n",
      "[59] Eval metrics for task 2 >> {'accuracy': 0.437, 'loss': 0.006705674767494202, 'std': 0.326, 'EER': -1}\n",
      "[60] Eval metrics for task 1 >> {'accuracy': 0.657, 'loss': 0.007349758565425872, 'std': 0.138, 'EER': -1}\n",
      "[60] Eval metrics for task 2 >> {'accuracy': 0.4805, 'loss': 0.00486205393075943, 'std': 0.20949999999999996, 'EER': -1}\n",
      "[61] Eval metrics for task 1 >> {'accuracy': 0.666, 'loss': 0.006532579720020294, 'std': 0.10999999999999999, 'EER': -1}\n",
      "[61] Eval metrics for task 2 >> {'accuracy': 0.4575, 'loss': 0.0048465536236763, 'std': 0.21150000000000002, 'EER': -1}\n",
      "[62] Eval metrics for task 1 >> {'accuracy': 0.512, 'loss': 0.01411577832698822, 'std': 0.204, 'EER': -1}\n",
      "[62] Eval metrics for task 2 >> {'accuracy': 0.5, 'loss': 0.0044400964975357055, 'std': 0.14600000000000002, 'EER': -1}\n",
      "[63] Eval metrics for task 1 >> {'accuracy': 0.4285, 'loss': 0.01442437732219696, 'std': 0.16349999999999998, 'EER': -1}\n",
      "[63] Eval metrics for task 2 >> {'accuracy': 0.5145, 'loss': 0.003961116999387741, 'std': 0.2245, 'EER': -1}\n",
      "[64] Eval metrics for task 1 >> {'accuracy': 0.5965, 'loss': 0.008500937223434448, 'std': 0.09449999999999997, 'EER': -1}\n",
      "[64] Eval metrics for task 2 >> {'accuracy': 0.447, 'loss': 0.004531245946884155, 'std': 0.08300000000000002, 'EER': -1}\n",
      "[65] Eval metrics for task 1 >> {'accuracy': 0.587, 'loss': 0.007914539158344268, 'std': 0.025999999999999968, 'EER': -1}\n",
      "[65] Eval metrics for task 2 >> {'accuracy': 0.468, 'loss': 0.005610436201095581, 'std': 0.30100000000000005, 'EER': -1}\n",
      "[66] Eval metrics for task 1 >> {'accuracy': 0.7184999999999999, 'loss': 0.005827503621578216, 'std': 0.009500000000000008, 'EER': -1}\n",
      "[66] Eval metrics for task 2 >> {'accuracy': 0.3935, 'loss': 0.00528049623966217, 'std': 0.1195, 'EER': -1}\n",
      "[67] Eval metrics for task 1 >> {'accuracy': 0.48050000000000004, 'loss': 0.014708481550216675, 'std': 0.02049999999999999, 'EER': -1}\n",
      "[67] Eval metrics for task 2 >> {'accuracy': 0.507, 'loss': 0.004309027224779129, 'std': 0.17900000000000002, 'EER': -1}\n",
      "[68] Eval metrics for task 1 >> {'accuracy': 0.546, 'loss': 0.010188063979148865, 'std': 0.16099999999999998, 'EER': -1}\n",
      "[68] Eval metrics for task 2 >> {'accuracy': 0.5125, 'loss': 0.004339885830879212, 'std': 0.1315, 'EER': -1}\n",
      "[69] Eval metrics for task 1 >> {'accuracy': 0.672, 'loss': 0.010503642797470092, 'std': 0.119, 'EER': -1}\n",
      "[69] Eval metrics for task 2 >> {'accuracy': 0.24, 'loss': 0.006712722897529602, 'std': 0.007999999999999993, 'EER': -1}\n",
      "[70] Eval metrics for task 1 >> {'accuracy': 0.697, 'loss': 0.006092627048492432, 'std': 0.125, 'EER': -1}\n",
      "[70] Eval metrics for task 2 >> {'accuracy': 0.51, 'loss': 0.004394117951393128, 'std': 0.10799999999999998, 'EER': -1}\n",
      "[71] Eval metrics for task 1 >> {'accuracy': 0.785, 'loss': 0.004707178741693497, 'std': 0.0, 'EER': -1}\n",
      "[71] Eval metrics for task 2 >> {'accuracy': 0.40049999999999997, 'loss': 0.005293827474117279, 'std': 0.07049999999999998, 'EER': -1}\n",
      "[72] Eval metrics for task 1 >> {'accuracy': 0.673, 'loss': 0.005800249576568603, 'std': 0.11000000000000004, 'EER': -1}\n",
      "[72] Eval metrics for task 2 >> {'accuracy': 0.504, 'loss': 0.004516169130802154, 'std': 0.21, 'EER': -1}\n",
      "[73] Eval metrics for task 1 >> {'accuracy': 0.7455, 'loss': 0.004794636160135269, 'std': 0.030500000000000027, 'EER': -1}\n",
      "[73] Eval metrics for task 2 >> {'accuracy': 0.4385, 'loss': 0.0048193070292472835, 'std': 0.0995, 'EER': -1}\n",
      "[74] Eval metrics for task 1 >> {'accuracy': 0.7335, 'loss': 0.005215366959571839, 'std': 0.038500000000000034, 'EER': -1}\n",
      "[74] Eval metrics for task 2 >> {'accuracy': 0.4375, 'loss': 0.004974551260471344, 'std': 0.0605, 'EER': -1}\n",
      "[75] Eval metrics for task 1 >> {'accuracy': 0.688, 'loss': 0.006175059676170349, 'std': 0.03199999999999997, 'EER': -1}\n",
      "[75] Eval metrics for task 2 >> {'accuracy': 0.49, 'loss': 0.0048109711408615115, 'std': 0.19400000000000003, 'EER': -1}\n",
      "[76] Eval metrics for task 1 >> {'accuracy': 0.6185, 'loss': 0.007138315737247467, 'std': 0.08449999999999996, 'EER': -1}\n",
      "[76] Eval metrics for task 2 >> {'accuracy': 0.4845, 'loss': 0.0046162960529327396, 'std': 0.01050000000000001, 'EER': -1}\n",
      "[77] Eval metrics for task 1 >> {'accuracy': 0.6055, 'loss': 0.00733350533246994, 'std': 0.07050000000000001, 'EER': -1}\n",
      "[77] Eval metrics for task 2 >> {'accuracy': 0.49049999999999994, 'loss': 0.004843563556671143, 'std': 0.08249999999999999, 'EER': -1}\n",
      "[78] Eval metrics for task 1 >> {'accuracy': 0.6819999999999999, 'loss': 0.005899705410003662, 'std': 0.059, 'EER': -1}\n",
      "[78] Eval metrics for task 2 >> {'accuracy': 0.563, 'loss': 0.004151003718376159, 'std': 0.13299999999999998, 'EER': -1}\n",
      "[79] Eval metrics for task 1 >> {'accuracy': 0.708, 'loss': 0.00550897091627121, 'std': 0.04299999999999998, 'EER': -1}\n",
      "[79] Eval metrics for task 2 >> {'accuracy': 0.5635, 'loss': 0.004507929563522339, 'std': 0.1945, 'EER': -1}\n",
      "[80] Eval metrics for task 1 >> {'accuracy': 0.6145, 'loss': 0.006239748656749726, 'std': 0.057499999999999996, 'EER': -1}\n",
      "[80] Eval metrics for task 2 >> {'accuracy': 0.6555, 'loss': 0.003352803647518158, 'std': 0.11049999999999999, 'EER': -1}\n",
      "[81] Eval metrics for task 1 >> {'accuracy': 0.651, 'loss': 0.00587861829996109, 'std': 0.067, 'EER': -1}\n",
      "[81] Eval metrics for task 2 >> {'accuracy': 0.6275, 'loss': 0.003652627617120743, 'std': 0.1395, 'EER': -1}\n",
      "[82] Eval metrics for task 1 >> {'accuracy': 0.6319999999999999, 'loss': 0.0060430924892425535, 'std': 0.062, 'EER': -1}\n",
      "[82] Eval metrics for task 2 >> {'accuracy': 0.6445000000000001, 'loss': 0.003474470317363739, 'std': 0.1325, 'EER': -1}\n",
      "[83] Eval metrics for task 1 >> {'accuracy': 0.6174999999999999, 'loss': 0.006345782518386841, 'std': 0.05350000000000005, 'EER': -1}\n",
      "[83] Eval metrics for task 2 >> {'accuracy': 0.6495, 'loss': 0.003410546153783798, 'std': 0.10649999999999998, 'EER': -1}\n",
      "[84] Eval metrics for task 1 >> {'accuracy': 0.6005, 'loss': 0.006592021822929383, 'std': 0.0645, 'EER': -1}\n",
      "[84] Eval metrics for task 2 >> {'accuracy': 0.6635, 'loss': 0.0032732025384902956, 'std': 0.10949999999999999, 'EER': -1}\n",
      "[85] Eval metrics for task 1 >> {'accuracy': 0.6759999999999999, 'loss': 0.005972911536693573, 'std': 0.06, 'EER': -1}\n",
      "[85] Eval metrics for task 2 >> {'accuracy': 0.5825, 'loss': 0.004089102745056152, 'std': 0.12749999999999997, 'EER': -1}\n",
      "[86] Eval metrics for task 1 >> {'accuracy': 0.633, 'loss': 0.006537127435207367, 'std': 0.07, 'EER': -1}\n",
      "[86] Eval metrics for task 2 >> {'accuracy': 0.625, 'loss': 0.0036735689342021942, 'std': 0.11499999999999999, 'EER': -1}\n",
      "[87] Eval metrics for task 1 >> {'accuracy': 0.6755, 'loss': 0.006131635308265686, 'std': 0.08150000000000002, 'EER': -1}\n",
      "[87] Eval metrics for task 2 >> {'accuracy': 0.603, 'loss': 0.003933456182479859, 'std': 0.128, 'EER': -1}\n",
      "[88] Eval metrics for task 1 >> {'accuracy': 0.6739999999999999, 'loss': 0.005831565856933594, 'std': 0.065, 'EER': -1}\n",
      "[88] Eval metrics for task 2 >> {'accuracy': 0.608, 'loss': 0.003802266627550125, 'std': 0.11399999999999999, 'EER': -1}\n",
      "[89] Eval metrics for task 1 >> {'accuracy': 0.6174999999999999, 'loss': 0.006231092751026153, 'std': 0.051500000000000046, 'EER': -1}\n",
      "[89] Eval metrics for task 2 >> {'accuracy': 0.6615, 'loss': 0.0033315814733505247, 'std': 0.1215, 'EER': -1}\n",
      "[90] Eval metrics for task 1 >> {'accuracy': 0.6040000000000001, 'loss': 0.006169970870018005, 'std': 0.055999999999999994, 'EER': -1}\n",
      "[90] Eval metrics for task 2 >> {'accuracy': 0.65, 'loss': 0.003398458480834961, 'std': 0.09999999999999998, 'EER': -1}\n",
      "[91] Eval metrics for task 1 >> {'accuracy': 0.6515, 'loss': 0.006046457052230835, 'std': 0.04149999999999998, 'EER': -1}\n",
      "[91] Eval metrics for task 2 >> {'accuracy': 0.624, 'loss': 0.0037150665521621705, 'std': 0.127, 'EER': -1}\n",
      "[92] Eval metrics for task 1 >> {'accuracy': 0.6385, 'loss': 0.006533479332923889, 'std': 0.0675, 'EER': -1}\n",
      "[92] Eval metrics for task 2 >> {'accuracy': 0.62, 'loss': 0.003741758018732071, 'std': 0.121, 'EER': -1}\n",
      "[93] Eval metrics for task 1 >> {'accuracy': 0.597, 'loss': 0.006516621351242065, 'std': 0.056999999999999995, 'EER': -1}\n",
      "[93] Eval metrics for task 2 >> {'accuracy': 0.6639999999999999, 'loss': 0.003249338924884796, 'std': 0.08700000000000002, 'EER': -1}\n",
      "[94] Eval metrics for task 1 >> {'accuracy': 0.6475, 'loss': 0.006086661100387573, 'std': 0.0655, 'EER': -1}\n",
      "[94] Eval metrics for task 2 >> {'accuracy': 0.6295, 'loss': 0.003657897651195526, 'std': 0.1325, 'EER': -1}\n",
      "[95] Eval metrics for task 1 >> {'accuracy': 0.706, 'loss': 0.0056441810131073, 'std': 0.06, 'EER': -1}\n",
      "[95] Eval metrics for task 2 >> {'accuracy': 0.5495, 'loss': 0.004350013703107834, 'std': 0.10550000000000001, 'EER': -1}\n",
      "[96] Eval metrics for task 1 >> {'accuracy': 0.6855, 'loss': 0.0058207492232322695, 'std': 0.0665, 'EER': -1}\n",
      "[96] Eval metrics for task 2 >> {'accuracy': 0.57, 'loss': 0.004142429232597351, 'std': 0.12299999999999997, 'EER': -1}\n",
      "[97] Eval metrics for task 1 >> {'accuracy': 0.6735, 'loss': 0.00588436758518219, 'std': 0.07250000000000001, 'EER': -1}\n",
      "[97] Eval metrics for task 2 >> {'accuracy': 0.591, 'loss': 0.0039781066477298736, 'std': 0.11099999999999999, 'EER': -1}\n",
      "[98] Eval metrics for task 1 >> {'accuracy': 0.6439999999999999, 'loss': 0.006138023138046265, 'std': 0.061, 'EER': -1}\n",
      "[98] Eval metrics for task 2 >> {'accuracy': 0.633, 'loss': 0.0036175206005573273, 'std': 0.14200000000000002, 'EER': -1}\n",
      "[99] Eval metrics for task 1 >> {'accuracy': 0.6485, 'loss': 0.0060146204829216, 'std': 0.0645, 'EER': -1}\n",
      "[99] Eval metrics for task 2 >> {'accuracy': 0.6305000000000001, 'loss': 0.003582843095064163, 'std': 0.1265, 'EER': -1}\n",
      "[100] Eval metrics for task 1 >> {'accuracy': 0.611, 'loss': 0.006180550813674927, 'std': 0.064, 'EER': -1}\n",
      "[100] Eval metrics for task 2 >> {'accuracy': 0.6505000000000001, 'loss': 0.0034367005228996277, 'std': 0.1295, 'EER': -1}\n",
      "training_task_end\n",
      "---------------------------- Task 3 -----------------------\n",
      "[101] Eval metrics for task 1 >> {'accuracy': 0.5529999999999999, 'loss': 0.011638901948928833, 'std': 0.04099999999999998, 'EER': -1}\n",
      "[101] Eval metrics for task 2 >> {'accuracy': 0.101, 'loss': 0.008062235236167907, 'std': 0.055, 'EER': -1}\n",
      "[101] Eval metrics for task 3 >> {'accuracy': 0.526, 'loss': 0.004859563827514649, 'std': 0.1, 'EER': -1}\n",
      "[102] Eval metrics for task 1 >> {'accuracy': 0.49, 'loss': 0.019495917320251466, 'std': 0.19200000000000003, 'EER': -1}\n",
      "[102] Eval metrics for task 2 >> {'accuracy': 0.3325, 'loss': 0.01018657112121582, 'std': 0.0025000000000000022, 'EER': -1}\n",
      "[102] Eval metrics for task 3 >> {'accuracy': 0.429, 'loss': 0.0050344827175140385, 'std': 0.08200000000000002, 'EER': -1}\n",
      "[103] Eval metrics for task 1 >> {'accuracy': 0.4335, 'loss': 0.012480692148208619, 'std': 0.13349999999999998, 'EER': -1}\n",
      "[103] Eval metrics for task 2 >> {'accuracy': 0.3855, 'loss': 0.008905191659927368, 'std': 0.019500000000000017, 'EER': -1}\n",
      "[103] Eval metrics for task 3 >> {'accuracy': 0.388, 'loss': 0.00511009430885315, 'std': 0.04899999999999999, 'EER': -1}\n",
      "[104] Eval metrics for task 1 >> {'accuracy': 0.44, 'loss': 0.012513021945953369, 'std': 0.027000000000000024, 'EER': -1}\n",
      "[104] Eval metrics for task 2 >> {'accuracy': 0.443, 'loss': 0.008904946267604828, 'std': 0.01100000000000001, 'EER': -1}\n",
      "[104] Eval metrics for task 3 >> {'accuracy': 0.28700000000000003, 'loss': 0.006866087138652802, 'std': 0.028999999999999998, 'EER': -1}\n",
      "[105] Eval metrics for task 1 >> {'accuracy': 0.3725, 'loss': 0.01615573763847351, 'std': 0.0655, 'EER': -1}\n",
      "[105] Eval metrics for task 2 >> {'accuracy': 0.377, 'loss': 0.010661516666412353, 'std': 0.061, 'EER': -1}\n",
      "[105] Eval metrics for task 3 >> {'accuracy': 0.42200000000000004, 'loss': 0.005303231537342071, 'std': 0.12200000000000003, 'EER': -1}\n",
      "[106] Eval metrics for task 1 >> {'accuracy': 0.2755, 'loss': 0.022795760869979857, 'std': 0.06350000000000001, 'EER': -1}\n",
      "[106] Eval metrics for task 2 >> {'accuracy': 0.39549999999999996, 'loss': 0.011585001945495605, 'std': 0.04150000000000001, 'EER': -1}\n",
      "[106] Eval metrics for task 3 >> {'accuracy': 0.4095, 'loss': 0.006050729215145111, 'std': 0.08049999999999999, 'EER': -1}\n",
      "[107] Eval metrics for task 1 >> {'accuracy': 0.44699999999999995, 'loss': 0.021604190826416014, 'std': 0.033, 'EER': -1}\n",
      "[107] Eval metrics for task 2 >> {'accuracy': 0.21200000000000002, 'loss': 0.01755227518081665, 'std': 0.05, 'EER': -1}\n",
      "[107] Eval metrics for task 3 >> {'accuracy': 0.4395, 'loss': 0.005461801171302795, 'std': 0.11350000000000002, 'EER': -1}\n",
      "[108] Eval metrics for task 1 >> {'accuracy': 0.389, 'loss': 0.014517423152923583, 'std': 0.07400000000000001, 'EER': -1}\n",
      "[108] Eval metrics for task 2 >> {'accuracy': 0.34650000000000003, 'loss': 0.011046104431152344, 'std': 0.037500000000000006, 'EER': -1}\n",
      "[108] Eval metrics for task 3 >> {'accuracy': 0.5305, 'loss': 0.004034664690494538, 'std': 0.013500000000000012, 'EER': -1}\n",
      "[109] Eval metrics for task 1 >> {'accuracy': 0.3015, 'loss': 0.018256598711013795, 'std': 0.0985, 'EER': -1}\n",
      "[109] Eval metrics for task 2 >> {'accuracy': 0.3375, 'loss': 0.012840205073356628, 'std': 0.08549999999999999, 'EER': -1}\n",
      "[109] Eval metrics for task 3 >> {'accuracy': 0.5335, 'loss': 0.004214767187833786, 'std': 0.057499999999999996, 'EER': -1}\n",
      "[110] Eval metrics for task 1 >> {'accuracy': 0.437, 'loss': 0.013341588139533997, 'std': 0.07600000000000001, 'EER': -1}\n",
      "[110] Eval metrics for task 2 >> {'accuracy': 0.33399999999999996, 'loss': 0.013212968826293945, 'std': 0.04600000000000001, 'EER': -1}\n",
      "[110] Eval metrics for task 3 >> {'accuracy': 0.53, 'loss': 0.004485714435577393, 'std': 0.07099999999999998, 'EER': -1}\n",
      "[111] Eval metrics for task 1 >> {'accuracy': 0.4155, 'loss': 0.014817423939704895, 'std': 0.008500000000000008, 'EER': -1}\n",
      "[111] Eval metrics for task 2 >> {'accuracy': 0.2865, 'loss': 0.01673261249065399, 'std': 0.00849999999999998, 'EER': -1}\n",
      "[111] Eval metrics for task 3 >> {'accuracy': 0.4955, 'loss': 0.005124780237674713, 'std': 0.11249999999999999, 'EER': -1}\n",
      "[112] Eval metrics for task 1 >> {'accuracy': 0.46099999999999997, 'loss': 0.014117595434188843, 'std': 0.038000000000000006, 'EER': -1}\n",
      "[112] Eval metrics for task 2 >> {'accuracy': 0.3375, 'loss': 0.014926719069480896, 'std': 0.0885, 'EER': -1}\n",
      "[112] Eval metrics for task 3 >> {'accuracy': 0.384, 'loss': 0.006818358421325684, 'std': 0.101, 'EER': -1}\n",
      "[113] Eval metrics for task 1 >> {'accuracy': 0.4185, 'loss': 0.014834308505058288, 'std': 0.07450000000000001, 'EER': -1}\n",
      "[113] Eval metrics for task 2 >> {'accuracy': 0.2905, 'loss': 0.016479860067367555, 'std': 0.007500000000000007, 'EER': -1}\n",
      "[113] Eval metrics for task 3 >> {'accuracy': 0.5589999999999999, 'loss': 0.004449223637580871, 'std': 0.035999999999999976, 'EER': -1}\n",
      "[114] Eval metrics for task 1 >> {'accuracy': 0.4425, 'loss': 0.015099529623985291, 'std': 0.007500000000000007, 'EER': -1}\n",
      "[114] Eval metrics for task 2 >> {'accuracy': 0.3385, 'loss': 0.015913734078407286, 'std': 0.01849999999999999, 'EER': -1}\n",
      "[114] Eval metrics for task 3 >> {'accuracy': 0.5045, 'loss': 0.005134399116039276, 'std': 0.016500000000000015, 'EER': -1}\n",
      "[115] Eval metrics for task 1 >> {'accuracy': 0.43100000000000005, 'loss': 0.014098604202270508, 'std': 0.032, 'EER': -1}\n",
      "[115] Eval metrics for task 2 >> {'accuracy': 0.39, 'loss': 0.011810056686401367, 'std': 0.03, 'EER': -1}\n",
      "[115] Eval metrics for task 3 >> {'accuracy': 0.508, 'loss': 0.004705132126808166, 'std': 0.017000000000000015, 'EER': -1}\n",
      "[116] Eval metrics for task 1 >> {'accuracy': 0.41400000000000003, 'loss': 0.014779552340507507, 'std': 0.009999999999999981, 'EER': -1}\n",
      "[116] Eval metrics for task 2 >> {'accuracy': 0.3255, 'loss': 0.014964333415031433, 'std': 0.0335, 'EER': -1}\n",
      "[116] Eval metrics for task 3 >> {'accuracy': 0.508, 'loss': 0.004970027029514313, 'std': 0.030000000000000027, 'EER': -1}\n",
      "[117] Eval metrics for task 1 >> {'accuracy': 0.34950000000000003, 'loss': 0.01709577178955078, 'std': 0.0985, 'EER': -1}\n",
      "[117] Eval metrics for task 2 >> {'accuracy': 0.382, 'loss': 0.012988693118095397, 'std': 0.098, 'EER': -1}\n",
      "[117] Eval metrics for task 3 >> {'accuracy': 0.517, 'loss': 0.005134936213493347, 'std': 0.07899999999999999, 'EER': -1}\n",
      "[118] Eval metrics for task 1 >> {'accuracy': 0.4655, 'loss': 0.012992135405540466, 'std': 0.04550000000000001, 'EER': -1}\n",
      "[118] Eval metrics for task 2 >> {'accuracy': 0.394, 'loss': 0.013137595891952515, 'std': 0.032, 'EER': -1}\n",
      "[118] Eval metrics for task 3 >> {'accuracy': 0.4535, 'loss': 0.005948536396026612, 'std': 0.0335, 'EER': -1}\n",
      "[119] Eval metrics for task 1 >> {'accuracy': 0.46900000000000003, 'loss': 0.013606913924217224, 'std': 0.07500000000000001, 'EER': -1}\n",
      "[119] Eval metrics for task 2 >> {'accuracy': 0.3215, 'loss': 0.01691936528682709, 'std': 0.0325, 'EER': -1}\n",
      "[119] Eval metrics for task 3 >> {'accuracy': 0.52, 'loss': 0.004977299630641937, 'std': 0.099, 'EER': -1}\n",
      "[120] Eval metrics for task 1 >> {'accuracy': 0.37749999999999995, 'loss': 0.018111728310585024, 'std': 0.0925, 'EER': -1}\n",
      "[120] Eval metrics for task 2 >> {'accuracy': 0.3315, 'loss': 0.01435050928592682, 'std': 0.04150000000000001, 'EER': -1}\n",
      "[120] Eval metrics for task 3 >> {'accuracy': 0.5815, 'loss': 0.0038580816686153412, 'std': 0.04749999999999999, 'EER': -1}\n",
      "[121] Eval metrics for task 1 >> {'accuracy': 0.4285, 'loss': 0.015432990908622742, 'std': 0.0865, 'EER': -1}\n",
      "[121] Eval metrics for task 2 >> {'accuracy': 0.326, 'loss': 0.015232726097106934, 'std': 0.007000000000000006, 'EER': -1}\n",
      "[121] Eval metrics for task 3 >> {'accuracy': 0.5425, 'loss': 0.004271156162023545, 'std': 0.020499999999999963, 'EER': -1}\n",
      "[122] Eval metrics for task 1 >> {'accuracy': 0.37849999999999995, 'loss': 0.017876779556274414, 'std': 0.0955, 'EER': -1}\n",
      "[122] Eval metrics for task 2 >> {'accuracy': 0.35650000000000004, 'loss': 0.014313417315483093, 'std': 0.0905, 'EER': -1}\n",
      "[122] Eval metrics for task 3 >> {'accuracy': 0.538, 'loss': 0.004648411810398102, 'std': 0.099, 'EER': -1}\n",
      "[123] Eval metrics for task 1 >> {'accuracy': 0.3665, 'loss': 0.01974447464942932, 'std': 0.04349999999999998, 'EER': -1}\n",
      "[123] Eval metrics for task 2 >> {'accuracy': 0.34199999999999997, 'loss': 0.016082412481307984, 'std': 0.04100000000000001, 'EER': -1}\n",
      "[123] Eval metrics for task 3 >> {'accuracy': 0.5175000000000001, 'loss': 0.004891957461833954, 'std': 0.008500000000000008, 'EER': -1}\n",
      "[124] Eval metrics for task 1 >> {'accuracy': 0.301, 'loss': 0.02936146521568298, 'std': 0.13499999999999998, 'EER': -1}\n",
      "[124] Eval metrics for task 2 >> {'accuracy': 0.27449999999999997, 'loss': 0.02024688243865967, 'std': 0.0905, 'EER': -1}\n",
      "[124] Eval metrics for task 3 >> {'accuracy': 0.6205, 'loss': 0.005073521733283997, 'std': 0.14850000000000002, 'EER': -1}\n",
      "[125] Eval metrics for task 1 >> {'accuracy': 0.35450000000000004, 'loss': 0.017821989774703978, 'std': 0.0985, 'EER': -1}\n",
      "[125] Eval metrics for task 2 >> {'accuracy': 0.314, 'loss': 0.01529168951511383, 'std': 0.045999999999999985, 'EER': -1}\n",
      "[125] Eval metrics for task 3 >> {'accuracy': 0.5945, 'loss': 0.0038048008978366853, 'std': 0.07350000000000001, 'EER': -1}\n",
      "[126] Eval metrics for task 1 >> {'accuracy': 0.443, 'loss': 0.01501828920841217, 'std': 0.09000000000000002, 'EER': -1}\n",
      "[126] Eval metrics for task 2 >> {'accuracy': 0.33999999999999997, 'loss': 0.013983788013458252, 'std': 0.08199999999999999, 'EER': -1}\n",
      "[126] Eval metrics for task 3 >> {'accuracy': 0.585, 'loss': 0.004212352752685547, 'std': 0.024999999999999967, 'EER': -1}\n",
      "[127] Eval metrics for task 1 >> {'accuracy': 0.467, 'loss': 0.015625378847122194, 'std': 0.066, 'EER': -1}\n",
      "[127] Eval metrics for task 2 >> {'accuracy': 0.4125, 'loss': 0.013007484793663026, 'std': 0.0965, 'EER': -1}\n",
      "[127] Eval metrics for task 3 >> {'accuracy': 0.4635, 'loss': 0.0059934968948364255, 'std': 0.08050000000000002, 'EER': -1}\n",
      "[128] Eval metrics for task 1 >> {'accuracy': 0.46199999999999997, 'loss': 0.014583645582199097, 'std': 0.037000000000000005, 'EER': -1}\n",
      "[128] Eval metrics for task 2 >> {'accuracy': 0.322, 'loss': 0.015528963804244995, 'std': 0.006000000000000005, 'EER': -1}\n",
      "[128] Eval metrics for task 3 >> {'accuracy': 0.5834999999999999, 'loss': 0.004180115342140198, 'std': 0.020500000000000018, 'EER': -1}\n",
      "[129] Eval metrics for task 1 >> {'accuracy': 0.383, 'loss': 0.0186573965549469, 'std': 0.13, 'EER': -1}\n",
      "[129] Eval metrics for task 2 >> {'accuracy': 0.39249999999999996, 'loss': 0.013679170727729797, 'std': 0.1015, 'EER': -1}\n",
      "[129] Eval metrics for task 3 >> {'accuracy': 0.529, 'loss': 0.005108854293823242, 'std': 0.095, 'EER': -1}\n",
      "[130] Eval metrics for task 1 >> {'accuracy': 0.43800000000000006, 'loss': 0.014951928496360779, 'std': 0.11400000000000002, 'EER': -1}\n",
      "[130] Eval metrics for task 2 >> {'accuracy': 0.37, 'loss': 0.013835858225822449, 'std': 0.08300000000000002, 'EER': -1}\n",
      "[130] Eval metrics for task 3 >> {'accuracy': 0.5865, 'loss': 0.00425260841846466, 'std': 0.02150000000000002, 'EER': -1}\n",
      "[131] Eval metrics for task 1 >> {'accuracy': 0.44400000000000006, 'loss': 0.0149787917137146, 'std': 0.10800000000000001, 'EER': -1}\n",
      "[131] Eval metrics for task 2 >> {'accuracy': 0.38349999999999995, 'loss': 0.013453372120857239, 'std': 0.0965, 'EER': -1}\n",
      "[131] Eval metrics for task 3 >> {'accuracy': 0.5660000000000001, 'loss': 0.004504020392894745, 'std': 0.01699999999999996, 'EER': -1}\n",
      "[132] Eval metrics for task 1 >> {'accuracy': 0.4365, 'loss': 0.015151156663894653, 'std': 0.10950000000000001, 'EER': -1}\n",
      "[132] Eval metrics for task 2 >> {'accuracy': 0.37, 'loss': 0.013598683595657348, 'std': 0.095, 'EER': -1}\n",
      "[132] Eval metrics for task 3 >> {'accuracy': 0.5755, 'loss': 0.004414286643266678, 'std': 0.04249999999999998, 'EER': -1}\n",
      "[133] Eval metrics for task 1 >> {'accuracy': 0.442, 'loss': 0.015273116827011109, 'std': 0.09700000000000003, 'EER': -1}\n",
      "[133] Eval metrics for task 2 >> {'accuracy': 0.39, 'loss': 0.013339603304862975, 'std': 0.1, 'EER': -1}\n",
      "[133] Eval metrics for task 3 >> {'accuracy': 0.562, 'loss': 0.004635696351528168, 'std': 0.01799999999999996, 'EER': -1}\n",
      "[134] Eval metrics for task 1 >> {'accuracy': 0.43000000000000005, 'loss': 0.015464374899864197, 'std': 0.11700000000000002, 'EER': -1}\n",
      "[134] Eval metrics for task 2 >> {'accuracy': 0.373, 'loss': 0.013586065411567688, 'std': 0.09999999999999998, 'EER': -1}\n",
      "[134] Eval metrics for task 3 >> {'accuracy': 0.5755, 'loss': 0.004395136773586273, 'std': 0.021499999999999964, 'EER': -1}\n",
      "[135] Eval metrics for task 1 >> {'accuracy': 0.46849999999999997, 'loss': 0.014578659892082214, 'std': 0.09949999999999998, 'EER': -1}\n",
      "[135] Eval metrics for task 2 >> {'accuracy': 0.396, 'loss': 0.013154344201087952, 'std': 0.092, 'EER': -1}\n",
      "[135] Eval metrics for task 3 >> {'accuracy': 0.5485, 'loss': 0.0047830771803855894, 'std': 0.02949999999999997, 'EER': -1}\n",
      "[136] Eval metrics for task 1 >> {'accuracy': 0.43000000000000005, 'loss': 0.015535653591156006, 'std': 0.11300000000000002, 'EER': -1}\n",
      "[136] Eval metrics for task 2 >> {'accuracy': 0.3655, 'loss': 0.0138702632188797, 'std': 0.08250000000000002, 'EER': -1}\n",
      "[136] Eval metrics for task 3 >> {'accuracy': 0.585, 'loss': 0.004283532053232193, 'std': 0.04199999999999998, 'EER': -1}\n",
      "[137] Eval metrics for task 1 >> {'accuracy': 0.4595, 'loss': 0.014466116786003113, 'std': 0.09750000000000003, 'EER': -1}\n",
      "[137] Eval metrics for task 2 >> {'accuracy': 0.3825, 'loss': 0.01345586919784546, 'std': 0.10349999999999998, 'EER': -1}\n",
      "[137] Eval metrics for task 3 >> {'accuracy': 0.5545, 'loss': 0.004658365607261658, 'std': 0.03049999999999997, 'EER': -1}\n",
      "[138] Eval metrics for task 1 >> {'accuracy': 0.44500000000000006, 'loss': 0.015034868597984315, 'std': 0.10500000000000001, 'EER': -1}\n",
      "[138] Eval metrics for task 2 >> {'accuracy': 0.376, 'loss': 0.013633134484291076, 'std': 0.10899999999999999, 'EER': -1}\n",
      "[138] Eval metrics for task 3 >> {'accuracy': 0.5655, 'loss': 0.004522588312625885, 'std': 0.02749999999999997, 'EER': -1}\n",
      "[139] Eval metrics for task 1 >> {'accuracy': 0.456, 'loss': 0.014497398138046265, 'std': 0.09100000000000003, 'EER': -1}\n",
      "[139] Eval metrics for task 2 >> {'accuracy': 0.39849999999999997, 'loss': 0.013017522096633911, 'std': 0.0975, 'EER': -1}\n",
      "[139] Eval metrics for task 3 >> {'accuracy': 0.5429999999999999, 'loss': 0.004833644807338715, 'std': 0.02799999999999997, 'EER': -1}\n",
      "[140] Eval metrics for task 1 >> {'accuracy': 0.45, 'loss': 0.014474962711334229, 'std': 0.09300000000000003, 'EER': -1}\n",
      "[140] Eval metrics for task 2 >> {'accuracy': 0.3855, 'loss': 0.013209694266319275, 'std': 0.11149999999999999, 'EER': -1}\n",
      "[140] Eval metrics for task 3 >> {'accuracy': 0.5529999999999999, 'loss': 0.004649763345718384, 'std': 0.02899999999999997, 'EER': -1}\n",
      "[141] Eval metrics for task 1 >> {'accuracy': 0.4525, 'loss': 0.014898383855819703, 'std': 0.10050000000000003, 'EER': -1}\n",
      "[141] Eval metrics for task 2 >> {'accuracy': 0.386, 'loss': 0.01341702675819397, 'std': 0.094, 'EER': -1}\n",
      "[141] Eval metrics for task 3 >> {'accuracy': 0.554, 'loss': 0.004738364934921265, 'std': 0.04899999999999999, 'EER': -1}\n",
      "[142] Eval metrics for task 1 >> {'accuracy': 0.451, 'loss': 0.014527764797210694, 'std': 0.10400000000000004, 'EER': -1}\n",
      "[142] Eval metrics for task 2 >> {'accuracy': 0.3745, 'loss': 0.013648635625839234, 'std': 0.10649999999999998, 'EER': -1}\n",
      "[142] Eval metrics for task 3 >> {'accuracy': 0.5675, 'loss': 0.0045543363690376286, 'std': 0.03249999999999997, 'EER': -1}\n",
      "[143] Eval metrics for task 1 >> {'accuracy': 0.444, 'loss': 0.01456915855407715, 'std': 0.09700000000000003, 'EER': -1}\n",
      "[143] Eval metrics for task 2 >> {'accuracy': 0.3925, 'loss': 0.013186542987823487, 'std': 0.11649999999999999, 'EER': -1}\n",
      "[143] Eval metrics for task 3 >> {'accuracy': 0.5429999999999999, 'loss': 0.004882955014705658, 'std': 0.03199999999999997, 'EER': -1}\n",
      "[144] Eval metrics for task 1 >> {'accuracy': 0.4535, 'loss': 0.014918269753456117, 'std': 0.09550000000000003, 'EER': -1}\n",
      "[144] Eval metrics for task 2 >> {'accuracy': 0.38549999999999995, 'loss': 0.013449674129486083, 'std': 0.0905, 'EER': -1}\n",
      "[144] Eval metrics for task 3 >> {'accuracy': 0.5549999999999999, 'loss': 0.004684177935123443, 'std': 0.045999999999999985, 'EER': -1}\n",
      "[145] Eval metrics for task 1 >> {'accuracy': 0.456, 'loss': 0.014839704632759094, 'std': 0.09800000000000003, 'EER': -1}\n",
      "[145] Eval metrics for task 2 >> {'accuracy': 0.38849999999999996, 'loss': 0.013452494382858277, 'std': 0.0865, 'EER': -1}\n",
      "[145] Eval metrics for task 3 >> {'accuracy': 0.5569999999999999, 'loss': 0.0046969007849693295, 'std': 0.03699999999999998, 'EER': -1}\n",
      "[146] Eval metrics for task 1 >> {'accuracy': 0.43300000000000005, 'loss': 0.01515363073348999, 'std': 0.11100000000000002, 'EER': -1}\n",
      "[146] Eval metrics for task 2 >> {'accuracy': 0.36450000000000005, 'loss': 0.01379268217086792, 'std': 0.0935, 'EER': -1}\n",
      "[146] Eval metrics for task 3 >> {'accuracy': 0.5874999999999999, 'loss': 0.004226267993450165, 'std': 0.019500000000000017, 'EER': -1}\n",
      "[147] Eval metrics for task 1 >> {'accuracy': 0.4425, 'loss': 0.01497517216205597, 'std': 0.10450000000000001, 'EER': -1}\n",
      "[147] Eval metrics for task 2 >> {'accuracy': 0.38849999999999996, 'loss': 0.013326905965805054, 'std': 0.10250000000000001, 'EER': -1}\n",
      "[147] Eval metrics for task 3 >> {'accuracy': 0.5549999999999999, 'loss': 0.004695341408252716, 'std': 0.03199999999999997, 'EER': -1}\n",
      "[148] Eval metrics for task 1 >> {'accuracy': 0.4605, 'loss': 0.01423381781578064, 'std': 0.09150000000000003, 'EER': -1}\n",
      "[148] Eval metrics for task 2 >> {'accuracy': 0.397, 'loss': 0.01304630434513092, 'std': 0.099, 'EER': -1}\n",
      "[148] Eval metrics for task 3 >> {'accuracy': 0.544, 'loss': 0.004776742815971374, 'std': 0.024999999999999967, 'EER': -1}\n",
      "[149] Eval metrics for task 1 >> {'accuracy': 0.45949999999999996, 'loss': 0.014463016986846924, 'std': 0.10949999999999999, 'EER': -1}\n",
      "[149] Eval metrics for task 2 >> {'accuracy': 0.38149999999999995, 'loss': 0.013384485960006715, 'std': 0.0885, 'EER': -1}\n",
      "[149] Eval metrics for task 3 >> {'accuracy': 0.5680000000000001, 'loss': 0.004469558119773865, 'std': 0.019999999999999962, 'EER': -1}\n",
      "[150] Eval metrics for task 1 >> {'accuracy': 0.4375, 'loss': 0.015159907102584838, 'std': 0.1015, 'EER': -1}\n",
      "[150] Eval metrics for task 2 >> {'accuracy': 0.375, 'loss': 0.013534281611442565, 'std': 0.09699999999999998, 'EER': -1}\n",
      "[150] Eval metrics for task 3 >> {'accuracy': 0.5745, 'loss': 0.004361496806144715, 'std': 0.03049999999999997, 'EER': -1}\n",
      "training_task_end\n",
      "---------------------------- Task 4 -----------------------\n",
      "[151] Eval metrics for task 1 >> {'accuracy': 0.617, 'loss': 0.006834433376789093, 'std': 0.0040000000000000036, 'EER': -1}\n",
      "[151] Eval metrics for task 2 >> {'accuracy': 0.041499999999999995, 'loss': 0.011201695561408997, 'std': 0.0335, 'EER': -1}\n",
      "[151] Eval metrics for task 3 >> {'accuracy': 0.001, 'loss': 0.014291071176528931, 'std': 0.001, 'EER': -1}\n",
      "[151] Eval metrics for task 4 >> {'accuracy': 0.6435, 'loss': 0.004093418717384338, 'std': 0.18249999999999994, 'EER': -1}\n",
      "[152] Eval metrics for task 1 >> {'accuracy': 0.39949999999999997, 'loss': 0.013386593580245972, 'std': 0.19649999999999998, 'EER': -1}\n",
      "[152] Eval metrics for task 2 >> {'accuracy': 0.141, 'loss': 0.01355043113231659, 'std': 0.038, 'EER': -1}\n",
      "[152] Eval metrics for task 3 >> {'accuracy': 0.006, 'loss': 0.010108840584754943, 'std': 0.006, 'EER': -1}\n",
      "[152] Eval metrics for task 4 >> {'accuracy': 0.6925, 'loss': 0.0035093648433685305, 'std': 0.05249999999999999, 'EER': -1}\n",
      "[153] Eval metrics for task 1 >> {'accuracy': 0.336, 'loss': 0.01617516601085663, 'std': 0.17800000000000002, 'EER': -1}\n",
      "[153] Eval metrics for task 2 >> {'accuracy': 0.209, 'loss': 0.017537960767745973, 'std': 0.09699999999999999, 'EER': -1}\n",
      "[153] Eval metrics for task 3 >> {'accuracy': 0.325, 'loss': 0.007937792479991913, 'std': 0.045999999999999985, 'EER': -1}\n",
      "[153] Eval metrics for task 4 >> {'accuracy': 0.5015000000000001, 'loss': 0.006419362008571625, 'std': 0.007500000000000007, 'EER': -1}\n",
      "[154] Eval metrics for task 1 >> {'accuracy': 0.3375, 'loss': 0.023276041507720946, 'std': 0.0325, 'EER': -1}\n",
      "[154] Eval metrics for task 2 >> {'accuracy': 0.256, 'loss': 0.019888195753097533, 'std': 0.05299999999999999, 'EER': -1}\n",
      "[154] Eval metrics for task 3 >> {'accuracy': 0.26949999999999996, 'loss': 0.010432075142860413, 'std': 0.07449999999999998, 'EER': -1}\n",
      "[154] Eval metrics for task 4 >> {'accuracy': 0.627, 'loss': 0.004566915452480316, 'std': 0.128, 'EER': -1}\n",
      "[155] Eval metrics for task 1 >> {'accuracy': 0.4075, 'loss': 0.014139449238777161, 'std': 0.18049999999999997, 'EER': -1}\n",
      "[155] Eval metrics for task 2 >> {'accuracy': 0.11299999999999999, 'loss': 0.02137839388847351, 'std': 0.033999999999999996, 'EER': -1}\n",
      "[155] Eval metrics for task 3 >> {'accuracy': 0.33699999999999997, 'loss': 0.008719708859920502, 'std': 0.033, 'EER': -1}\n",
      "[155] Eval metrics for task 4 >> {'accuracy': 0.7545, 'loss': 0.0025708101391792295, 'std': 0.014500000000000013, 'EER': -1}\n",
      "[156] Eval metrics for task 1 >> {'accuracy': 0.363, 'loss': 0.01825247836112976, 'std': 0.17500000000000002, 'EER': -1}\n",
      "[156] Eval metrics for task 2 >> {'accuracy': 0.172, 'loss': 0.020300437927246093, 'std': 0.046, 'EER': -1}\n",
      "[156] Eval metrics for task 3 >> {'accuracy': 0.4395, 'loss': 0.008748401761054993, 'std': 0.10650000000000001, 'EER': -1}\n",
      "[156] Eval metrics for task 4 >> {'accuracy': 0.6745, 'loss': 0.0035158625841140746, 'std': 0.09250000000000003, 'EER': -1}\n",
      "[157] Eval metrics for task 1 >> {'accuracy': 0.367, 'loss': 0.018315530180931093, 'std': 0.13299999999999998, 'EER': -1}\n",
      "[157] Eval metrics for task 2 >> {'accuracy': 0.14150000000000001, 'loss': 0.023848770618438722, 'std': 0.028500000000000004, 'EER': -1}\n",
      "[157] Eval metrics for task 3 >> {'accuracy': 0.395, 'loss': 0.009636996030807496, 'std': 0.02099999999999999, 'EER': -1}\n",
      "[157] Eval metrics for task 4 >> {'accuracy': 0.673, 'loss': 0.003191160798072815, 'std': 0.01899999999999996, 'EER': -1}\n",
      "[158] Eval metrics for task 1 >> {'accuracy': 0.356, 'loss': 0.019808188676834107, 'std': 0.11000000000000001, 'EER': -1}\n",
      "[158] Eval metrics for task 2 >> {'accuracy': 0.1285, 'loss': 0.02379892659187317, 'std': 0.007500000000000007, 'EER': -1}\n",
      "[158] Eval metrics for task 3 >> {'accuracy': 0.3755, 'loss': 0.010219710469245911, 'std': 0.029500000000000026, 'EER': -1}\n",
      "[158] Eval metrics for task 4 >> {'accuracy': 0.764, 'loss': 0.002442850321531296, 'std': 0.025000000000000022, 'EER': -1}\n",
      "[159] Eval metrics for task 1 >> {'accuracy': 0.34750000000000003, 'loss': 0.020608857154846193, 'std': 0.10850000000000001, 'EER': -1}\n",
      "[159] Eval metrics for task 2 >> {'accuracy': 0.22199999999999998, 'loss': 0.02015514874458313, 'std': 0.013999999999999999, 'EER': -1}\n",
      "[159] Eval metrics for task 3 >> {'accuracy': 0.4195, 'loss': 0.009546277403831483, 'std': 0.05049999999999999, 'EER': -1}\n",
      "[159] Eval metrics for task 4 >> {'accuracy': 0.7190000000000001, 'loss': 0.002967612951993942, 'std': 0.03899999999999998, 'EER': -1}\n",
      "[160] Eval metrics for task 1 >> {'accuracy': 0.401, 'loss': 0.01727795088291168, 'std': 0.101, 'EER': -1}\n",
      "[160] Eval metrics for task 2 >> {'accuracy': 0.16549999999999998, 'loss': 0.025384426593780516, 'std': 0.03849999999999999, 'EER': -1}\n",
      "[160] Eval metrics for task 3 >> {'accuracy': 0.381, 'loss': 0.011206591725349426, 'std': 0.017000000000000015, 'EER': -1}\n",
      "[160] Eval metrics for task 4 >> {'accuracy': 0.653, 'loss': 0.0034874586760997774, 'std': 0.018000000000000016, 'EER': -1}\n",
      "[161] Eval metrics for task 1 >> {'accuracy': 0.3095, 'loss': 0.02208310055732727, 'std': 0.09550000000000002, 'EER': -1}\n",
      "[161] Eval metrics for task 2 >> {'accuracy': 0.16899999999999998, 'loss': 0.023463537454605103, 'std': 0.03499999999999999, 'EER': -1}\n",
      "[161] Eval metrics for task 3 >> {'accuracy': 0.346, 'loss': 0.01178611123561859, 'std': 0.07199999999999998, 'EER': -1}\n",
      "[161] Eval metrics for task 4 >> {'accuracy': 0.8095, 'loss': 0.0020627942234277725, 'std': 0.034499999999999975, 'EER': -1}\n",
      "[162] Eval metrics for task 1 >> {'accuracy': 0.4255, 'loss': 0.017255770444869995, 'std': 0.007500000000000007, 'EER': -1}\n",
      "[162] Eval metrics for task 2 >> {'accuracy': 0.177, 'loss': 0.025383641481399537, 'std': 0.011999999999999997, 'EER': -1}\n",
      "[162] Eval metrics for task 3 >> {'accuracy': 0.325, 'loss': 0.013260823369026184, 'std': 0.010000000000000009, 'EER': -1}\n",
      "[162] Eval metrics for task 4 >> {'accuracy': 0.7235, 'loss': 0.002887695640325546, 'std': 0.018500000000000016, 'EER': -1}\n",
      "[163] Eval metrics for task 1 >> {'accuracy': 0.3725, 'loss': 0.02014144492149353, 'std': 0.14650000000000002, 'EER': -1}\n",
      "[163] Eval metrics for task 2 >> {'accuracy': 0.1595, 'loss': 0.02424322509765625, 'std': 0.024499999999999994, 'EER': -1}\n",
      "[163] Eval metrics for task 3 >> {'accuracy': 0.37, 'loss': 0.011589347958564759, 'std': 0.055999999999999994, 'EER': -1}\n",
      "[163] Eval metrics for task 4 >> {'accuracy': 0.7805, 'loss': 0.0024419846832752228, 'std': 0.03150000000000003, 'EER': -1}\n",
      "[164] Eval metrics for task 1 >> {'accuracy': 0.34249999999999997, 'loss': 0.020931856155395508, 'std': 0.1375, 'EER': -1}\n",
      "[164] Eval metrics for task 2 >> {'accuracy': 0.21400000000000002, 'loss': 0.02298272180557251, 'std': 0.06600000000000002, 'EER': -1}\n",
      "[164] Eval metrics for task 3 >> {'accuracy': 0.39549999999999996, 'loss': 0.011455690383911133, 'std': 0.07949999999999999, 'EER': -1}\n",
      "[164] Eval metrics for task 4 >> {'accuracy': 0.753, 'loss': 0.0027865092158317565, 'std': 0.031000000000000028, 'EER': -1}\n",
      "[165] Eval metrics for task 1 >> {'accuracy': 0.41200000000000003, 'loss': 0.018723867893218994, 'std': 0.14, 'EER': -1}\n",
      "[165] Eval metrics for task 2 >> {'accuracy': 0.185, 'loss': 0.024097958087921142, 'std': 0.0030000000000000027, 'EER': -1}\n",
      "[165] Eval metrics for task 3 >> {'accuracy': 0.4135, 'loss': 0.010612547874450684, 'std': 0.0925, 'EER': -1}\n",
      "[165] Eval metrics for task 4 >> {'accuracy': 0.758, 'loss': 0.0025258701145648957, 'std': 0.020000000000000018, 'EER': -1}\n",
      "[166] Eval metrics for task 1 >> {'accuracy': 0.42400000000000004, 'loss': 0.017607932209968567, 'std': 0.091, 'EER': -1}\n",
      "[166] Eval metrics for task 2 >> {'accuracy': 0.186, 'loss': 0.024941413402557372, 'std': 0.033, 'EER': -1}\n",
      "[166] Eval metrics for task 3 >> {'accuracy': 0.4575, 'loss': 0.010058845400810241, 'std': 0.07450000000000001, 'EER': -1}\n",
      "[166] Eval metrics for task 4 >> {'accuracy': 0.739, 'loss': 0.0029298027157783507, 'std': 0.006000000000000005, 'EER': -1}\n",
      "[167] Eval metrics for task 1 >> {'accuracy': 0.3555, 'loss': 0.0219017813205719, 'std': 0.0605, 'EER': -1}\n",
      "[167] Eval metrics for task 2 >> {'accuracy': 0.1885, 'loss': 0.02570059084892273, 'std': 0.1045, 'EER': -1}\n",
      "[167] Eval metrics for task 3 >> {'accuracy': 0.4145, 'loss': 0.011599820852279664, 'std': 0.0685, 'EER': -1}\n",
      "[167] Eval metrics for task 4 >> {'accuracy': 0.7025, 'loss': 0.003360634207725525, 'std': 0.015499999999999958, 'EER': -1}\n",
      "[168] Eval metrics for task 1 >> {'accuracy': 0.3765, 'loss': 0.021203481435775755, 'std': 0.1305, 'EER': -1}\n",
      "[168] Eval metrics for task 2 >> {'accuracy': 0.178, 'loss': 0.023097388029098512, 'std': 0.007999999999999993, 'EER': -1}\n",
      "[168] Eval metrics for task 3 >> {'accuracy': 0.3645, 'loss': 0.011287457585334778, 'std': 0.1325, 'EER': -1}\n",
      "[168] Eval metrics for task 4 >> {'accuracy': 0.768, 'loss': 0.0025468537658452986, 'std': 0.064, 'EER': -1}\n",
      "[169] Eval metrics for task 1 >> {'accuracy': 0.376, 'loss': 0.019708006739616393, 'std': 0.093, 'EER': -1}\n",
      "[169] Eval metrics for task 2 >> {'accuracy': 0.1765, 'loss': 0.024710376739501952, 'std': 0.022500000000000006, 'EER': -1}\n",
      "[169] Eval metrics for task 3 >> {'accuracy': 0.3785, 'loss': 0.012130444407463074, 'std': 0.04149999999999998, 'EER': -1}\n",
      "[169] Eval metrics for task 4 >> {'accuracy': 0.7875, 'loss': 0.0023878591656684876, 'std': 0.02849999999999997, 'EER': -1}\n",
      "[170] Eval metrics for task 1 >> {'accuracy': 0.3705, 'loss': 0.021386538028717043, 'std': 0.08450000000000002, 'EER': -1}\n",
      "[170] Eval metrics for task 2 >> {'accuracy': 0.1915, 'loss': 0.024892486333847046, 'std': 0.0025000000000000022, 'EER': -1}\n",
      "[170] Eval metrics for task 3 >> {'accuracy': 0.392, 'loss': 0.01152976655960083, 'std': 0.064, 'EER': -1}\n",
      "[170] Eval metrics for task 4 >> {'accuracy': 0.753, 'loss': 0.0026884911954402923, 'std': 0.01200000000000001, 'EER': -1}\n",
      "[171] Eval metrics for task 1 >> {'accuracy': 0.40149999999999997, 'loss': 0.01818876016139984, 'std': 0.02049999999999999, 'EER': -1}\n",
      "[171] Eval metrics for task 2 >> {'accuracy': 0.153, 'loss': 0.028204065084457396, 'std': 0.0010000000000000009, 'EER': -1}\n",
      "[171] Eval metrics for task 3 >> {'accuracy': 0.3395, 'loss': 0.014257650136947632, 'std': 0.02049999999999999, 'EER': -1}\n",
      "[171] Eval metrics for task 4 >> {'accuracy': 0.6745000000000001, 'loss': 0.0034261286556720736, 'std': 0.012500000000000011, 'EER': -1}\n",
      "[172] Eval metrics for task 1 >> {'accuracy': 0.4255, 'loss': 0.01955702304840088, 'std': 0.12350000000000003, 'EER': -1}\n",
      "[172] Eval metrics for task 2 >> {'accuracy': 0.15, 'loss': 0.027162224292755128, 'std': 0.026999999999999996, 'EER': -1}\n",
      "[172] Eval metrics for task 3 >> {'accuracy': 0.396, 'loss': 0.011434121489524841, 'std': 0.07599999999999998, 'EER': -1}\n",
      "[172] Eval metrics for task 4 >> {'accuracy': 0.8, 'loss': 0.0022089099138975143, 'std': 0.030999999999999972, 'EER': -1}\n",
      "[173] Eval metrics for task 1 >> {'accuracy': 0.39049999999999996, 'loss': 0.021491421937942505, 'std': 0.0965, 'EER': -1}\n",
      "[173] Eval metrics for task 2 >> {'accuracy': 0.183, 'loss': 0.02615407943725586, 'std': 0.048, 'EER': -1}\n",
      "[173] Eval metrics for task 3 >> {'accuracy': 0.384, 'loss': 0.01254365909099579, 'std': 0.10299999999999998, 'EER': -1}\n",
      "[173] Eval metrics for task 4 >> {'accuracy': 0.7665, 'loss': 0.002794090390205383, 'std': 0.057499999999999996, 'EER': -1}\n",
      "[174] Eval metrics for task 1 >> {'accuracy': 0.391, 'loss': 0.020631659269332886, 'std': 0.10999999999999999, 'EER': -1}\n",
      "[174] Eval metrics for task 2 >> {'accuracy': 0.216, 'loss': 0.02332416772842407, 'std': 0.03, 'EER': -1}\n",
      "[174] Eval metrics for task 3 >> {'accuracy': 0.40249999999999997, 'loss': 0.012122800707817077, 'std': 0.07549999999999998, 'EER': -1}\n",
      "[174] Eval metrics for task 4 >> {'accuracy': 0.749, 'loss': 0.0028068765997886656, 'std': 0.040000000000000036, 'EER': -1}\n",
      "[175] Eval metrics for task 1 >> {'accuracy': 0.43500000000000005, 'loss': 0.018844502687454225, 'std': 0.11300000000000002, 'EER': -1}\n",
      "[175] Eval metrics for task 2 >> {'accuracy': 0.185, 'loss': 0.02739390182495117, 'std': 0.007000000000000006, 'EER': -1}\n",
      "[175] Eval metrics for task 3 >> {'accuracy': 0.4205, 'loss': 0.012072175741195679, 'std': 0.0915, 'EER': -1}\n",
      "[175] Eval metrics for task 4 >> {'accuracy': 0.7605, 'loss': 0.002628698945045471, 'std': 0.029500000000000026, 'EER': -1}\n",
      "[176] Eval metrics for task 1 >> {'accuracy': 0.363, 'loss': 0.02032923984527588, 'std': 0.044999999999999984, 'EER': -1}\n",
      "[176] Eval metrics for task 2 >> {'accuracy': 0.2255, 'loss': 0.02459003281593323, 'std': 0.022499999999999992, 'EER': -1}\n",
      "[176] Eval metrics for task 3 >> {'accuracy': 0.36350000000000005, 'loss': 0.013497385025024414, 'std': 0.024499999999999994, 'EER': -1}\n",
      "[176] Eval metrics for task 4 >> {'accuracy': 0.742, 'loss': 0.002880998820066452, 'std': 0.016000000000000014, 'EER': -1}\n",
      "[177] Eval metrics for task 1 >> {'accuracy': 0.499, 'loss': 0.016278531432151796, 'std': 0.061000000000000026, 'EER': -1}\n",
      "[177] Eval metrics for task 2 >> {'accuracy': 0.1875, 'loss': 0.02586882781982422, 'std': 0.012500000000000011, 'EER': -1}\n",
      "[177] Eval metrics for task 3 >> {'accuracy': 0.4075, 'loss': 0.012349953889846802, 'std': 0.04450000000000001, 'EER': -1}\n",
      "[177] Eval metrics for task 4 >> {'accuracy': 0.6859999999999999, 'loss': 0.003353298306465149, 'std': 0.01599999999999996, 'EER': -1}\n",
      "[178] Eval metrics for task 1 >> {'accuracy': 0.362, 'loss': 0.01942643404006958, 'std': 0.014000000000000012, 'EER': -1}\n",
      "[178] Eval metrics for task 2 >> {'accuracy': 0.155, 'loss': 0.02827798843383789, 'std': 0.06999999999999999, 'EER': -1}\n",
      "[178] Eval metrics for task 3 >> {'accuracy': 0.3145, 'loss': 0.014426344394683838, 'std': 0.03749999999999998, 'EER': -1}\n",
      "[178] Eval metrics for task 4 >> {'accuracy': 0.794, 'loss': 0.0022094475477933886, 'std': 0.03899999999999998, 'EER': -1}\n",
      "[179] Eval metrics for task 1 >> {'accuracy': 0.36650000000000005, 'loss': 0.020000357866287233, 'std': 0.0945, 'EER': -1}\n",
      "[179] Eval metrics for task 2 >> {'accuracy': 0.17049999999999998, 'loss': 0.025407623767852782, 'std': 0.008499999999999994, 'EER': -1}\n",
      "[179] Eval metrics for task 3 >> {'accuracy': 0.368, 'loss': 0.012466410398483277, 'std': 0.0040000000000000036, 'EER': -1}\n",
      "[179] Eval metrics for task 4 >> {'accuracy': 0.81, 'loss': 0.0021221341788768768, 'std': 0.013999999999999957, 'EER': -1}\n",
      "[180] Eval metrics for task 1 >> {'accuracy': 0.3645, 'loss': 0.019982394456863402, 'std': 0.1185, 'EER': -1}\n",
      "[180] Eval metrics for task 2 >> {'accuracy': 0.14600000000000002, 'loss': 0.027261659145355225, 'std': 0.012999999999999998, 'EER': -1}\n",
      "[180] Eval metrics for task 3 >> {'accuracy': 0.3435, 'loss': 0.013162346363067626, 'std': 0.04150000000000001, 'EER': -1}\n",
      "[180] Eval metrics for task 4 >> {'accuracy': 0.839, 'loss': 0.0018391097784042358, 'std': 0.0010000000000000009, 'EER': -1}\n",
      "[181] Eval metrics for task 1 >> {'accuracy': 0.365, 'loss': 0.020238144636154174, 'std': 0.12, 'EER': -1}\n",
      "[181] Eval metrics for task 2 >> {'accuracy': 0.15949999999999998, 'loss': 0.02626389193534851, 'std': 0.018500000000000003, 'EER': -1}\n",
      "[181] Eval metrics for task 3 >> {'accuracy': 0.358, 'loss': 0.01258951997756958, 'std': 0.036000000000000004, 'EER': -1}\n",
      "[181] Eval metrics for task 4 >> {'accuracy': 0.829, 'loss': 0.001956086352467537, 'std': 0.007000000000000006, 'EER': -1}\n",
      "[182] Eval metrics for task 1 >> {'accuracy': 0.367, 'loss': 0.020414535999298097, 'std': 0.118, 'EER': -1}\n",
      "[182] Eval metrics for task 2 >> {'accuracy': 0.173, 'loss': 0.025756809234619142, 'std': 0.015, 'EER': -1}\n",
      "[182] Eval metrics for task 3 >> {'accuracy': 0.358, 'loss': 0.012656711459159852, 'std': 0.03900000000000001, 'EER': -1}\n",
      "[182] Eval metrics for task 4 >> {'accuracy': 0.827, 'loss': 0.002003950595855713, 'std': 0.014000000000000012, 'EER': -1}\n",
      "[183] Eval metrics for task 1 >> {'accuracy': 0.35, 'loss': 0.02125954294204712, 'std': 0.12499999999999999, 'EER': -1}\n",
      "[183] Eval metrics for task 2 >> {'accuracy': 0.153, 'loss': 0.026831301212310792, 'std': 0.01899999999999999, 'EER': -1}\n",
      "[183] Eval metrics for task 3 >> {'accuracy': 0.32699999999999996, 'loss': 0.013538309574127197, 'std': 0.032, 'EER': -1}\n",
      "[183] Eval metrics for task 4 >> {'accuracy': 0.8514999999999999, 'loss': 0.0017294849753379821, 'std': 0.01150000000000001, 'EER': -1}\n",
      "[184] Eval metrics for task 1 >> {'accuracy': 0.3745, 'loss': 0.019820070028305055, 'std': 0.1185, 'EER': -1}\n",
      "[184] Eval metrics for task 2 >> {'accuracy': 0.16149999999999998, 'loss': 0.026620606899261476, 'std': 0.0155, 'EER': -1}\n",
      "[184] Eval metrics for task 3 >> {'accuracy': 0.362, 'loss': 0.012798656702041626, 'std': 0.036000000000000004, 'EER': -1}\n",
      "[184] Eval metrics for task 4 >> {'accuracy': 0.8234999999999999, 'loss': 0.001992444455623627, 'std': 0.004500000000000004, 'EER': -1}\n",
      "[185] Eval metrics for task 1 >> {'accuracy': 0.3625, 'loss': 0.02060883641242981, 'std': 0.11549999999999999, 'EER': -1}\n",
      "[185] Eval metrics for task 2 >> {'accuracy': 0.16699999999999998, 'loss': 0.026235114812850954, 'std': 0.011999999999999997, 'EER': -1}\n",
      "[185] Eval metrics for task 3 >> {'accuracy': 0.345, 'loss': 0.013050293445587158, 'std': 0.036000000000000004, 'EER': -1}\n",
      "[185] Eval metrics for task 4 >> {'accuracy': 0.832, 'loss': 0.0019396968334913253, 'std': 0.01200000000000001, 'EER': -1}\n",
      "[186] Eval metrics for task 1 >> {'accuracy': 0.364, 'loss': 0.020085344552993774, 'std': 0.11499999999999999, 'EER': -1}\n",
      "[186] Eval metrics for task 2 >> {'accuracy': 0.1565, 'loss': 0.026686012744903564, 'std': 0.02049999999999999, 'EER': -1}\n",
      "[186] Eval metrics for task 3 >> {'accuracy': 0.3435, 'loss': 0.013084990978240967, 'std': 0.0325, 'EER': -1}\n",
      "[186] Eval metrics for task 4 >> {'accuracy': 0.8365, 'loss': 0.0018711819797754287, 'std': 0.009500000000000008, 'EER': -1}\n",
      "[187] Eval metrics for task 1 >> {'accuracy': 0.3655, 'loss': 0.01997184157371521, 'std': 0.1195, 'EER': -1}\n",
      "[187] Eval metrics for task 2 >> {'accuracy': 0.16149999999999998, 'loss': 0.02646255087852478, 'std': 0.011499999999999996, 'EER': -1}\n",
      "[187] Eval metrics for task 3 >> {'accuracy': 0.351, 'loss': 0.012941658854484558, 'std': 0.038000000000000006, 'EER': -1}\n",
      "[187] Eval metrics for task 4 >> {'accuracy': 0.8305, 'loss': 0.0019310250878334045, 'std': 0.0005000000000000004, 'EER': -1}\n",
      "[188] Eval metrics for task 1 >> {'accuracy': 0.3665, 'loss': 0.019701087713241576, 'std': 0.11549999999999999, 'EER': -1}\n",
      "[188] Eval metrics for task 2 >> {'accuracy': 0.1575, 'loss': 0.026696933269500733, 'std': 0.01050000000000001, 'EER': -1}\n",
      "[188] Eval metrics for task 3 >> {'accuracy': 0.35350000000000004, 'loss': 0.01296595811843872, 'std': 0.0345, 'EER': -1}\n",
      "[188] Eval metrics for task 4 >> {'accuracy': 0.829, 'loss': 0.001937891587615013, 'std': 0.006000000000000005, 'EER': -1}\n",
      "[189] Eval metrics for task 1 >> {'accuracy': 0.3615, 'loss': 0.020414746284484864, 'std': 0.1255, 'EER': -1}\n",
      "[189] Eval metrics for task 2 >> {'accuracy': 0.159, 'loss': 0.026424137592315673, 'std': 0.006000000000000005, 'EER': -1}\n",
      "[189] Eval metrics for task 3 >> {'accuracy': 0.34650000000000003, 'loss': 0.012861841201782227, 'std': 0.0345, 'EER': -1}\n",
      "[189] Eval metrics for task 4 >> {'accuracy': 0.84, 'loss': 0.0018526677638292313, 'std': 0.010000000000000009, 'EER': -1}\n",
      "[190] Eval metrics for task 1 >> {'accuracy': 0.371, 'loss': 0.020120720148086548, 'std': 0.124, 'EER': -1}\n",
      "[190] Eval metrics for task 2 >> {'accuracy': 0.16549999999999998, 'loss': 0.02655426335334778, 'std': 0.0155, 'EER': -1}\n",
      "[190] Eval metrics for task 3 >> {'accuracy': 0.368, 'loss': 0.012726695656776428, 'std': 0.043999999999999984, 'EER': -1}\n",
      "[190] Eval metrics for task 4 >> {'accuracy': 0.8185, 'loss': 0.0020698798298835757, 'std': 0.003500000000000003, 'EER': -1}\n",
      "[191] Eval metrics for task 1 >> {'accuracy': 0.3615, 'loss': 0.020376261949539183, 'std': 0.12749999999999997, 'EER': -1}\n",
      "[191] Eval metrics for task 2 >> {'accuracy': 0.154, 'loss': 0.026850871324539186, 'std': 0.010000000000000009, 'EER': -1}\n",
      "[191] Eval metrics for task 3 >> {'accuracy': 0.34750000000000003, 'loss': 0.012960817456245423, 'std': 0.035500000000000004, 'EER': -1}\n",
      "[191] Eval metrics for task 4 >> {'accuracy': 0.8434999999999999, 'loss': 0.0018248554468154906, 'std': 0.012500000000000011, 'EER': -1}\n",
      "[192] Eval metrics for task 1 >> {'accuracy': 0.373, 'loss': 0.02002509355545044, 'std': 0.123, 'EER': -1}\n",
      "[192] Eval metrics for task 2 >> {'accuracy': 0.1645, 'loss': 0.026129750728607178, 'std': 0.006500000000000006, 'EER': -1}\n",
      "[192] Eval metrics for task 3 >> {'accuracy': 0.367, 'loss': 0.012551333665847778, 'std': 0.03900000000000001, 'EER': -1}\n",
      "[192] Eval metrics for task 4 >> {'accuracy': 0.83, 'loss': 0.00196502959728241, 'std': 0.008000000000000007, 'EER': -1}\n",
      "[193] Eval metrics for task 1 >> {'accuracy': 0.3875, 'loss': 0.018802244424819946, 'std': 0.11249999999999999, 'EER': -1}\n",
      "[193] Eval metrics for task 2 >> {'accuracy': 0.1775, 'loss': 0.025937451362609863, 'std': 0.022500000000000006, 'EER': -1}\n",
      "[193] Eval metrics for task 3 >> {'accuracy': 0.375, 'loss': 0.012511019587516785, 'std': 0.035999999999999976, 'EER': -1}\n",
      "[193] Eval metrics for task 4 >> {'accuracy': 0.7995000000000001, 'loss': 0.0022485260367393492, 'std': 0.008500000000000008, 'EER': -1}\n",
      "[194] Eval metrics for task 1 >> {'accuracy': 0.3655, 'loss': 0.020000136137008667, 'std': 0.1235, 'EER': -1}\n",
      "[194] Eval metrics for task 2 >> {'accuracy': 0.16449999999999998, 'loss': 0.026097362279891966, 'std': 0.0165, 'EER': -1}\n",
      "[194] Eval metrics for task 3 >> {'accuracy': 0.355, 'loss': 0.01283778417110443, 'std': 0.04000000000000001, 'EER': -1}\n",
      "[194] Eval metrics for task 4 >> {'accuracy': 0.832, 'loss': 0.001951755627989769, 'std': 0.0030000000000000027, 'EER': -1}\n",
      "[195] Eval metrics for task 1 >> {'accuracy': 0.376, 'loss': 0.019584007263183593, 'std': 0.11299999999999999, 'EER': -1}\n",
      "[195] Eval metrics for task 2 >> {'accuracy': 0.17049999999999998, 'loss': 0.02615142011642456, 'std': 0.014499999999999999, 'EER': -1}\n",
      "[195] Eval metrics for task 3 >> {'accuracy': 0.355, 'loss': 0.012920849204063415, 'std': 0.023999999999999994, 'EER': -1}\n",
      "[195] Eval metrics for task 4 >> {'accuracy': 0.8245, 'loss': 0.0020324206948280333, 'std': 0.006500000000000006, 'EER': -1}\n",
      "[196] Eval metrics for task 1 >> {'accuracy': 0.3705, 'loss': 0.019809057235717773, 'std': 0.11649999999999999, 'EER': -1}\n",
      "[196] Eval metrics for task 2 >> {'accuracy': 0.15899999999999997, 'loss': 0.026939401626586913, 'std': 0.017, 'EER': -1}\n",
      "[196] Eval metrics for task 3 >> {'accuracy': 0.344, 'loss': 0.013196288466453552, 'std': 0.05100000000000002, 'EER': -1}\n",
      "[196] Eval metrics for task 4 >> {'accuracy': 0.8245, 'loss': 0.0019788304269313813, 'std': 0.007500000000000007, 'EER': -1}\n",
      "[197] Eval metrics for task 1 >> {'accuracy': 0.3765, 'loss': 0.019449120759963988, 'std': 0.11549999999999999, 'EER': -1}\n",
      "[197] Eval metrics for task 2 >> {'accuracy': 0.1805, 'loss': 0.025594115257263184, 'std': 0.018500000000000003, 'EER': -1}\n",
      "[197] Eval metrics for task 3 >> {'accuracy': 0.377, 'loss': 0.012462992429733276, 'std': 0.03799999999999998, 'EER': -1}\n",
      "[197] Eval metrics for task 4 >> {'accuracy': 0.8035000000000001, 'loss': 0.002242400422692299, 'std': 0.003500000000000003, 'EER': -1}\n",
      "[198] Eval metrics for task 1 >> {'accuracy': 0.377, 'loss': 0.02012972688674927, 'std': 0.12, 'EER': -1}\n",
      "[198] Eval metrics for task 2 >> {'accuracy': 0.172, 'loss': 0.025914987564086913, 'std': 0.018000000000000002, 'EER': -1}\n",
      "[198] Eval metrics for task 3 >> {'accuracy': 0.36450000000000005, 'loss': 0.01261779010295868, 'std': 0.0295, 'EER': -1}\n",
      "[198] Eval metrics for task 4 >> {'accuracy': 0.8220000000000001, 'loss': 0.0020523642897605898, 'std': 0.01899999999999996, 'EER': -1}\n",
      "[199] Eval metrics for task 1 >> {'accuracy': 0.3615, 'loss': 0.020550273895263673, 'std': 0.1245, 'EER': -1}\n",
      "[199] Eval metrics for task 2 >> {'accuracy': 0.16449999999999998, 'loss': 0.026103225946426393, 'std': 0.010499999999999995, 'EER': -1}\n",
      "[199] Eval metrics for task 3 >> {'accuracy': 0.35450000000000004, 'loss': 0.012674399256706237, 'std': 0.0315, 'EER': -1}\n",
      "[199] Eval metrics for task 4 >> {'accuracy': 0.834, 'loss': 0.0019160687625408173, 'std': 0.008000000000000007, 'EER': -1}\n",
      "[200] Eval metrics for task 1 >> {'accuracy': 0.3585, 'loss': 0.020163700580596924, 'std': 0.1175, 'EER': -1}\n",
      "[200] Eval metrics for task 2 >> {'accuracy': 0.15, 'loss': 0.026900219917297363, 'std': 0.007000000000000006, 'EER': -1}\n",
      "[200] Eval metrics for task 3 >> {'accuracy': 0.33599999999999997, 'loss': 0.013201605439186095, 'std': 0.034, 'EER': -1}\n",
      "[200] Eval metrics for task 4 >> {'accuracy': 0.844, 'loss': 0.0017832815349102021, 'std': 0.0, 'EER': -1}\n",
      "training_task_end\n",
      "---------------------------- Task 5 -----------------------\n",
      "[201] Eval metrics for task 1 >> {'accuracy': 0.34099999999999997, 'loss': 0.010747538328170776, 'std': 0.03900000000000001, 'EER': -1}\n",
      "[201] Eval metrics for task 2 >> {'accuracy': 0.1555, 'loss': 0.009288384318351746, 'std': 0.0825, 'EER': -1}\n",
      "[201] Eval metrics for task 3 >> {'accuracy': 0.0, 'loss': 0.01239001190662384, 'std': 0.0, 'EER': -1}\n",
      "[201] Eval metrics for task 4 >> {'accuracy': 0.0, 'loss': 0.013435580849647522, 'std': 0.0, 'EER': -1}\n",
      "[201] Eval metrics for task 5 >> {'accuracy': 0.598, 'loss': 0.004479999482631683, 'std': 0.018000000000000016, 'EER': -1}\n",
      "[202] Eval metrics for task 1 >> {'accuracy': 0.2625, 'loss': 0.012574640035629272, 'std': 0.01050000000000001, 'EER': -1}\n",
      "[202] Eval metrics for task 2 >> {'accuracy': 0.1545, 'loss': 0.014390214204788207, 'std': 0.04850000000000001, 'EER': -1}\n",
      "[202] Eval metrics for task 3 >> {'accuracy': 0.024, 'loss': 0.011066361069679261, 'std': 0.024, 'EER': -1}\n",
      "[202] Eval metrics for task 4 >> {'accuracy': 0.1865, 'loss': 0.009329691171646119, 'std': 0.1865, 'EER': -1}\n",
      "[202] Eval metrics for task 5 >> {'accuracy': 0.7495, 'loss': 0.003265028566122055, 'std': 0.020500000000000018, 'EER': -1}\n",
      "[203] Eval metrics for task 1 >> {'accuracy': 0.1955, 'loss': 0.022761597394943236, 'std': 0.1075, 'EER': -1}\n",
      "[203] Eval metrics for task 2 >> {'accuracy': 0.1825, 'loss': 0.020677623748779298, 'std': 0.1335, 'EER': -1}\n",
      "[203] Eval metrics for task 3 >> {'accuracy': 0.1805, 'loss': 0.012726560711860657, 'std': 0.0455, 'EER': -1}\n",
      "[203] Eval metrics for task 4 >> {'accuracy': 0.506, 'loss': 0.006443707942962646, 'std': 0.06199999999999997, 'EER': -1}\n",
      "[203] Eval metrics for task 5 >> {'accuracy': 0.7769999999999999, 'loss': 0.0029907094538211823, 'std': 0.04199999999999998, 'EER': -1}\n",
      "[204] Eval metrics for task 1 >> {'accuracy': 0.192, 'loss': 0.016901163578033448, 'std': 0.09699999999999999, 'EER': -1}\n",
      "[204] Eval metrics for task 2 >> {'accuracy': 0.11249999999999999, 'loss': 0.022021854639053345, 'std': 0.0635, 'EER': -1}\n",
      "[204] Eval metrics for task 3 >> {'accuracy': 0.1315, 'loss': 0.014329102873802185, 'std': 0.013499999999999998, 'EER': -1}\n",
      "[204] Eval metrics for task 4 >> {'accuracy': 0.35250000000000004, 'loss': 0.007871644020080566, 'std': 0.046500000000000014, 'EER': -1}\n",
      "[204] Eval metrics for task 5 >> {'accuracy': 0.8345, 'loss': 0.0021641289591789246, 'std': 0.05349999999999999, 'EER': -1}\n",
      "[205] Eval metrics for task 1 >> {'accuracy': 0.147, 'loss': 0.0202492196559906, 'std': 0.042, 'EER': -1}\n",
      "[205] Eval metrics for task 2 >> {'accuracy': 0.1265, 'loss': 0.02466779613494873, 'std': 0.058499999999999996, 'EER': -1}\n",
      "[205] Eval metrics for task 3 >> {'accuracy': 0.21, 'loss': 0.016400862574577332, 'std': 0.0020000000000000018, 'EER': -1}\n",
      "[205] Eval metrics for task 4 >> {'accuracy': 0.49750000000000005, 'loss': 0.007525649070739746, 'std': 0.046500000000000014, 'EER': -1}\n",
      "[205] Eval metrics for task 5 >> {'accuracy': 0.7835, 'loss': 0.002300914078950882, 'std': 0.0655, 'EER': -1}\n",
      "[206] Eval metrics for task 1 >> {'accuracy': 0.1075, 'loss': 0.022220749378204344, 'std': 0.0445, 'EER': -1}\n",
      "[206] Eval metrics for task 2 >> {'accuracy': 0.069, 'loss': 0.028638489484786988, 'std': 0.043000000000000003, 'EER': -1}\n",
      "[206] Eval metrics for task 3 >> {'accuracy': 0.149, 'loss': 0.01786686587333679, 'std': 0.04700000000000001, 'EER': -1}\n",
      "[206] Eval metrics for task 4 >> {'accuracy': 0.4655, 'loss': 0.008619155943393707, 'std': 0.08350000000000002, 'EER': -1}\n",
      "[206] Eval metrics for task 5 >> {'accuracy': 0.8395, 'loss': 0.0019341693967580794, 'std': 0.05449999999999999, 'EER': -1}\n",
      "[207] Eval metrics for task 1 >> {'accuracy': 0.1905, 'loss': 0.022176669359207153, 'std': 0.08650000000000002, 'EER': -1}\n",
      "[207] Eval metrics for task 2 >> {'accuracy': 0.20249999999999999, 'loss': 0.025781723260879515, 'std': 0.08449999999999999, 'EER': -1}\n",
      "[207] Eval metrics for task 3 >> {'accuracy': 0.23199999999999998, 'loss': 0.01905515170097351, 'std': 0.024000000000000007, 'EER': -1}\n",
      "[207] Eval metrics for task 4 >> {'accuracy': 0.4475, 'loss': 0.010895517826080323, 'std': 0.08050000000000002, 'EER': -1}\n",
      "[207] Eval metrics for task 5 >> {'accuracy': 0.753, 'loss': 0.0025526327192783357, 'std': 0.08699999999999997, 'EER': -1}\n",
      "[208] Eval metrics for task 1 >> {'accuracy': 0.17049999999999998, 'loss': 0.021024922609329224, 'std': 0.022500000000000006, 'EER': -1}\n",
      "[208] Eval metrics for task 2 >> {'accuracy': 0.122, 'loss': 0.025462419986724855, 'std': 0.005999999999999998, 'EER': -1}\n",
      "[208] Eval metrics for task 3 >> {'accuracy': 0.1865, 'loss': 0.017505115032196046, 'std': 0.0005000000000000004, 'EER': -1}\n",
      "[208] Eval metrics for task 4 >> {'accuracy': 0.4255, 'loss': 0.008832335472106934, 'std': 0.07050000000000001, 'EER': -1}\n",
      "[208] Eval metrics for task 5 >> {'accuracy': 0.798, 'loss': 0.0022962808907032012, 'std': 0.0020000000000000018, 'EER': -1}\n",
      "[209] Eval metrics for task 1 >> {'accuracy': 0.1685, 'loss': 0.022029443740844725, 'std': 0.0015000000000000013, 'EER': -1}\n",
      "[209] Eval metrics for task 2 >> {'accuracy': 0.114, 'loss': 0.02609179663658142, 'std': 0.02600000000000001, 'EER': -1}\n",
      "[209] Eval metrics for task 3 >> {'accuracy': 0.253, 'loss': 0.01636202549934387, 'std': 0.03799999999999999, 'EER': -1}\n",
      "[209] Eval metrics for task 4 >> {'accuracy': 0.5095000000000001, 'loss': 0.007981313705444335, 'std': 0.02250000000000002, 'EER': -1}\n",
      "[209] Eval metrics for task 5 >> {'accuracy': 0.778, 'loss': 0.0022943283766508104, 'std': 0.0050000000000000044, 'EER': -1}\n",
      "[210] Eval metrics for task 1 >> {'accuracy': 0.14950000000000002, 'loss': 0.024058202981948853, 'std': 0.0495, 'EER': -1}\n",
      "[210] Eval metrics for task 2 >> {'accuracy': 0.136, 'loss': 0.025717106580734252, 'std': 0.025, 'EER': -1}\n",
      "[210] Eval metrics for task 3 >> {'accuracy': 0.1695, 'loss': 0.02013964009284973, 'std': 0.0305, 'EER': -1}\n",
      "[210] Eval metrics for task 4 >> {'accuracy': 0.5325, 'loss': 0.0077204728722572325, 'std': 0.017500000000000016, 'EER': -1}\n",
      "[210] Eval metrics for task 5 >> {'accuracy': 0.813, 'loss': 0.002120185598731041, 'std': 0.03799999999999998, 'EER': -1}\n",
      "[211] Eval metrics for task 1 >> {'accuracy': 0.11699999999999999, 'loss': 0.023780888080596925, 'std': 0.033999999999999996, 'EER': -1}\n",
      "[211] Eval metrics for task 2 >> {'accuracy': 0.1045, 'loss': 0.027487220287323, 'std': 0.0175, 'EER': -1}\n",
      "[211] Eval metrics for task 3 >> {'accuracy': 0.21100000000000002, 'loss': 0.01878307795524597, 'std': 0.06600000000000002, 'EER': -1}\n",
      "[211] Eval metrics for task 4 >> {'accuracy': 0.404, 'loss': 0.010210055232048034, 'std': 0.012999999999999984, 'EER': -1}\n",
      "[211] Eval metrics for task 5 >> {'accuracy': 0.8400000000000001, 'loss': 0.0016997171342372894, 'std': 0.045999999999999985, 'EER': -1}\n",
      "[212] Eval metrics for task 1 >> {'accuracy': 0.178, 'loss': 0.019716119527816774, 'std': 0.028999999999999998, 'EER': -1}\n",
      "[212] Eval metrics for task 2 >> {'accuracy': 0.117, 'loss': 0.02533251929283142, 'std': 0.022000000000000006, 'EER': -1}\n",
      "[212] Eval metrics for task 3 >> {'accuracy': 0.24, 'loss': 0.016223070740699768, 'std': 0.0020000000000000018, 'EER': -1}\n",
      "[212] Eval metrics for task 4 >> {'accuracy': 0.5085000000000001, 'loss': 0.008053705930709839, 'std': 0.04450000000000001, 'EER': -1}\n",
      "[212] Eval metrics for task 5 >> {'accuracy': 0.7415, 'loss': 0.0026592696607112883, 'std': 0.003500000000000003, 'EER': -1}\n",
      "[213] Eval metrics for task 1 >> {'accuracy': 0.1865, 'loss': 0.018836058139801024, 'std': 0.003500000000000003, 'EER': -1}\n",
      "[213] Eval metrics for task 2 >> {'accuracy': 0.1255, 'loss': 0.024920876264572143, 'std': 0.0005000000000000004, 'EER': -1}\n",
      "[213] Eval metrics for task 3 >> {'accuracy': 0.164, 'loss': 0.01722860360145569, 'std': 0.006000000000000005, 'EER': -1}\n",
      "[213] Eval metrics for task 4 >> {'accuracy': 0.473, 'loss': 0.007720682203769684, 'std': 0.027999999999999997, 'EER': -1}\n",
      "[213] Eval metrics for task 5 >> {'accuracy': 0.817, 'loss': 0.002082187429070473, 'std': 0.01699999999999996, 'EER': -1}\n",
      "[214] Eval metrics for task 1 >> {'accuracy': 0.1795, 'loss': 0.021438044786453246, 'std': 0.014499999999999999, 'EER': -1}\n",
      "[214] Eval metrics for task 2 >> {'accuracy': 0.133, 'loss': 0.02647211289405823, 'std': 0.040999999999999995, 'EER': -1}\n",
      "[214] Eval metrics for task 3 >> {'accuracy': 0.257, 'loss': 0.016990331292152404, 'std': 0.03399999999999999, 'EER': -1}\n",
      "[214] Eval metrics for task 4 >> {'accuracy': 0.5055000000000001, 'loss': 0.008177433729171752, 'std': 0.02350000000000002, 'EER': -1}\n",
      "[214] Eval metrics for task 5 >> {'accuracy': 0.7725, 'loss': 0.0024073525071144105, 'std': 0.018500000000000016, 'EER': -1}\n",
      "[215] Eval metrics for task 1 >> {'accuracy': 0.1865, 'loss': 0.022413435697555543, 'std': 0.012500000000000011, 'EER': -1}\n",
      "[215] Eval metrics for task 2 >> {'accuracy': 0.15100000000000002, 'loss': 0.027172335386276246, 'std': 0.012999999999999998, 'EER': -1}\n",
      "[215] Eval metrics for task 3 >> {'accuracy': 0.1875, 'loss': 0.020756040811538697, 'std': 0.014500000000000013, 'EER': -1}\n",
      "[215] Eval metrics for task 4 >> {'accuracy': 0.521, 'loss': 0.008314130127429962, 'std': 0.055999999999999966, 'EER': -1}\n",
      "[215] Eval metrics for task 5 >> {'accuracy': 0.8049999999999999, 'loss': 0.002165738195180893, 'std': 0.02899999999999997, 'EER': -1}\n",
      "[216] Eval metrics for task 1 >> {'accuracy': 0.14600000000000002, 'loss': 0.023047616481781007, 'std': 0.017, 'EER': -1}\n",
      "[216] Eval metrics for task 2 >> {'accuracy': 0.16599999999999998, 'loss': 0.025632429361343384, 'std': 0.011999999999999997, 'EER': -1}\n",
      "[216] Eval metrics for task 3 >> {'accuracy': 0.239, 'loss': 0.018088514804840087, 'std': 0.006999999999999992, 'EER': -1}\n",
      "[216] Eval metrics for task 4 >> {'accuracy': 0.461, 'loss': 0.009604113698005677, 'std': 0.0040000000000000036, 'EER': -1}\n",
      "[216] Eval metrics for task 5 >> {'accuracy': 0.787, 'loss': 0.0022553372383117675, 'std': 0.018000000000000016, 'EER': -1}\n",
      "[217] Eval metrics for task 1 >> {'accuracy': 0.14300000000000002, 'loss': 0.023617428779602052, 'std': 0.021000000000000005, 'EER': -1}\n",
      "[217] Eval metrics for task 2 >> {'accuracy': 0.148, 'loss': 0.02622164750099182, 'std': 0.03, 'EER': -1}\n",
      "[217] Eval metrics for task 3 >> {'accuracy': 0.2565, 'loss': 0.017295207262039185, 'std': 0.020500000000000018, 'EER': -1}\n",
      "[217] Eval metrics for task 4 >> {'accuracy': 0.489, 'loss': 0.009320592164993285, 'std': 0.06900000000000003, 'EER': -1}\n",
      "[217] Eval metrics for task 5 >> {'accuracy': 0.7805, 'loss': 0.0022734378576278686, 'std': 0.02150000000000002, 'EER': -1}\n",
      "[218] Eval metrics for task 1 >> {'accuracy': 0.139, 'loss': 0.026758436679840087, 'std': 0.020000000000000004, 'EER': -1}\n",
      "[218] Eval metrics for task 2 >> {'accuracy': 0.1595, 'loss': 0.0267564857006073, 'std': 0.004500000000000004, 'EER': -1}\n",
      "[218] Eval metrics for task 3 >> {'accuracy': 0.2205, 'loss': 0.019687126636505126, 'std': 0.007500000000000007, 'EER': -1}\n",
      "[218] Eval metrics for task 4 >> {'accuracy': 0.5065, 'loss': 0.009361949205398559, 'std': 0.03150000000000003, 'EER': -1}\n",
      "[218] Eval metrics for task 5 >> {'accuracy': 0.8174999999999999, 'loss': 0.002047527000308037, 'std': 0.0005000000000000004, 'EER': -1}\n",
      "[219] Eval metrics for task 1 >> {'accuracy': 0.1215, 'loss': 0.026487210273742675, 'std': 0.05349999999999999, 'EER': -1}\n",
      "[219] Eval metrics for task 2 >> {'accuracy': 0.1405, 'loss': 0.02819461989402771, 'std': 0.0445, 'EER': -1}\n",
      "[219] Eval metrics for task 3 >> {'accuracy': 0.201, 'loss': 0.01977067184448242, 'std': 0.02700000000000001, 'EER': -1}\n",
      "[219] Eval metrics for task 4 >> {'accuracy': 0.468, 'loss': 0.009580358266830444, 'std': 0.08600000000000002, 'EER': -1}\n",
      "[219] Eval metrics for task 5 >> {'accuracy': 0.8505, 'loss': 0.001603790208697319, 'std': 0.019500000000000017, 'EER': -1}\n",
      "[220] Eval metrics for task 1 >> {'accuracy': 0.255, 'loss': 0.021382380723953247, 'std': 0.09899999999999999, 'EER': -1}\n",
      "[220] Eval metrics for task 2 >> {'accuracy': 0.1335, 'loss': 0.029182684183120727, 'std': 0.013499999999999998, 'EER': -1}\n",
      "[220] Eval metrics for task 3 >> {'accuracy': 0.21900000000000003, 'loss': 0.02160854411125183, 'std': 0.052000000000000005, 'EER': -1}\n",
      "[220] Eval metrics for task 4 >> {'accuracy': 0.358, 'loss': 0.01410304319858551, 'std': 0.0050000000000000044, 'EER': -1}\n",
      "[220] Eval metrics for task 5 >> {'accuracy': 0.6455, 'loss': 0.004890700519084931, 'std': 0.007500000000000007, 'EER': -1}\n",
      "[221] Eval metrics for task 1 >> {'accuracy': 0.124, 'loss': 0.027963778734207155, 'std': 0.0050000000000000044, 'EER': -1}\n",
      "[221] Eval metrics for task 2 >> {'accuracy': 0.1745, 'loss': 0.025184897661209106, 'std': 0.0305, 'EER': -1}\n",
      "[221] Eval metrics for task 3 >> {'accuracy': 0.2565, 'loss': 0.017162134170532226, 'std': 0.07950000000000002, 'EER': -1}\n",
      "[221] Eval metrics for task 4 >> {'accuracy': 0.5005, 'loss': 0.008905811548233031, 'std': 0.08049999999999999, 'EER': -1}\n",
      "[221] Eval metrics for task 5 >> {'accuracy': 0.7715, 'loss': 0.002451032519340515, 'std': 0.046499999999999986, 'EER': -1}\n",
      "[222] Eval metrics for task 1 >> {'accuracy': 0.2415, 'loss': 0.0224935302734375, 'std': 0.0845, 'EER': -1}\n",
      "[222] Eval metrics for task 2 >> {'accuracy': 0.1595, 'loss': 0.024796611070632933, 'std': 0.0845, 'EER': -1}\n",
      "[222] Eval metrics for task 3 >> {'accuracy': 0.24050000000000002, 'loss': 0.01683137583732605, 'std': 0.038500000000000006, 'EER': -1}\n",
      "[222] Eval metrics for task 4 >> {'accuracy': 0.4565, 'loss': 0.008527758538722991, 'std': 0.04150000000000001, 'EER': -1}\n",
      "[222] Eval metrics for task 5 >> {'accuracy': 0.782, 'loss': 0.002400314927101135, 'std': 0.07900000000000001, 'EER': -1}\n",
      "[223] Eval metrics for task 1 >> {'accuracy': 0.21750000000000003, 'loss': 0.020825932025909422, 'std': 0.0465, 'EER': -1}\n",
      "[223] Eval metrics for task 2 >> {'accuracy': 0.117, 'loss': 0.027708590984344483, 'std': 0.053000000000000005, 'EER': -1}\n",
      "[223] Eval metrics for task 3 >> {'accuracy': 0.2655, 'loss': 0.01611849856376648, 'std': 0.0625, 'EER': -1}\n",
      "[223] Eval metrics for task 4 >> {'accuracy': 0.412, 'loss': 0.009455137252807617, 'std': 0.067, 'EER': -1}\n",
      "[223] Eval metrics for task 5 >> {'accuracy': 0.8175, 'loss': 0.0021597032696008683, 'std': 0.035499999999999976, 'EER': -1}\n",
      "[224] Eval metrics for task 1 >> {'accuracy': 0.18, 'loss': 0.020208741903305055, 'std': 0.009999999999999995, 'EER': -1}\n",
      "[224] Eval metrics for task 2 >> {'accuracy': 0.1465, 'loss': 0.024715705156326293, 'std': 0.030499999999999992, 'EER': -1}\n",
      "[224] Eval metrics for task 3 >> {'accuracy': 0.21800000000000003, 'loss': 0.017772090435028077, 'std': 0.015, 'EER': -1}\n",
      "[224] Eval metrics for task 4 >> {'accuracy': 0.4535, 'loss': 0.00943230402469635, 'std': 0.004500000000000004, 'EER': -1}\n",
      "[224] Eval metrics for task 5 >> {'accuracy': 0.8115, 'loss': 0.002138915792107582, 'std': 0.015499999999999958, 'EER': -1}\n",
      "[225] Eval metrics for task 1 >> {'accuracy': 0.11299999999999999, 'loss': 0.027493845462799073, 'std': 0.031999999999999994, 'EER': -1}\n",
      "[225] Eval metrics for task 2 >> {'accuracy': 0.097, 'loss': 0.029011814832687378, 'std': 0.031, 'EER': -1}\n",
      "[225] Eval metrics for task 3 >> {'accuracy': 0.149, 'loss': 0.019761388301849366, 'std': 0.026999999999999996, 'EER': -1}\n",
      "[225] Eval metrics for task 4 >> {'accuracy': 0.346, 'loss': 0.011967072248458862, 'std': 0.05500000000000002, 'EER': -1}\n",
      "[225] Eval metrics for task 5 >> {'accuracy': 0.885, 'loss': 0.001422675959765911, 'std': 0.008000000000000007, 'EER': -1}\n",
      "[226] Eval metrics for task 1 >> {'accuracy': 0.1855, 'loss': 0.0219087872505188, 'std': 0.023499999999999993, 'EER': -1}\n",
      "[226] Eval metrics for task 2 >> {'accuracy': 0.156, 'loss': 0.025808080911636354, 'std': 0.034, 'EER': -1}\n",
      "[226] Eval metrics for task 3 >> {'accuracy': 0.293, 'loss': 0.016139547944068907, 'std': 0.0, 'EER': -1}\n",
      "[226] Eval metrics for task 4 >> {'accuracy': 0.485, 'loss': 0.009564473032951356, 'std': 0.0040000000000000036, 'EER': -1}\n",
      "[226] Eval metrics for task 5 >> {'accuracy': 0.8305, 'loss': 0.0019999441504478456, 'std': 0.023499999999999965, 'EER': -1}\n",
      "[227] Eval metrics for task 1 >> {'accuracy': 0.17149999999999999, 'loss': 0.02379775333404541, 'std': 0.024500000000000008, 'EER': -1}\n",
      "[227] Eval metrics for task 2 >> {'accuracy': 0.153, 'loss': 0.029710349798202515, 'std': 0.07200000000000001, 'EER': -1}\n",
      "[227] Eval metrics for task 3 >> {'accuracy': 0.157, 'loss': 0.025043593406677247, 'std': 0.027999999999999997, 'EER': -1}\n",
      "[227] Eval metrics for task 4 >> {'accuracy': 0.381, 'loss': 0.012942046880722046, 'std': 0.03899999999999998, 'EER': -1}\n",
      "[227] Eval metrics for task 5 >> {'accuracy': 0.831, 'loss': 0.0024928374886512756, 'std': 0.025999999999999968, 'EER': -1}\n",
      "[228] Eval metrics for task 1 >> {'accuracy': 0.1865, 'loss': 0.02294047451019287, 'std': 0.003500000000000003, 'EER': -1}\n",
      "[228] Eval metrics for task 2 >> {'accuracy': 0.1775, 'loss': 0.024900492429733277, 'std': 0.05450000000000001, 'EER': -1}\n",
      "[228] Eval metrics for task 3 >> {'accuracy': 0.1835, 'loss': 0.019210279703140258, 'std': 0.04150000000000001, 'EER': -1}\n",
      "[228] Eval metrics for task 4 >> {'accuracy': 0.4445, 'loss': 0.00929827630519867, 'std': 0.02250000000000002, 'EER': -1}\n",
      "[228] Eval metrics for task 5 >> {'accuracy': 0.812, 'loss': 0.002023817494511604, 'std': 0.02799999999999997, 'EER': -1}\n",
      "[229] Eval metrics for task 1 >> {'accuracy': 0.19, 'loss': 0.02334061670303345, 'std': 0.026999999999999996, 'EER': -1}\n",
      "[229] Eval metrics for task 2 >> {'accuracy': 0.1695, 'loss': 0.025992805242538452, 'std': 0.060500000000000005, 'EER': -1}\n",
      "[229] Eval metrics for task 3 >> {'accuracy': 0.157, 'loss': 0.02333308434486389, 'std': 0.0030000000000000027, 'EER': -1}\n",
      "[229] Eval metrics for task 4 >> {'accuracy': 0.4425, 'loss': 0.010495129585266114, 'std': 0.05349999999999999, 'EER': -1}\n",
      "[229] Eval metrics for task 5 >> {'accuracy': 0.8445, 'loss': 0.0018405608683824538, 'std': 0.007500000000000007, 'EER': -1}\n",
      "[230] Eval metrics for task 1 >> {'accuracy': 0.184, 'loss': 0.023159164428710938, 'std': 0.04200000000000001, 'EER': -1}\n",
      "[230] Eval metrics for task 2 >> {'accuracy': 0.153, 'loss': 0.026296263217926025, 'std': 0.067, 'EER': -1}\n",
      "[230] Eval metrics for task 3 >> {'accuracy': 0.1975, 'loss': 0.020558218955993652, 'std': 0.0165, 'EER': -1}\n",
      "[230] Eval metrics for task 4 >> {'accuracy': 0.447, 'loss': 0.01004333233833313, 'std': 0.0030000000000000027, 'EER': -1}\n",
      "[230] Eval metrics for task 5 >> {'accuracy': 0.8414999999999999, 'loss': 0.0018691327720880507, 'std': 0.0015000000000000013, 'EER': -1}\n",
      "[231] Eval metrics for task 1 >> {'accuracy': 0.1755, 'loss': 0.02331507420539856, 'std': 0.03949999999999999, 'EER': -1}\n",
      "[231] Eval metrics for task 2 >> {'accuracy': 0.1445, 'loss': 0.026308335065841675, 'std': 0.05949999999999999, 'EER': -1}\n",
      "[231] Eval metrics for task 3 >> {'accuracy': 0.1915, 'loss': 0.020347851753234864, 'std': 0.014499999999999999, 'EER': -1}\n",
      "[231] Eval metrics for task 4 >> {'accuracy': 0.4355, 'loss': 0.010016115188598632, 'std': 0.01050000000000001, 'EER': -1}\n",
      "[231] Eval metrics for task 5 >> {'accuracy': 0.848, 'loss': 0.0017403605729341507, 'std': 0.0020000000000000018, 'EER': -1}\n",
      "[232] Eval metrics for task 1 >> {'accuracy': 0.2, 'loss': 0.02256114077568054, 'std': 0.053000000000000005, 'EER': -1}\n",
      "[232] Eval metrics for task 2 >> {'accuracy': 0.162, 'loss': 0.02582949709892273, 'std': 0.04499999999999999, 'EER': -1}\n",
      "[232] Eval metrics for task 3 >> {'accuracy': 0.23, 'loss': 0.0192312331199646, 'std': 0.037000000000000005, 'EER': -1}\n",
      "[232] Eval metrics for task 4 >> {'accuracy': 0.494, 'loss': 0.008825022339820862, 'std': 0.0010000000000000009, 'EER': -1}\n",
      "[232] Eval metrics for task 5 >> {'accuracy': 0.8160000000000001, 'loss': 0.002069015011191368, 'std': 0.01699999999999996, 'EER': -1}\n",
      "[233] Eval metrics for task 1 >> {'accuracy': 0.21450000000000002, 'loss': 0.022012494802474976, 'std': 0.051500000000000004, 'EER': -1}\n",
      "[233] Eval metrics for task 2 >> {'accuracy': 0.1655, 'loss': 0.025296632766723632, 'std': 0.0515, 'EER': -1}\n",
      "[233] Eval metrics for task 3 >> {'accuracy': 0.23450000000000001, 'loss': 0.018835825443267822, 'std': 0.0335, 'EER': -1}\n",
      "[233] Eval metrics for task 4 >> {'accuracy': 0.502, 'loss': 0.008744138598442077, 'std': 0.01100000000000001, 'EER': -1}\n",
      "[233] Eval metrics for task 5 >> {'accuracy': 0.8109999999999999, 'loss': 0.0021961545050144197, 'std': 0.013999999999999957, 'EER': -1}\n",
      "[234] Eval metrics for task 1 >> {'accuracy': 0.202, 'loss': 0.02215302515029907, 'std': 0.049, 'EER': -1}\n",
      "[234] Eval metrics for task 2 >> {'accuracy': 0.1565, 'loss': 0.026229808807373047, 'std': 0.0595, 'EER': -1}\n",
      "[234] Eval metrics for task 3 >> {'accuracy': 0.21450000000000002, 'loss': 0.02000773882865906, 'std': 0.018500000000000003, 'EER': -1}\n",
      "[234] Eval metrics for task 4 >> {'accuracy': 0.46499999999999997, 'loss': 0.00959040892124176, 'std': 0.00799999999999998, 'EER': -1}\n",
      "[234] Eval metrics for task 5 >> {'accuracy': 0.8294999999999999, 'loss': 0.0020022452622652054, 'std': 0.0025000000000000022, 'EER': -1}\n",
      "[235] Eval metrics for task 1 >> {'accuracy': 0.187, 'loss': 0.02370709276199341, 'std': 0.04100000000000001, 'EER': -1}\n",
      "[235] Eval metrics for task 2 >> {'accuracy': 0.1595, 'loss': 0.02581536030769348, 'std': 0.0575, 'EER': -1}\n",
      "[235] Eval metrics for task 3 >> {'accuracy': 0.2155, 'loss': 0.01991788077354431, 'std': 0.009500000000000008, 'EER': -1}\n",
      "[235] Eval metrics for task 4 >> {'accuracy': 0.471, 'loss': 0.009651168704032898, 'std': 0.00799999999999998, 'EER': -1}\n",
      "[235] Eval metrics for task 5 >> {'accuracy': 0.831, 'loss': 0.0019764412194490434, 'std': 0.0020000000000000018, 'EER': -1}\n",
      "[236] Eval metrics for task 1 >> {'accuracy': 0.20900000000000002, 'loss': 0.021955267429351808, 'std': 0.05500000000000001, 'EER': -1}\n",
      "[236] Eval metrics for task 2 >> {'accuracy': 0.162, 'loss': 0.025757758378982545, 'std': 0.065, 'EER': -1}\n",
      "[236] Eval metrics for task 3 >> {'accuracy': 0.2195, 'loss': 0.01969422459602356, 'std': 0.0295, 'EER': -1}\n",
      "[236] Eval metrics for task 4 >> {'accuracy': 0.485, 'loss': 0.00911294984817505, 'std': 0.006000000000000005, 'EER': -1}\n",
      "[236] Eval metrics for task 5 >> {'accuracy': 0.822, 'loss': 0.0020659018307924272, 'std': 0.006000000000000005, 'EER': -1}\n",
      "[237] Eval metrics for task 1 >> {'accuracy': 0.1965, 'loss': 0.022554500579833985, 'std': 0.0475, 'EER': -1}\n",
      "[237] Eval metrics for task 2 >> {'accuracy': 0.1585, 'loss': 0.025827353954315187, 'std': 0.0555, 'EER': -1}\n",
      "[237] Eval metrics for task 3 >> {'accuracy': 0.2255, 'loss': 0.01953163743019104, 'std': 0.024499999999999994, 'EER': -1}\n",
      "[237] Eval metrics for task 4 >> {'accuracy': 0.48, 'loss': 0.009325418829917907, 'std': 0.010000000000000009, 'EER': -1}\n",
      "[237] Eval metrics for task 5 >> {'accuracy': 0.828, 'loss': 0.0020142118632793427, 'std': 0.0050000000000000044, 'EER': -1}\n",
      "[238] Eval metrics for task 1 >> {'accuracy': 0.1985, 'loss': 0.022355451345443724, 'std': 0.0505, 'EER': -1}\n",
      "[238] Eval metrics for task 2 >> {'accuracy': 0.154, 'loss': 0.02598765182495117, 'std': 0.05299999999999999, 'EER': -1}\n",
      "[238] Eval metrics for task 3 >> {'accuracy': 0.216, 'loss': 0.019790191173553465, 'std': 0.022999999999999993, 'EER': -1}\n",
      "[238] Eval metrics for task 4 >> {'accuracy': 0.4725, 'loss': 0.009278902769088744, 'std': 0.003500000000000003, 'EER': -1}\n",
      "[238] Eval metrics for task 5 >> {'accuracy': 0.837, 'loss': 0.0019226618260145187, 'std': 0.008000000000000007, 'EER': -1}\n",
      "[239] Eval metrics for task 1 >> {'accuracy': 0.21900000000000003, 'loss': 0.021949719667434694, 'std': 0.049, 'EER': -1}\n",
      "[239] Eval metrics for task 2 >> {'accuracy': 0.1635, 'loss': 0.026380452156066894, 'std': 0.0635, 'EER': -1}\n",
      "[239] Eval metrics for task 3 >> {'accuracy': 0.22599999999999998, 'loss': 0.020024605751037598, 'std': 0.016, 'EER': -1}\n",
      "[239] Eval metrics for task 4 >> {'accuracy': 0.4965, 'loss': 0.009145571947097779, 'std': 0.012500000000000011, 'EER': -1}\n",
      "[239] Eval metrics for task 5 >> {'accuracy': 0.806, 'loss': 0.0021997915357351303, 'std': 0.009999999999999953, 'EER': -1}\n",
      "[240] Eval metrics for task 1 >> {'accuracy': 0.2325, 'loss': 0.021704944849014283, 'std': 0.047500000000000014, 'EER': -1}\n",
      "[240] Eval metrics for task 2 >> {'accuracy': 0.17250000000000001, 'loss': 0.025730177879333495, 'std': 0.0565, 'EER': -1}\n",
      "[240] Eval metrics for task 3 >> {'accuracy': 0.2425, 'loss': 0.019585193157196045, 'std': 0.019500000000000003, 'EER': -1}\n",
      "[240] Eval metrics for task 4 >> {'accuracy': 0.5055000000000001, 'loss': 0.009040286421775817, 'std': 0.009500000000000008, 'EER': -1}\n",
      "[240] Eval metrics for task 5 >> {'accuracy': 0.7905, 'loss': 0.002362534165382385, 'std': 0.006500000000000006, 'EER': -1}\n",
      "[241] Eval metrics for task 1 >> {'accuracy': 0.20750000000000002, 'loss': 0.022246684551239012, 'std': 0.0495, 'EER': -1}\n",
      "[241] Eval metrics for task 2 >> {'accuracy': 0.1615, 'loss': 0.026197169303894045, 'std': 0.0585, 'EER': -1}\n",
      "[241] Eval metrics for task 3 >> {'accuracy': 0.214, 'loss': 0.020051682949066164, 'std': 0.023999999999999994, 'EER': -1}\n",
      "[241] Eval metrics for task 4 >> {'accuracy': 0.487, 'loss': 0.009252085328102112, 'std': 0.01899999999999999, 'EER': -1}\n",
      "[241] Eval metrics for task 5 >> {'accuracy': 0.819, 'loss': 0.002079187721014023, 'std': 0.006000000000000005, 'EER': -1}\n",
      "[242] Eval metrics for task 1 >> {'accuracy': 0.20350000000000001, 'loss': 0.02209455418586731, 'std': 0.0475, 'EER': -1}\n",
      "[242] Eval metrics for task 2 >> {'accuracy': 0.158, 'loss': 0.025985673904418947, 'std': 0.057999999999999996, 'EER': -1}\n",
      "[242] Eval metrics for task 3 >> {'accuracy': 0.21350000000000002, 'loss': 0.02000238037109375, 'std': 0.013499999999999998, 'EER': -1}\n",
      "[242] Eval metrics for task 4 >> {'accuracy': 0.474, 'loss': 0.009350853204727174, 'std': 0.0030000000000000027, 'EER': -1}\n",
      "[242] Eval metrics for task 5 >> {'accuracy': 0.8285, 'loss': 0.001994108244776726, 'std': 0.006500000000000006, 'EER': -1}\n",
      "[243] Eval metrics for task 1 >> {'accuracy': 0.184, 'loss': 0.022889279127120972, 'std': 0.04100000000000001, 'EER': -1}\n",
      "[243] Eval metrics for task 2 >> {'accuracy': 0.1455, 'loss': 0.026795195817947388, 'std': 0.058499999999999996, 'EER': -1}\n",
      "[243] Eval metrics for task 3 >> {'accuracy': 0.2015, 'loss': 0.020393796682357787, 'std': 0.0165, 'EER': -1}\n",
      "[243] Eval metrics for task 4 >> {'accuracy': 0.4585, 'loss': 0.009679690480232239, 'std': 0.0005000000000000004, 'EER': -1}\n",
      "[243] Eval metrics for task 5 >> {'accuracy': 0.8405, 'loss': 0.0018386276215314864, 'std': 0.005500000000000005, 'EER': -1}\n",
      "[244] Eval metrics for task 1 >> {'accuracy': 0.17099999999999999, 'loss': 0.023541121006011963, 'std': 0.03899999999999999, 'EER': -1}\n",
      "[244] Eval metrics for task 2 >> {'accuracy': 0.14750000000000002, 'loss': 0.02626041269302368, 'std': 0.0485, 'EER': -1}\n",
      "[244] Eval metrics for task 3 >> {'accuracy': 0.20350000000000001, 'loss': 0.01985585069656372, 'std': 0.02750000000000001, 'EER': -1}\n",
      "[244] Eval metrics for task 4 >> {'accuracy': 0.4615, 'loss': 0.009480423927307129, 'std': 0.0005000000000000004, 'EER': -1}\n",
      "[244] Eval metrics for task 5 >> {'accuracy': 0.8454999999999999, 'loss': 0.0017564255446195602, 'std': 0.006500000000000006, 'EER': -1}\n",
      "[245] Eval metrics for task 1 >> {'accuracy': 0.233, 'loss': 0.021658223152160646, 'std': 0.04100000000000001, 'EER': -1}\n",
      "[245] Eval metrics for task 2 >> {'accuracy': 0.1695, 'loss': 0.026210899829864503, 'std': 0.061500000000000006, 'EER': -1}\n",
      "[245] Eval metrics for task 3 >> {'accuracy': 0.22849999999999998, 'loss': 0.020379537343978883, 'std': 0.023500000000000007, 'EER': -1}\n",
      "[245] Eval metrics for task 4 >> {'accuracy': 0.498, 'loss': 0.00928121167421341, 'std': 0.018000000000000016, 'EER': -1}\n",
      "[245] Eval metrics for task 5 >> {'accuracy': 0.7905, 'loss': 0.0024114418625831606, 'std': 0.007500000000000007, 'EER': -1}\n",
      "[246] Eval metrics for task 1 >> {'accuracy': 0.2015, 'loss': 0.022346011638641358, 'std': 0.0495, 'EER': -1}\n",
      "[246] Eval metrics for task 2 >> {'accuracy': 0.1575, 'loss': 0.025763683319091797, 'std': 0.0525, 'EER': -1}\n",
      "[246] Eval metrics for task 3 >> {'accuracy': 0.229, 'loss': 0.019283581495285033, 'std': 0.028999999999999998, 'EER': -1}\n",
      "[246] Eval metrics for task 4 >> {'accuracy': 0.4865, 'loss': 0.009072256684303283, 'std': 0.01050000000000001, 'EER': -1}\n",
      "[246] Eval metrics for task 5 >> {'accuracy': 0.8285, 'loss': 0.002018136739730835, 'std': 0.012500000000000011, 'EER': -1}\n",
      "[247] Eval metrics for task 1 >> {'accuracy': 0.1935, 'loss': 0.02254130673408508, 'std': 0.04050000000000001, 'EER': -1}\n",
      "[247] Eval metrics for task 2 >> {'accuracy': 0.16, 'loss': 0.025952797889709472, 'std': 0.057, 'EER': -1}\n",
      "[247] Eval metrics for task 3 >> {'accuracy': 0.216, 'loss': 0.02002002263069153, 'std': 0.023999999999999994, 'EER': -1}\n",
      "[247] Eval metrics for task 4 >> {'accuracy': 0.4645, 'loss': 0.009618710279464721, 'std': 0.006499999999999978, 'EER': -1}\n",
      "[247] Eval metrics for task 5 >> {'accuracy': 0.835, 'loss': 0.001967779353260994, 'std': 0.0040000000000000036, 'EER': -1}\n",
      "[248] Eval metrics for task 1 >> {'accuracy': 0.197, 'loss': 0.022939528465270996, 'std': 0.048, 'EER': -1}\n",
      "[248] Eval metrics for task 2 >> {'accuracy': 0.162, 'loss': 0.026198740243911743, 'std': 0.058, 'EER': -1}\n",
      "[248] Eval metrics for task 3 >> {'accuracy': 0.2175, 'loss': 0.019944772720336915, 'std': 0.0335, 'EER': -1}\n",
      "[248] Eval metrics for task 4 >> {'accuracy': 0.4855, 'loss': 0.009274709701538085, 'std': 0.01150000000000001, 'EER': -1}\n",
      "[248] Eval metrics for task 5 >> {'accuracy': 0.8234999999999999, 'loss': 0.0020912207961082457, 'std': 0.007500000000000007, 'EER': -1}\n",
      "[249] Eval metrics for task 1 >> {'accuracy': 0.2165, 'loss': 0.021747187852859496, 'std': 0.04450000000000001, 'EER': -1}\n",
      "[249] Eval metrics for task 2 >> {'accuracy': 0.1665, 'loss': 0.02532000422477722, 'std': 0.0585, 'EER': -1}\n",
      "[249] Eval metrics for task 3 >> {'accuracy': 0.23249999999999998, 'loss': 0.019406043767929076, 'std': 0.021500000000000005, 'EER': -1}\n",
      "[249] Eval metrics for task 4 >> {'accuracy': 0.4895, 'loss': 0.009204556345939635, 'std': 0.01150000000000001, 'EER': -1}\n",
      "[249] Eval metrics for task 5 >> {'accuracy': 0.8115, 'loss': 0.002193124771118164, 'std': 0.005499999999999949, 'EER': -1}\n",
      "[250] Eval metrics for task 1 >> {'accuracy': 0.21100000000000002, 'loss': 0.02237920618057251, 'std': 0.06200000000000001, 'EER': -1}\n",
      "[250] Eval metrics for task 2 >> {'accuracy': 0.1625, 'loss': 0.02608563780784607, 'std': 0.0645, 'EER': -1}\n",
      "[250] Eval metrics for task 3 >> {'accuracy': 0.21300000000000002, 'loss': 0.020223727703094482, 'std': 0.021000000000000005, 'EER': -1}\n",
      "[250] Eval metrics for task 4 >> {'accuracy': 0.487, 'loss': 0.00920368081331253, 'std': 0.01100000000000001, 'EER': -1}\n",
      "[250] Eval metrics for task 5 >> {'accuracy': 0.825, 'loss': 0.002011670917272568, 'std': 0.006000000000000005, 'EER': -1}\n",
      "training_task_end\n",
      "final avg-acc 0.37970000000000004\n",
      "final avg-forget 0.48462500000000003\n"
     ]
    }
   ],
   "source": [
    "trainer.run()\n",
    "print(\"final avg-acc\", metric_manager_callback.meters['accuracy'].compute_final())\n",
    "print(\"final avg-forget\", metric_manager_callback.meters['forgetting'].compute_final())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9801a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ebfb58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.019750000000000045, 0.07477777777777778, 0.2109375, 0.22104]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_manager_callback.meters['EER'].get_eer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06af72df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.04199999999999998,\n",
       " 0.10403454954965684,\n",
       " 0.11756794725698931,\n",
       " 0.26386901935430007,\n",
       " 0.2537053606055654]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_manager_callback.meters['std'].get_std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a893b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7039ed8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.943, 0.   , 0.   , 0.   , 0.   ],\n",
       "       [0.611, 0.651, 0.   , 0.   , 0.   ],\n",
       "       [0.438, 0.375, 0.574, 0.   , 0.   ],\n",
       "       [0.358, 0.15 , 0.336, 0.844, 0.   ],\n",
       "       [0.211, 0.162, 0.213, 0.487, 0.825]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_manager_callback.meters['accuracy'].get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "173c4765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9430000000000001,\n",
       " 0.63075,\n",
       " 0.4623333333333333,\n",
       " 0.422125,\n",
       " 0.37970000000000004]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_manager_callback.meters['accuracy'].compute_overall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "706ad34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.5675816666666667\n",
      "EER:0.10530105555555555\n",
      "std:0.15623537535330234\n"
     ]
    }
   ],
   "source": [
    "print(f\"accuracy:{np.mean(metric_manager_callback.meters['accuracy'].compute_overall())}\")\n",
    "print(f\"EER:{np.mean(metric_manager_callback.meters['EER'].compute_overall())}\")\n",
    "print(f\"std:{np.mean(metric_manager_callback.meters['std'].compute_overall())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b848e47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
