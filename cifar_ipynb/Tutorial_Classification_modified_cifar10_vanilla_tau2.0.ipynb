{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0c3b92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_dir=./outputs/demo/dataset=CIFAR10/seed=10_epoch=50_lr=0.01_alpha=0.0_tau=2.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import cl_gym as cl\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "seed = 10\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.set_num_threads(8)\n",
    "\n",
    "def make_params() -> dict:\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    import uuid\n",
    "\n",
    "    params = {\n",
    "            # dataset\n",
    "            'dataset': \"CIFAR10\",\n",
    "            # 'dataset': \"FMNIST\",\n",
    "            'random_class_idx' : False,\n",
    "            'method': \"vanilla\",\n",
    "\n",
    "            # benchmark\n",
    "            'seed': seed,\n",
    "            'num_tasks': 5,\n",
    "            'epochs_per_task': 50,\n",
    "            # 'per_task_examples': np.inf,\n",
    "            'per_task_examples': 200000,\n",
    "            'per_task_memory_examples': 64,\n",
    "            'batch_size_train': 256,\n",
    "            'batch_size_memory': 256,\n",
    "            # 'batch_size_memory': 256,\n",
    "            'batch_size_validation': 256,\n",
    "            'tau': 2.0,\n",
    "            # 'tau': 0.0,\n",
    "\n",
    "            # algorithm\n",
    "            'optimizer': 'sgd',\n",
    "            'learning_rate': 0.01,\n",
    "            'learning_rate_decay_epoch': [30, 50, 70, 90],\n",
    "            'momentum': 0.9,\n",
    "            'learning_rate_decay': 1.0,\n",
    "            'criterion': torch.nn.CrossEntropyLoss(),\n",
    "            'device': torch.device('cuda:7' if torch.cuda.is_available() else 'cpu'),\n",
    "             \n",
    "            # sample selection\n",
    "            'alpha':0.0,\n",
    "            'lambda': 0.0,\n",
    "            'lambda_old': 0.0,\n",
    "              }\n",
    "\n",
    "#     trial_id = str(uuid.uuid4())\n",
    "    trial_id = f\"demo/dataset={params['dataset']}/seed={params['seed']}_epoch={params['epochs_per_task']}_lr={params['learning_rate']}_alpha={params['alpha']}_tau={params['tau']}\"\n",
    "    params['trial_id'] = trial_id\n",
    "    params['output_dir'] = os.path.join(\"./outputs/{}\".format(trial_id))\n",
    "    print(f\"output_dir={params['output_dir']}\")\n",
    "    Path(params['output_dir']).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    return params\n",
    "\n",
    "params = make_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93b43ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from datasets import MNIST, FashionMNIST, BiasedMNIST, CIFAR10, CIFAR100\n",
    "if params['dataset'] == 'MNIST':\n",
    "    benchmark = MNIST(num_tasks=params['num_tasks'],\n",
    "                        per_task_memory_examples=params['per_task_memory_examples'],\n",
    "                        per_task_examples = params['per_task_examples'],\n",
    "                        joint = (params['method'] == \"joint\"),\n",
    "                        random_class_idx = params['random_class_idx'])\n",
    "    input_dim = (28, 28)\n",
    "elif params['dataset'] == 'FashionMNIST':\n",
    "    benchmark = FashionMNIST(num_tasks=params['num_tasks'],\n",
    "                                per_task_memory_examples=params['per_task_memory_examples'],\n",
    "                                per_task_examples = params['per_task_examples'],\n",
    "                                joint = (params['method'] == \"joint\"),\n",
    "                                random_class_idx = params['random_class_idx'])\n",
    "    input_dim = (28, 28)\n",
    "elif params['dataset'] == 'CIFAR10':\n",
    "    benchmark = CIFAR10(num_tasks=params['num_tasks'],\n",
    "                        per_task_memory_examples=params['per_task_memory_examples'],\n",
    "                        per_task_examples = params['per_task_examples'],\n",
    "                        joint = (params['method'] == \"joint\"),\n",
    "                        random_class_idx = params['random_class_idx'])\n",
    "    input_dim = (3, 32, 32)\n",
    "elif params['dataset'] == 'CIFAR100':        \n",
    "    benchmark = CIFAR100(num_tasks=params['num_tasks'],\n",
    "                            per_task_memory_examples=params['per_task_memory_examples'],\n",
    "                            per_task_examples = params['per_task_examples'],\n",
    "                            joint = (params['method'] == \"joint\"),\n",
    "                            random_class_idx = params['random_class_idx'])\n",
    "    input_dim = (3, 32, 32)\n",
    "elif params['dataset'] in [\"BiasedMNIST\"]:\n",
    "    benchmark = BiasedMNIST(num_tasks=params['num_tasks'],\n",
    "                            per_task_memory_examples=params['per_task_memory_examples'],\n",
    "                            per_task_examples = params['per_task_examples'],\n",
    "                            joint = (params['method'] == \"joint\"),\n",
    "                            random_class_idx = params['random_class_idx'])\n",
    "    input_dim = (3, 28, 28)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "class_idx = benchmark.class_idx\n",
    "num_classes = len(class_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20c7b886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modify resnet for cifar\n"
     ]
    }
   ],
   "source": [
    "from algorithms.imbalance import Heuristic2\n",
    "from metrics import MetricCollector2\n",
    "from backbones import MLP2Layers2\n",
    "\n",
    "from backbones.resnet import ResNet18\n",
    "\n",
    "\n",
    "# backbone = ResNet18(\n",
    "#     input_dim=input_dim, \n",
    "#     output_dim=num_classes,\n",
    "#     class_idx=class_idx,\n",
    "#     config=params\n",
    "#     ).to(params['device'])\n",
    "\n",
    "backbone = ResNet18(\n",
    "    input_dim=input_dim, \n",
    "    output_dim=num_classes,\n",
    "    class_idx=class_idx,\n",
    "    config=params\n",
    "    ).to(params['device'])\n",
    "\n",
    "algorithm = Heuristic2(backbone, benchmark, params, requires_memory=True)\n",
    "metric_manager_callback = MetricCollector2(num_tasks=params['num_tasks'],\n",
    "                                                        eval_interval='epoch',\n",
    "                                                        epochs_per_task=params['epochs_per_task'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8efa3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainers import ContinualTrainer\n",
    "\n",
    "trainer = ContinualTrainer(algorithm, params, callbacks=[metric_manager_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c315bf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Task 1 -----------------------\n",
      "[1] Eval metrics for task 1 >> {'accuracy': 0.821, 'loss': 0.0015542374849319457, 'std': 0.09600000000000003, 'EER': -1}\n",
      "[2] Eval metrics for task 1 >> {'accuracy': 0.8505, 'loss': 0.0013441222906112672, 'std': 0.08650000000000002, 'EER': -1}\n",
      "[3] Eval metrics for task 1 >> {'accuracy': 0.8835, 'loss': 0.001098384290933609, 'std': 0.04150000000000004, 'EER': -1}\n",
      "[4] Eval metrics for task 1 >> {'accuracy': 0.905, 'loss': 0.0009727678298950195, 'std': 0.013000000000000012, 'EER': -1}\n",
      "[5] Eval metrics for task 1 >> {'accuracy': 0.9145, 'loss': 0.0008592504635453224, 'std': 0.04149999999999998, 'EER': -1}\n",
      "[6] Eval metrics for task 1 >> {'accuracy': 0.927, 'loss': 0.0007724330499768257, 'std': 0.023999999999999966, 'EER': -1}\n",
      "[7] Eval metrics for task 1 >> {'accuracy': 0.872, 'loss': 0.0012186369150877, 'std': 0.10999999999999999, 'EER': -1}\n",
      "[8] Eval metrics for task 1 >> {'accuracy': 0.9239999999999999, 'loss': 0.0008102221190929413, 'std': 0.03799999999999998, 'EER': -1}\n",
      "[9] Eval metrics for task 1 >> {'accuracy': 0.9425, 'loss': 0.0006228669360280037, 'std': 0.013499999999999956, 'EER': -1}\n",
      "[10] Eval metrics for task 1 >> {'accuracy': 0.9435, 'loss': 0.0006541663408279419, 'std': 0.03049999999999997, 'EER': -1}\n",
      "[11] Eval metrics for task 1 >> {'accuracy': 0.9535, 'loss': 0.0005021771676838398, 'std': 0.004500000000000004, 'EER': -1}\n",
      "[12] Eval metrics for task 1 >> {'accuracy': 0.9495, 'loss': 0.0005349710024893284, 'std': 0.013499999999999956, 'EER': -1}\n",
      "[13] Eval metrics for task 1 >> {'accuracy': 0.9544999999999999, 'loss': 0.0005347102098166943, 'std': 0.005500000000000005, 'EER': -1}\n",
      "[14] Eval metrics for task 1 >> {'accuracy': 0.9615, 'loss': 0.00040383763238787654, 'std': 0.006500000000000006, 'EER': -1}\n",
      "[15] Eval metrics for task 1 >> {'accuracy': 0.9205, 'loss': 0.0010295420587062836, 'std': 0.07450000000000001, 'EER': -1}\n",
      "[16] Eval metrics for task 1 >> {'accuracy': 0.956, 'loss': 0.0004740884080529213, 'std': 0.007000000000000006, 'EER': -1}\n",
      "[17] Eval metrics for task 1 >> {'accuracy': 0.9644999999999999, 'loss': 0.00037283831648528574, 'std': 0.01150000000000001, 'EER': -1}\n",
      "[18] Eval metrics for task 1 >> {'accuracy': 0.959, 'loss': 0.0004592818133533001, 'std': 0.017000000000000015, 'EER': -1}\n",
      "[19] Eval metrics for task 1 >> {'accuracy': 0.966, 'loss': 0.0003582383552566171, 'std': 0.014000000000000012, 'EER': -1}\n",
      "[20] Eval metrics for task 1 >> {'accuracy': 0.96, 'loss': 0.0004337979666888714, 'std': 0.019000000000000017, 'EER': -1}\n",
      "[21] Eval metrics for task 1 >> {'accuracy': 0.9695, 'loss': 0.0003738541044294834, 'std': 0.006500000000000006, 'EER': -1}\n",
      "[22] Eval metrics for task 1 >> {'accuracy': 0.9610000000000001, 'loss': 0.00042475255206227304, 'std': 0.02699999999999997, 'EER': -1}\n",
      "[23] Eval metrics for task 1 >> {'accuracy': 0.9724999999999999, 'loss': 0.0002934701405465603, 'std': 0.0025000000000000022, 'EER': -1}\n",
      "[24] Eval metrics for task 1 >> {'accuracy': 0.967, 'loss': 0.00036090693809092046, 'std': 0.0050000000000000044, 'EER': -1}\n",
      "[25] Eval metrics for task 1 >> {'accuracy': 0.975, 'loss': 0.00028701317124068735, 'std': 0.0010000000000000009, 'EER': -1}\n",
      "[26] Eval metrics for task 1 >> {'accuracy': 0.9715, 'loss': 0.0003687286414206028, 'std': 0.0015000000000000013, 'EER': -1}\n",
      "[27] Eval metrics for task 1 >> {'accuracy': 0.9724999999999999, 'loss': 0.0003830532394349575, 'std': 0.0015000000000000013, 'EER': -1}\n",
      "[28] Eval metrics for task 1 >> {'accuracy': 0.972, 'loss': 0.0003108647773042321, 'std': 0.007000000000000006, 'EER': -1}\n",
      "[29] Eval metrics for task 1 >> {'accuracy': 0.9325, 'loss': 0.0009475812017917633, 'std': 0.04049999999999998, 'EER': -1}\n",
      "[30] Eval metrics for task 1 >> {'accuracy': 0.948, 'loss': 0.0008168460093438626, 'std': 0.034999999999999976, 'EER': -1}\n",
      "[31] Eval metrics for task 1 >> {'accuracy': 0.9410000000000001, 'loss': 0.000901186853647232, 'std': 0.04299999999999998, 'EER': -1}\n",
      "[32] Eval metrics for task 1 >> {'accuracy': 0.9425, 'loss': 0.000876957193017006, 'std': 0.04149999999999998, 'EER': -1}\n",
      "[33] Eval metrics for task 1 >> {'accuracy': 0.95, 'loss': 0.0007845024466514587, 'std': 0.02999999999999997, 'EER': -1}\n",
      "[34] Eval metrics for task 1 >> {'accuracy': 0.9445, 'loss': 0.000872126579284668, 'std': 0.04049999999999998, 'EER': -1}\n",
      "[35] Eval metrics for task 1 >> {'accuracy': 0.942, 'loss': 0.0008924752697348594, 'std': 0.04299999999999998, 'EER': -1}\n",
      "[36] Eval metrics for task 1 >> {'accuracy': 0.9390000000000001, 'loss': 0.0009520881697535515, 'std': 0.045999999999999985, 'EER': -1}\n",
      "[37] Eval metrics for task 1 >> {'accuracy': 0.9435, 'loss': 0.0008644357547163964, 'std': 0.04049999999999998, 'EER': -1}\n",
      "[38] Eval metrics for task 1 >> {'accuracy': 0.9515, 'loss': 0.0007570509016513825, 'std': 0.02849999999999997, 'EER': -1}\n",
      "[39] Eval metrics for task 1 >> {'accuracy': 0.9475, 'loss': 0.0008233070299029351, 'std': 0.03649999999999998, 'EER': -1}\n",
      "[40] Eval metrics for task 1 >> {'accuracy': 0.9470000000000001, 'loss': 0.0008493602201342582, 'std': 0.03699999999999998, 'EER': -1}\n",
      "[41] Eval metrics for task 1 >> {'accuracy': 0.9475, 'loss': 0.0008152196519076824, 'std': 0.03649999999999998, 'EER': -1}\n",
      "[42] Eval metrics for task 1 >> {'accuracy': 0.9415, 'loss': 0.0008951142840087414, 'std': 0.04349999999999998, 'EER': -1}\n",
      "[43] Eval metrics for task 1 >> {'accuracy': 0.9450000000000001, 'loss': 0.000874044619500637, 'std': 0.03899999999999998, 'EER': -1}\n",
      "[44] Eval metrics for task 1 >> {'accuracy': 0.944, 'loss': 0.0008662469312548638, 'std': 0.04099999999999998, 'EER': -1}\n",
      "[45] Eval metrics for task 1 >> {'accuracy': 0.9495, 'loss': 0.0008122915476560593, 'std': 0.03249999999999997, 'EER': -1}\n",
      "[46] Eval metrics for task 1 >> {'accuracy': 0.95, 'loss': 0.0007514705434441566, 'std': 0.02899999999999997, 'EER': -1}\n",
      "[47] Eval metrics for task 1 >> {'accuracy': 0.9410000000000001, 'loss': 0.0009208736419677734, 'std': 0.04299999999999998, 'EER': -1}\n",
      "[48] Eval metrics for task 1 >> {'accuracy': 0.9450000000000001, 'loss': 0.0008587613031268119, 'std': 0.03899999999999998, 'EER': -1}\n",
      "[49] Eval metrics for task 1 >> {'accuracy': 0.9490000000000001, 'loss': 0.0007111882157623768, 'std': 0.023999999999999966, 'EER': -1}\n",
      "[50] Eval metrics for task 1 >> {'accuracy': 0.9430000000000001, 'loss': 0.0008770229443907738, 'std': 0.04199999999999998, 'EER': -1}\n",
      "training_task_end\n",
      "---------------------------- Task 2 -----------------------\n",
      "[51] Eval metrics for task 1 >> {'accuracy': 0.5155, 'loss': 0.008995271801948547, 'std': 0.05949999999999997, 'EER': -1}\n",
      "[51] Eval metrics for task 2 >> {'accuracy': 0.366, 'loss': 0.0051955593824386595, 'std': 0.061, 'EER': -1}\n",
      "[52] Eval metrics for task 1 >> {'accuracy': 0.44000000000000006, 'loss': 0.01180485498905182, 'std': 0.11300000000000002, 'EER': -1}\n",
      "[52] Eval metrics for task 2 >> {'accuracy': 0.4275, 'loss': 0.005445972740650177, 'std': 0.04849999999999999, 'EER': -1}\n",
      "[53] Eval metrics for task 1 >> {'accuracy': 0.5665, 'loss': 0.011133793711662293, 'std': 0.03849999999999998, 'EER': -1}\n",
      "[53] Eval metrics for task 2 >> {'accuracy': 0.2665, 'loss': 0.0073210178017616276, 'std': 0.042499999999999996, 'EER': -1}\n",
      "[54] Eval metrics for task 1 >> {'accuracy': 0.533, 'loss': 0.011020180702209472, 'std': 0.07099999999999998, 'EER': -1}\n",
      "[54] Eval metrics for task 2 >> {'accuracy': 0.347, 'loss': 0.005322001874446869, 'std': 0.017999999999999988, 'EER': -1}\n",
      "[55] Eval metrics for task 1 >> {'accuracy': 0.595, 'loss': 0.00907379549741745, 'std': 0.0030000000000000027, 'EER': -1}\n",
      "[55] Eval metrics for task 2 >> {'accuracy': 0.35400000000000004, 'loss': 0.005861945748329163, 'std': 0.18300000000000002, 'EER': -1}\n",
      "[56] Eval metrics for task 1 >> {'accuracy': 0.551, 'loss': 0.010007429718971252, 'std': 0.01100000000000001, 'EER': -1}\n",
      "[56] Eval metrics for task 2 >> {'accuracy': 0.348, 'loss': 0.007104350507259369, 'std': 0.165, 'EER': -1}\n",
      "[57] Eval metrics for task 1 >> {'accuracy': 0.52, 'loss': 0.010524002313613891, 'std': 0.03500000000000003, 'EER': -1}\n",
      "[57] Eval metrics for task 2 >> {'accuracy': 0.39749999999999996, 'loss': 0.004851760864257812, 'std': 0.0965, 'EER': -1}\n",
      "[58] Eval metrics for task 1 >> {'accuracy': 0.627, 'loss': 0.008257172286510468, 'std': 0.05600000000000005, 'EER': -1}\n",
      "[58] Eval metrics for task 2 >> {'accuracy': 0.379, 'loss': 0.005413423240184784, 'std': 0.03899999999999998, 'EER': -1}\n",
      "[59] Eval metrics for task 1 >> {'accuracy': 0.5805, 'loss': 0.011543452978134154, 'std': 0.08650000000000002, 'EER': -1}\n",
      "[59] Eval metrics for task 2 >> {'accuracy': 0.2545, 'loss': 0.008278275668621063, 'std': 0.1385, 'EER': -1}\n",
      "[60] Eval metrics for task 1 >> {'accuracy': 0.562, 'loss': 0.009051377356052399, 'std': 0.025999999999999968, 'EER': -1}\n",
      "[60] Eval metrics for task 2 >> {'accuracy': 0.448, 'loss': 0.004926236987113953, 'std': 0.196, 'EER': -1}\n",
      "[61] Eval metrics for task 1 >> {'accuracy': 0.5860000000000001, 'loss': 0.009011574983596803, 'std': 0.043999999999999984, 'EER': -1}\n",
      "[61] Eval metrics for task 2 >> {'accuracy': 0.45399999999999996, 'loss': 0.004789904117584228, 'std': 0.12699999999999997, 'EER': -1}\n",
      "[62] Eval metrics for task 1 >> {'accuracy': 0.6759999999999999, 'loss': 0.007262940347194671, 'std': 0.10100000000000003, 'EER': -1}\n",
      "[62] Eval metrics for task 2 >> {'accuracy': 0.36850000000000005, 'loss': 0.006831819593906403, 'std': 0.17250000000000001, 'EER': -1}\n",
      "[63] Eval metrics for task 1 >> {'accuracy': 0.495, 'loss': 0.014848142981529236, 'std': 0.10899999999999999, 'EER': -1}\n",
      "[63] Eval metrics for task 2 >> {'accuracy': 0.44099999999999995, 'loss': 0.005281072854995727, 'std': 0.147, 'EER': -1}\n",
      "[64] Eval metrics for task 1 >> {'accuracy': 0.599, 'loss': 0.011081100821495056, 'std': 0.04499999999999999, 'EER': -1}\n",
      "[64] Eval metrics for task 2 >> {'accuracy': 0.4815, 'loss': 0.004527604818344117, 'std': 0.08349999999999996, 'EER': -1}\n",
      "[65] Eval metrics for task 1 >> {'accuracy': 0.47950000000000004, 'loss': 0.013144831061363221, 'std': 0.037500000000000006, 'EER': -1}\n",
      "[65] Eval metrics for task 2 >> {'accuracy': 0.4685, 'loss': 0.005195276737213135, 'std': 0.21450000000000002, 'EER': -1}\n",
      "[66] Eval metrics for task 1 >> {'accuracy': 0.511, 'loss': 0.011849353551864623, 'std': 0.049000000000000016, 'EER': -1}\n",
      "[66] Eval metrics for task 2 >> {'accuracy': 0.613, 'loss': 0.0033525083661079405, 'std': 0.07599999999999996, 'EER': -1}\n",
      "[67] Eval metrics for task 1 >> {'accuracy': 0.495, 'loss': 0.010051334738731384, 'std': 0.09799999999999998, 'EER': -1}\n",
      "[67] Eval metrics for task 2 >> {'accuracy': 0.5085, 'loss': 0.0041920974254608155, 'std': 0.005500000000000005, 'EER': -1}\n",
      "[68] Eval metrics for task 1 >> {'accuracy': 0.5255, 'loss': 0.01786767649650574, 'std': 0.0875, 'EER': -1}\n",
      "[68] Eval metrics for task 2 >> {'accuracy': 0.35050000000000003, 'loss': 0.005803700923919678, 'std': 0.07149999999999998, 'EER': -1}\n",
      "[69] Eval metrics for task 1 >> {'accuracy': 0.652, 'loss': 0.011275312185287475, 'std': 0.118, 'EER': -1}\n",
      "[69] Eval metrics for task 2 >> {'accuracy': 0.4365, 'loss': 0.0062328574061393735, 'std': 0.0985, 'EER': -1}\n",
      "[70] Eval metrics for task 1 >> {'accuracy': 0.3005, 'loss': 0.02440405535697937, 'std': 0.2305, 'EER': -1}\n",
      "[70] Eval metrics for task 2 >> {'accuracy': 0.381, 'loss': 0.006259576320648193, 'std': 0.03899999999999998, 'EER': -1}\n",
      "[71] Eval metrics for task 1 >> {'accuracy': 0.427, 'loss': 0.019328080773353577, 'std': 0.01200000000000001, 'EER': -1}\n",
      "[71] Eval metrics for task 2 >> {'accuracy': 0.42400000000000004, 'loss': 0.004968288958072662, 'std': 0.027999999999999997, 'EER': -1}\n",
      "[72] Eval metrics for task 1 >> {'accuracy': 0.542, 'loss': 0.012686482310295105, 'std': 0.066, 'EER': -1}\n",
      "[72] Eval metrics for task 2 >> {'accuracy': 0.4585, 'loss': 0.005006183743476868, 'std': 0.08750000000000002, 'EER': -1}\n",
      "[73] Eval metrics for task 1 >> {'accuracy': 0.524, 'loss': 0.012436297297477722, 'std': 0.020000000000000018, 'EER': -1}\n",
      "[73] Eval metrics for task 2 >> {'accuracy': 0.4745, 'loss': 0.00486751252412796, 'std': 0.09249999999999997, 'EER': -1}\n",
      "[74] Eval metrics for task 1 >> {'accuracy': 0.5685, 'loss': 0.01329089879989624, 'std': 0.05449999999999999, 'EER': -1}\n",
      "[74] Eval metrics for task 2 >> {'accuracy': 0.4635, 'loss': 0.004828847110271454, 'std': 0.048500000000000015, 'EER': -1}\n",
      "[75] Eval metrics for task 1 >> {'accuracy': 0.4685, 'loss': 0.014348415970802306, 'std': 0.05650000000000002, 'EER': -1}\n",
      "[75] Eval metrics for task 2 >> {'accuracy': 0.515, 'loss': 0.004604626536369324, 'std': 0.14800000000000002, 'EER': -1}\n",
      "[76] Eval metrics for task 1 >> {'accuracy': 0.5235, 'loss': 0.013443407893180848, 'std': 0.10650000000000001, 'EER': -1}\n",
      "[76] Eval metrics for task 2 >> {'accuracy': 0.46099999999999997, 'loss': 0.005147046744823456, 'std': 0.11499999999999999, 'EER': -1}\n",
      "[77] Eval metrics for task 1 >> {'accuracy': 0.553, 'loss': 0.011161734342575074, 'std': 0.11100000000000002, 'EER': -1}\n",
      "[77] Eval metrics for task 2 >> {'accuracy': 0.525, 'loss': 0.00448743623495102, 'std': 0.06599999999999998, 'EER': -1}\n",
      "[78] Eval metrics for task 1 >> {'accuracy': 0.419, 'loss': 0.011855655193328858, 'std': 0.008000000000000007, 'EER': -1}\n",
      "[78] Eval metrics for task 2 >> {'accuracy': 0.6185, 'loss': 0.003664688467979431, 'std': 0.10749999999999998, 'EER': -1}\n",
      "[79] Eval metrics for task 1 >> {'accuracy': 0.525, 'loss': 0.010822154939174652, 'std': 0.05699999999999997, 'EER': -1}\n",
      "[79] Eval metrics for task 2 >> {'accuracy': 0.5720000000000001, 'loss': 0.004007016181945801, 'std': 0.02699999999999997, 'EER': -1}\n",
      "[80] Eval metrics for task 1 >> {'accuracy': 0.4345, 'loss': 0.010815539121627808, 'std': 0.009500000000000008, 'EER': -1}\n",
      "[80] Eval metrics for task 2 >> {'accuracy': 0.6355, 'loss': 0.0033257626891136168, 'std': 0.0665, 'EER': -1}\n",
      "[81] Eval metrics for task 1 >> {'accuracy': 0.4635, 'loss': 0.010731225490570068, 'std': 0.025499999999999995, 'EER': -1}\n",
      "[81] Eval metrics for task 2 >> {'accuracy': 0.615, 'loss': 0.0036232234239578246, 'std': 0.07899999999999996, 'EER': -1}\n",
      "[82] Eval metrics for task 1 >> {'accuracy': 0.427, 'loss': 0.010707897305488587, 'std': 0.007000000000000006, 'EER': -1}\n",
      "[82] Eval metrics for task 2 >> {'accuracy': 0.6379999999999999, 'loss': 0.003313480257987976, 'std': 0.07100000000000001, 'EER': -1}\n",
      "[83] Eval metrics for task 1 >> {'accuracy': 0.48050000000000004, 'loss': 0.011496857047080993, 'std': 0.038500000000000006, 'EER': -1}\n",
      "[83] Eval metrics for task 2 >> {'accuracy': 0.5955, 'loss': 0.0037342326343059538, 'std': 0.04949999999999999, 'EER': -1}\n",
      "[84] Eval metrics for task 1 >> {'accuracy': 0.4375, 'loss': 0.011522031784057618, 'std': 0.028500000000000025, 'EER': -1}\n",
      "[84] Eval metrics for task 2 >> {'accuracy': 0.6335, 'loss': 0.00338386270403862, 'std': 0.055499999999999994, 'EER': -1}\n",
      "[85] Eval metrics for task 1 >> {'accuracy': 0.5675, 'loss': 0.010667881846427918, 'std': 0.045499999999999985, 'EER': -1}\n",
      "[85] Eval metrics for task 2 >> {'accuracy': 0.5385, 'loss': 0.004554580450057983, 'std': 0.0615, 'EER': -1}\n",
      "[86] Eval metrics for task 1 >> {'accuracy': 0.45599999999999996, 'loss': 0.012164076566696167, 'std': 0.027999999999999997, 'EER': -1}\n",
      "[86] Eval metrics for task 2 >> {'accuracy': 0.611, 'loss': 0.00361004301905632, 'std': 0.06, 'EER': -1}\n",
      "[87] Eval metrics for task 1 >> {'accuracy': 0.521, 'loss': 0.010902445435523987, 'std': 0.05999999999999997, 'EER': -1}\n",
      "[87] Eval metrics for task 2 >> {'accuracy': 0.5875, 'loss': 0.003914378702640533, 'std': 0.0685, 'EER': -1}\n",
      "[88] Eval metrics for task 1 >> {'accuracy': 0.5105, 'loss': 0.010306191563606262, 'std': 0.040500000000000036, 'EER': -1}\n",
      "[88] Eval metrics for task 2 >> {'accuracy': 0.5900000000000001, 'loss': 0.0038261520862579346, 'std': 0.04999999999999999, 'EER': -1}\n",
      "[89] Eval metrics for task 1 >> {'accuracy': 0.4375, 'loss': 0.0111845144033432, 'std': 0.02350000000000002, 'EER': -1}\n",
      "[89] Eval metrics for task 2 >> {'accuracy': 0.639, 'loss': 0.0033481604158878326, 'std': 0.064, 'EER': -1}\n",
      "[90] Eval metrics for task 1 >> {'accuracy': 0.446, 'loss': 0.009999900460243225, 'std': 0.0050000000000000044, 'EER': -1}\n",
      "[90] Eval metrics for task 2 >> {'accuracy': 0.629, 'loss': 0.003357540339231491, 'std': 0.05800000000000005, 'EER': -1}\n",
      "[91] Eval metrics for task 1 >> {'accuracy': 0.5045, 'loss': 0.010940045714378357, 'std': 0.03150000000000003, 'EER': -1}\n",
      "[91] Eval metrics for task 2 >> {'accuracy': 0.5865, 'loss': 0.003889119505882263, 'std': 0.05349999999999999, 'EER': -1}\n",
      "[92] Eval metrics for task 1 >> {'accuracy': 0.518, 'loss': 0.011566073894500732, 'std': 0.04899999999999999, 'EER': -1}\n",
      "[92] Eval metrics for task 2 >> {'accuracy': 0.5825, 'loss': 0.003965287238359452, 'std': 0.0615, 'EER': -1}\n",
      "[93] Eval metrics for task 1 >> {'accuracy': 0.4505, 'loss': 0.011506281733512879, 'std': 0.038500000000000006, 'EER': -1}\n",
      "[93] Eval metrics for task 2 >> {'accuracy': 0.6265000000000001, 'loss': 0.003440420627593994, 'std': 0.039500000000000035, 'EER': -1}\n",
      "[94] Eval metrics for task 1 >> {'accuracy': 0.45799999999999996, 'loss': 0.011319940090179443, 'std': 0.028999999999999998, 'EER': -1}\n",
      "[94] Eval metrics for task 2 >> {'accuracy': 0.6245, 'loss': 0.0034967233538627626, 'std': 0.07049999999999995, 'EER': -1}\n",
      "[95] Eval metrics for task 1 >> {'accuracy': 0.5660000000000001, 'loss': 0.010386272311210632, 'std': 0.04199999999999998, 'EER': -1}\n",
      "[95] Eval metrics for task 2 >> {'accuracy': 0.538, 'loss': 0.004489013314247131, 'std': 0.04299999999999998, 'EER': -1}\n",
      "[96] Eval metrics for task 1 >> {'accuracy': 0.56, 'loss': 0.010258971929550172, 'std': 0.05199999999999999, 'EER': -1}\n",
      "[96] Eval metrics for task 2 >> {'accuracy': 0.5565, 'loss': 0.004254797875881195, 'std': 0.056499999999999995, 'EER': -1}\n",
      "[97] Eval metrics for task 1 >> {'accuracy': 0.5505, 'loss': 0.010077802419662475, 'std': 0.04349999999999998, 'EER': -1}\n",
      "[97] Eval metrics for task 2 >> {'accuracy': 0.554, 'loss': 0.0043582538664340975, 'std': 0.046999999999999986, 'EER': -1}\n",
      "[98] Eval metrics for task 1 >> {'accuracy': 0.48150000000000004, 'loss': 0.010568228960037231, 'std': 0.014499999999999985, 'EER': -1}\n",
      "[98] Eval metrics for task 2 >> {'accuracy': 0.5980000000000001, 'loss': 0.0037923972010612487, 'std': 0.07700000000000001, 'EER': -1}\n",
      "[99] Eval metrics for task 1 >> {'accuracy': 0.508, 'loss': 0.010458608746528625, 'std': 0.04100000000000001, 'EER': -1}\n",
      "[99] Eval metrics for task 2 >> {'accuracy': 0.585, 'loss': 0.0038822101354599, 'std': 0.059, 'EER': -1}\n",
      "[100] Eval metrics for task 1 >> {'accuracy': 0.4455, 'loss': 0.010452526807785033, 'std': 0.017500000000000016, 'EER': -1}\n",
      "[100] Eval metrics for task 2 >> {'accuracy': 0.6275, 'loss': 0.0034113009572029115, 'std': 0.07049999999999995, 'EER': -1}\n",
      "training_task_end\n",
      "---------------------------- Task 3 -----------------------\n",
      "[101] Eval metrics for task 1 >> {'accuracy': 0.597, 'loss': 0.012458280444145202, 'std': 0.019000000000000017, 'EER': -1}\n",
      "[101] Eval metrics for task 2 >> {'accuracy': 0.492, 'loss': 0.006706747770309448, 'std': 0.05000000000000002, 'EER': -1}\n",
      "[101] Eval metrics for task 3 >> {'accuracy': 0.155, 'loss': 0.007527933180332184, 'std': 0.055999999999999994, 'EER': -1}\n",
      "[102] Eval metrics for task 1 >> {'accuracy': 0.47250000000000003, 'loss': 0.018918027520179747, 'std': 0.04450000000000001, 'EER': -1}\n",
      "[102] Eval metrics for task 2 >> {'accuracy': 0.5075000000000001, 'loss': 0.009244395732879638, 'std': 0.020500000000000018, 'EER': -1}\n",
      "[102] Eval metrics for task 3 >> {'accuracy': 0.1725, 'loss': 0.00825395518541336, 'std': 0.0795, 'EER': -1}\n",
      "[103] Eval metrics for task 1 >> {'accuracy': 0.473, 'loss': 0.021255329370498656, 'std': 0.10799999999999998, 'EER': -1}\n",
      "[103] Eval metrics for task 2 >> {'accuracy': 0.494, 'loss': 0.0098837388753891, 'std': 0.015000000000000013, 'EER': -1}\n",
      "[103] Eval metrics for task 3 >> {'accuracy': 0.2495, 'loss': 0.008072235345840454, 'std': 0.008500000000000008, 'EER': -1}\n",
      "[104] Eval metrics for task 1 >> {'accuracy': 0.506, 'loss': 0.01823076367378235, 'std': 0.05100000000000002, 'EER': -1}\n",
      "[104] Eval metrics for task 2 >> {'accuracy': 0.5249999999999999, 'loss': 0.00978189218044281, 'std': 0.043999999999999984, 'EER': -1}\n",
      "[104] Eval metrics for task 3 >> {'accuracy': 0.191, 'loss': 0.008904150128364563, 'std': 0.01100000000000001, 'EER': -1}\n",
      "[105] Eval metrics for task 1 >> {'accuracy': 0.468, 'loss': 0.021295578479766847, 'std': 0.07900000000000001, 'EER': -1}\n",
      "[105] Eval metrics for task 2 >> {'accuracy': 0.484, 'loss': 0.010925339698791505, 'std': 0.027999999999999997, 'EER': -1}\n",
      "[105] Eval metrics for task 3 >> {'accuracy': 0.2445, 'loss': 0.008946299791336059, 'std': 0.09250000000000001, 'EER': -1}\n",
      "[106] Eval metrics for task 1 >> {'accuracy': 0.493, 'loss': 0.01910777771472931, 'std': 0.05600000000000002, 'EER': -1}\n",
      "[106] Eval metrics for task 2 >> {'accuracy': 0.5205, 'loss': 0.010010005474090576, 'std': 0.026500000000000024, 'EER': -1}\n",
      "[106] Eval metrics for task 3 >> {'accuracy': 0.22799999999999998, 'loss': 0.007979761481285095, 'std': 0.020000000000000004, 'EER': -1}\n",
      "[107] Eval metrics for task 1 >> {'accuracy': 0.493, 'loss': 0.02155893349647522, 'std': 0.015000000000000013, 'EER': -1}\n",
      "[107] Eval metrics for task 2 >> {'accuracy': 0.472, 'loss': 0.010972779393196106, 'std': 0.0020000000000000018, 'EER': -1}\n",
      "[107] Eval metrics for task 3 >> {'accuracy': 0.23800000000000002, 'loss': 0.008180467844009399, 'std': 0.037000000000000005, 'EER': -1}\n",
      "[108] Eval metrics for task 1 >> {'accuracy': 0.5185, 'loss': 0.018990886807441713, 'std': 0.013500000000000012, 'EER': -1}\n",
      "[108] Eval metrics for task 2 >> {'accuracy': 0.4975, 'loss': 0.009964883983135223, 'std': 0.005500000000000005, 'EER': -1}\n",
      "[108] Eval metrics for task 3 >> {'accuracy': 0.23149999999999998, 'loss': 0.008308485329151153, 'std': 0.05249999999999999, 'EER': -1}\n",
      "[109] Eval metrics for task 1 >> {'accuracy': 0.49749999999999994, 'loss': 0.022595259070396424, 'std': 0.0875, 'EER': -1}\n",
      "[109] Eval metrics for task 2 >> {'accuracy': 0.4475, 'loss': 0.012130759954452515, 'std': 0.0295, 'EER': -1}\n",
      "[109] Eval metrics for task 3 >> {'accuracy': 0.34950000000000003, 'loss': 0.006502329885959625, 'std': 0.02149999999999999, 'EER': -1}\n",
      "[110] Eval metrics for task 1 >> {'accuracy': 0.539, 'loss': 0.01612140166759491, 'std': 0.02300000000000002, 'EER': -1}\n",
      "[110] Eval metrics for task 2 >> {'accuracy': 0.471, 'loss': 0.01096204423904419, 'std': 0.00799999999999998, 'EER': -1}\n",
      "[110] Eval metrics for task 3 >> {'accuracy': 0.303, 'loss': 0.0072047654986381535, 'std': 0.020000000000000018, 'EER': -1}\n",
      "[111] Eval metrics for task 1 >> {'accuracy': 0.5005, 'loss': 0.02131242799758911, 'std': 0.07049999999999998, 'EER': -1}\n",
      "[111] Eval metrics for task 2 >> {'accuracy': 0.502, 'loss': 0.01099519944190979, 'std': 0.013000000000000012, 'EER': -1}\n",
      "[111] Eval metrics for task 3 >> {'accuracy': 0.258, 'loss': 0.008118742406368255, 'std': 0.044, 'EER': -1}\n",
      "[112] Eval metrics for task 1 >> {'accuracy': 0.522, 'loss': 0.019249694705009462, 'std': 0.019000000000000017, 'EER': -1}\n",
      "[112] Eval metrics for task 2 >> {'accuracy': 0.382, 'loss': 0.015714958786964415, 'std': 0.098, 'EER': -1}\n",
      "[112] Eval metrics for task 3 >> {'accuracy': 0.35750000000000004, 'loss': 0.00678675788640976, 'std': 0.03950000000000001, 'EER': -1}\n",
      "[113] Eval metrics for task 1 >> {'accuracy': 0.446, 'loss': 0.021965457916259767, 'std': 0.04999999999999999, 'EER': -1}\n",
      "[113] Eval metrics for task 2 >> {'accuracy': 0.3795, 'loss': 0.014760962963104248, 'std': 0.04949999999999999, 'EER': -1}\n",
      "[113] Eval metrics for task 3 >> {'accuracy': 0.432, 'loss': 0.005649505615234375, 'std': 0.0010000000000000009, 'EER': -1}\n",
      "[114] Eval metrics for task 1 >> {'accuracy': 0.472, 'loss': 0.021422937154769898, 'std': 0.016999999999999987, 'EER': -1}\n",
      "[114] Eval metrics for task 2 >> {'accuracy': 0.4735, 'loss': 0.011078919887542725, 'std': 0.004500000000000004, 'EER': -1}\n",
      "[114] Eval metrics for task 3 >> {'accuracy': 0.346, 'loss': 0.006839668810367584, 'std': 0.01899999999999999, 'EER': -1}\n",
      "[115] Eval metrics for task 1 >> {'accuracy': 0.5395, 'loss': 0.016521097898483276, 'std': 0.0885, 'EER': -1}\n",
      "[115] Eval metrics for task 2 >> {'accuracy': 0.49949999999999994, 'loss': 0.011104377150535584, 'std': 0.07549999999999998, 'EER': -1}\n",
      "[115] Eval metrics for task 3 >> {'accuracy': 0.27, 'loss': 0.008470697402954102, 'std': 0.015999999999999986, 'EER': -1}\n",
      "[116] Eval metrics for task 1 >> {'accuracy': 0.5285, 'loss': 0.017645536422729494, 'std': 0.03649999999999998, 'EER': -1}\n",
      "[116] Eval metrics for task 2 >> {'accuracy': 0.4365, 'loss': 0.012543619394302367, 'std': 0.027500000000000024, 'EER': -1}\n",
      "[116] Eval metrics for task 3 >> {'accuracy': 0.379, 'loss': 0.006876094579696655, 'std': 0.046999999999999986, 'EER': -1}\n",
      "[117] Eval metrics for task 1 >> {'accuracy': 0.46699999999999997, 'loss': 0.022576842069625853, 'std': 0.04200000000000001, 'EER': -1}\n",
      "[117] Eval metrics for task 2 >> {'accuracy': 0.413, 'loss': 0.012604409098625183, 'std': 0.0050000000000000044, 'EER': -1}\n",
      "[117] Eval metrics for task 3 >> {'accuracy': 0.45399999999999996, 'loss': 0.005499700486660004, 'std': 0.028999999999999998, 'EER': -1}\n",
      "[118] Eval metrics for task 1 >> {'accuracy': 0.5545, 'loss': 0.014391530513763427, 'std': 0.035499999999999976, 'EER': -1}\n",
      "[118] Eval metrics for task 2 >> {'accuracy': 0.4675, 'loss': 0.011931843757629394, 'std': 0.00949999999999998, 'EER': -1}\n",
      "[118] Eval metrics for task 3 >> {'accuracy': 0.356, 'loss': 0.007153335094451904, 'std': 0.010000000000000009, 'EER': -1}\n",
      "[119] Eval metrics for task 1 >> {'accuracy': 0.5489999999999999, 'loss': 0.019029181361198425, 'std': 0.067, 'EER': -1}\n",
      "[119] Eval metrics for task 2 >> {'accuracy': 0.4675, 'loss': 0.012905946850776673, 'std': 0.026499999999999996, 'EER': -1}\n",
      "[119] Eval metrics for task 3 >> {'accuracy': 0.35550000000000004, 'loss': 0.007342817306518555, 'std': 0.048500000000000015, 'EER': -1}\n",
      "[120] Eval metrics for task 1 >> {'accuracy': 0.509, 'loss': 0.02005631494522095, 'std': 0.040000000000000036, 'EER': -1}\n",
      "[120] Eval metrics for task 2 >> {'accuracy': 0.449, 'loss': 0.013327847242355346, 'std': 0.019000000000000017, 'EER': -1}\n",
      "[120] Eval metrics for task 3 >> {'accuracy': 0.4315, 'loss': 0.006384060680866241, 'std': 0.015500000000000014, 'EER': -1}\n",
      "[121] Eval metrics for task 1 >> {'accuracy': 0.5309999999999999, 'loss': 0.01858664655685425, 'std': 0.035999999999999976, 'EER': -1}\n",
      "[121] Eval metrics for task 2 >> {'accuracy': 0.3715, 'loss': 0.01555095386505127, 'std': 0.0625, 'EER': -1}\n",
      "[121] Eval metrics for task 3 >> {'accuracy': 0.4955, 'loss': 0.005327252447605133, 'std': 0.012500000000000011, 'EER': -1}\n",
      "[122] Eval metrics for task 1 >> {'accuracy': 0.5509999999999999, 'loss': 0.016144394397735597, 'std': 0.05299999999999999, 'EER': -1}\n",
      "[122] Eval metrics for task 2 >> {'accuracy': 0.49150000000000005, 'loss': 0.012459500551223754, 'std': 0.05450000000000002, 'EER': -1}\n",
      "[122] Eval metrics for task 3 >> {'accuracy': 0.359, 'loss': 0.00746235328912735, 'std': 0.033, 'EER': -1}\n",
      "[123] Eval metrics for task 1 >> {'accuracy': 0.5745, 'loss': 0.015667078733444213, 'std': 0.02949999999999997, 'EER': -1}\n",
      "[123] Eval metrics for task 2 >> {'accuracy': 0.4585, 'loss': 0.014136726021766662, 'std': 0.009500000000000008, 'EER': -1}\n",
      "[123] Eval metrics for task 3 >> {'accuracy': 0.3825, 'loss': 0.007591444253921509, 'std': 0.07250000000000001, 'EER': -1}\n",
      "[124] Eval metrics for task 1 >> {'accuracy': 0.4435, 'loss': 0.022309959650039672, 'std': 0.0295, 'EER': -1}\n",
      "[124] Eval metrics for task 2 >> {'accuracy': 0.4455, 'loss': 0.013705176949501038, 'std': 0.08650000000000002, 'EER': -1}\n",
      "[124] Eval metrics for task 3 >> {'accuracy': 0.4255, 'loss': 0.0066107257604598995, 'std': 0.04749999999999999, 'EER': -1}\n",
      "[125] Eval metrics for task 1 >> {'accuracy': 0.534, 'loss': 0.01840207016468048, 'std': 0.02899999999999997, 'EER': -1}\n",
      "[125] Eval metrics for task 2 >> {'accuracy': 0.4265, 'loss': 0.013598208546638488, 'std': 0.027499999999999997, 'EER': -1}\n",
      "[125] Eval metrics for task 3 >> {'accuracy': 0.4135, 'loss': 0.006667495965957642, 'std': 0.036500000000000005, 'EER': -1}\n",
      "[126] Eval metrics for task 1 >> {'accuracy': 0.524, 'loss': 0.01906001603603363, 'std': 0.06399999999999997, 'EER': -1}\n",
      "[126] Eval metrics for task 2 >> {'accuracy': 0.44399999999999995, 'loss': 0.01289713716506958, 'std': 0.025999999999999995, 'EER': -1}\n",
      "[126] Eval metrics for task 3 >> {'accuracy': 0.46199999999999997, 'loss': 0.005868967115879059, 'std': 0.016999999999999987, 'EER': -1}\n",
      "[127] Eval metrics for task 1 >> {'accuracy': 0.5529999999999999, 'loss': 0.019329514145851136, 'std': 0.013999999999999957, 'EER': -1}\n",
      "[127] Eval metrics for task 2 >> {'accuracy': 0.4495, 'loss': 0.01372530460357666, 'std': 0.07950000000000002, 'EER': -1}\n",
      "[127] Eval metrics for task 3 >> {'accuracy': 0.40049999999999997, 'loss': 0.007011061370372772, 'std': 0.01849999999999999, 'EER': -1}\n",
      "[128] Eval metrics for task 1 >> {'accuracy': 0.527, 'loss': 0.018490111947059632, 'std': 0.06199999999999997, 'EER': -1}\n",
      "[128] Eval metrics for task 2 >> {'accuracy': 0.39949999999999997, 'loss': 0.015677725672721864, 'std': 0.022499999999999996, 'EER': -1}\n",
      "[128] Eval metrics for task 3 >> {'accuracy': 0.507, 'loss': 0.00548958420753479, 'std': 0.07099999999999998, 'EER': -1}\n",
      "[129] Eval metrics for task 1 >> {'accuracy': 0.5535, 'loss': 0.022678122282028198, 'std': 0.14849999999999997, 'EER': -1}\n",
      "[129] Eval metrics for task 2 >> {'accuracy': 0.4595, 'loss': 0.014438506722450256, 'std': 0.07150000000000001, 'EER': -1}\n",
      "[129] Eval metrics for task 3 >> {'accuracy': 0.353, 'loss': 0.008247675776481628, 'std': 0.02099999999999999, 'EER': -1}\n",
      "[130] Eval metrics for task 1 >> {'accuracy': 0.5670000000000001, 'loss': 0.018595253229141236, 'std': 0.12000000000000002, 'EER': -1}\n",
      "[130] Eval metrics for task 2 >> {'accuracy': 0.4585, 'loss': 0.01379922366142273, 'std': 0.04450000000000001, 'EER': -1}\n",
      "[130] Eval metrics for task 3 >> {'accuracy': 0.39349999999999996, 'loss': 0.007218755066394806, 'std': 0.0345, 'EER': -1}\n",
      "[131] Eval metrics for task 1 >> {'accuracy': 0.5625, 'loss': 0.019206955671310425, 'std': 0.13949999999999999, 'EER': -1}\n",
      "[131] Eval metrics for task 2 >> {'accuracy': 0.46199999999999997, 'loss': 0.013652806878089905, 'std': 0.04300000000000001, 'EER': -1}\n",
      "[131] Eval metrics for task 3 >> {'accuracy': 0.39, 'loss': 0.007340398490428925, 'std': 0.034, 'EER': -1}\n",
      "[132] Eval metrics for task 1 >> {'accuracy': 0.5545, 'loss': 0.019475051641464233, 'std': 0.11950000000000002, 'EER': -1}\n",
      "[132] Eval metrics for task 2 >> {'accuracy': 0.4685, 'loss': 0.013482755184173583, 'std': 0.046500000000000014, 'EER': -1}\n",
      "[132] Eval metrics for task 3 >> {'accuracy': 0.3765, 'loss': 0.007479833543300628, 'std': 0.0015000000000000013, 'EER': -1}\n",
      "[133] Eval metrics for task 1 >> {'accuracy': 0.5675, 'loss': 0.019053297519683838, 'std': 0.12549999999999997, 'EER': -1}\n",
      "[133] Eval metrics for task 2 >> {'accuracy': 0.4685, 'loss': 0.013519674181938172, 'std': 0.04250000000000001, 'EER': -1}\n",
      "[133] Eval metrics for task 3 >> {'accuracy': 0.3825, 'loss': 0.007564495623111725, 'std': 0.02150000000000002, 'EER': -1}\n",
      "[134] Eval metrics for task 1 >> {'accuracy': 0.5665, 'loss': 0.01740623342990875, 'std': 0.13749999999999998, 'EER': -1}\n",
      "[134] Eval metrics for task 2 >> {'accuracy': 0.47, 'loss': 0.013335118889808656, 'std': 0.049000000000000016, 'EER': -1}\n",
      "[134] Eval metrics for task 3 >> {'accuracy': 0.38649999999999995, 'loss': 0.007463850259780884, 'std': 0.024499999999999994, 'EER': -1}\n",
      "[135] Eval metrics for task 1 >> {'accuracy': 0.5609999999999999, 'loss': 0.01941442894935608, 'std': 0.12699999999999997, 'EER': -1}\n",
      "[135] Eval metrics for task 2 >> {'accuracy': 0.4635, 'loss': 0.013783055424690247, 'std': 0.0625, 'EER': -1}\n",
      "[135] Eval metrics for task 3 >> {'accuracy': 0.387, 'loss': 0.0073911606669425966, 'std': 0.019000000000000017, 'EER': -1}\n",
      "[136] Eval metrics for task 1 >> {'accuracy': 0.5605, 'loss': 0.017451043605804444, 'std': 0.11650000000000002, 'EER': -1}\n",
      "[136] Eval metrics for task 2 >> {'accuracy': 0.4595, 'loss': 0.013226967453956604, 'std': 0.05250000000000002, 'EER': -1}\n",
      "[136] Eval metrics for task 3 >> {'accuracy': 0.395, 'loss': 0.007085332334041595, 'std': 0.010000000000000009, 'EER': -1}\n",
      "[137] Eval metrics for task 1 >> {'accuracy': 0.5640000000000001, 'loss': 0.0191419358253479, 'std': 0.11900000000000002, 'EER': -1}\n",
      "[137] Eval metrics for task 2 >> {'accuracy': 0.4665, 'loss': 0.013531307339668274, 'std': 0.036500000000000005, 'EER': -1}\n",
      "[137] Eval metrics for task 3 >> {'accuracy': 0.379, 'loss': 0.007537897348403931, 'std': 0.02100000000000002, 'EER': -1}\n",
      "[138] Eval metrics for task 1 >> {'accuracy': 0.5545, 'loss': 0.020297003507614136, 'std': 0.12850000000000003, 'EER': -1}\n",
      "[138] Eval metrics for task 2 >> {'accuracy': 0.46099999999999997, 'loss': 0.013703442811965942, 'std': 0.035, 'EER': -1}\n",
      "[138] Eval metrics for task 3 >> {'accuracy': 0.393, 'loss': 0.007251588642597198, 'std': 0.016999999999999987, 'EER': -1}\n",
      "[139] Eval metrics for task 1 >> {'accuracy': 0.5685, 'loss': 0.017620424389839174, 'std': 0.12449999999999997, 'EER': -1}\n",
      "[139] Eval metrics for task 2 >> {'accuracy': 0.47950000000000004, 'loss': 0.012870764017105102, 'std': 0.04350000000000001, 'EER': -1}\n",
      "[139] Eval metrics for task 3 >> {'accuracy': 0.3685, 'loss': 0.00772578775882721, 'std': 0.020500000000000018, 'EER': -1}\n",
      "[140] Eval metrics for task 1 >> {'accuracy': 0.5655, 'loss': 0.019193804979324342, 'std': 0.11450000000000002, 'EER': -1}\n",
      "[140] Eval metrics for task 2 >> {'accuracy': 0.47050000000000003, 'loss': 0.01319866955280304, 'std': 0.0335, 'EER': -1}\n",
      "[140] Eval metrics for task 3 >> {'accuracy': 0.3705, 'loss': 0.007639658570289612, 'std': 0.02250000000000002, 'EER': -1}\n",
      "[141] Eval metrics for task 1 >> {'accuracy': 0.5545, 'loss': 0.019440287828445434, 'std': 0.12350000000000003, 'EER': -1}\n",
      "[141] Eval metrics for task 2 >> {'accuracy': 0.46099999999999997, 'loss': 0.013523378252983094, 'std': 0.04100000000000001, 'EER': -1}\n",
      "[141] Eval metrics for task 3 >> {'accuracy': 0.394, 'loss': 0.007127120614051819, 'std': 0.014999999999999986, 'EER': -1}\n",
      "[142] Eval metrics for task 1 >> {'accuracy': 0.5730000000000001, 'loss': 0.01734090292453766, 'std': 0.11000000000000001, 'EER': -1}\n",
      "[142] Eval metrics for task 2 >> {'accuracy': 0.46950000000000003, 'loss': 0.013381288766860962, 'std': 0.04250000000000001, 'EER': -1}\n",
      "[142] Eval metrics for task 3 >> {'accuracy': 0.3705, 'loss': 0.007722891211509705, 'std': 0.01150000000000001, 'EER': -1}\n",
      "[143] Eval metrics for task 1 >> {'accuracy': 0.5575, 'loss': 0.018768349409103394, 'std': 0.11050000000000001, 'EER': -1}\n",
      "[143] Eval metrics for task 2 >> {'accuracy': 0.4665, 'loss': 0.013275343656539916, 'std': 0.036500000000000005, 'EER': -1}\n",
      "[143] Eval metrics for task 3 >> {'accuracy': 0.39, 'loss': 0.007251835763454438, 'std': 0.01899999999999999, 'EER': -1}\n",
      "[144] Eval metrics for task 1 >> {'accuracy': 0.5575, 'loss': 0.019221646308898926, 'std': 0.11550000000000002, 'EER': -1}\n",
      "[144] Eval metrics for task 2 >> {'accuracy': 0.46199999999999997, 'loss': 0.013475544095039368, 'std': 0.047000000000000014, 'EER': -1}\n",
      "[144] Eval metrics for task 3 >> {'accuracy': 0.3785, 'loss': 0.007375440180301666, 'std': 0.005500000000000005, 'EER': -1}\n",
      "[145] Eval metrics for task 1 >> {'accuracy': 0.5615, 'loss': 0.019325519442558288, 'std': 0.13149999999999998, 'EER': -1}\n",
      "[145] Eval metrics for task 2 >> {'accuracy': 0.4585, 'loss': 0.013858086824417115, 'std': 0.046500000000000014, 'EER': -1}\n",
      "[145] Eval metrics for task 3 >> {'accuracy': 0.391, 'loss': 0.0073152962327003475, 'std': 0.017999999999999988, 'EER': -1}\n",
      "[146] Eval metrics for task 1 >> {'accuracy': 0.554, 'loss': 0.02082149386405945, 'std': 0.12700000000000003, 'EER': -1}\n",
      "[146] Eval metrics for task 2 >> {'accuracy': 0.4505, 'loss': 0.014134940028190613, 'std': 0.055499999999999994, 'EER': -1}\n",
      "[146] Eval metrics for task 3 >> {'accuracy': 0.4085, 'loss': 0.0071004659533500675, 'std': 0.015499999999999986, 'EER': -1}\n",
      "[147] Eval metrics for task 1 >> {'accuracy': 0.5635, 'loss': 0.019290564060211183, 'std': 0.12350000000000003, 'EER': -1}\n",
      "[147] Eval metrics for task 2 >> {'accuracy': 0.47150000000000003, 'loss': 0.013429381728172303, 'std': 0.049500000000000016, 'EER': -1}\n",
      "[147] Eval metrics for task 3 >> {'accuracy': 0.3815, 'loss': 0.007548286080360412, 'std': 0.02350000000000002, 'EER': -1}\n",
      "[148] Eval metrics for task 1 >> {'accuracy': 0.573, 'loss': 0.017336755394935607, 'std': 0.12499999999999997, 'EER': -1}\n",
      "[148] Eval metrics for task 2 >> {'accuracy': 0.46499999999999997, 'loss': 0.01340945851802826, 'std': 0.03900000000000001, 'EER': -1}\n",
      "[148] Eval metrics for task 3 >> {'accuracy': 0.371, 'loss': 0.007603814899921417, 'std': 0.02300000000000002, 'EER': -1}\n",
      "[149] Eval metrics for task 1 >> {'accuracy': 0.572, 'loss': 0.01856983745098114, 'std': 0.12999999999999998, 'EER': -1}\n",
      "[149] Eval metrics for task 2 >> {'accuracy': 0.46499999999999997, 'loss': 0.013651116251945495, 'std': 0.05000000000000002, 'EER': -1}\n",
      "[149] Eval metrics for task 3 >> {'accuracy': 0.379, 'loss': 0.007585907876491546, 'std': 0.025000000000000022, 'EER': -1}\n",
      "[150] Eval metrics for task 1 >> {'accuracy': 0.5495, 'loss': 0.020928160429000853, 'std': 0.13250000000000003, 'EER': -1}\n",
      "[150] Eval metrics for task 2 >> {'accuracy': 0.45999999999999996, 'loss': 0.013724240660667419, 'std': 0.036000000000000004, 'EER': -1}\n",
      "[150] Eval metrics for task 3 >> {'accuracy': 0.401, 'loss': 0.007167557775974273, 'std': 0.027999999999999997, 'EER': -1}\n",
      "training_task_end\n",
      "---------------------------- Task 4 -----------------------\n",
      "[151] Eval metrics for task 1 >> {'accuracy': 0.34199999999999997, 'loss': 0.030763217210769654, 'std': 0.04400000000000001, 'EER': -1}\n",
      "[151] Eval metrics for task 2 >> {'accuracy': 0.1825, 'loss': 0.020996416330337525, 'std': 0.058499999999999996, 'EER': -1}\n",
      "[151] Eval metrics for task 3 >> {'accuracy': 0.26749999999999996, 'loss': 0.011065055966377258, 'std': 0.0945, 'EER': -1}\n",
      "[151] Eval metrics for task 4 >> {'accuracy': 0.504, 'loss': 0.004716220617294311, 'std': 0.02100000000000002, 'EER': -1}\n",
      "[152] Eval metrics for task 1 >> {'accuracy': 0.41100000000000003, 'loss': 0.019344051837921143, 'std': 0.048000000000000015, 'EER': -1}\n",
      "[152] Eval metrics for task 2 >> {'accuracy': 0.12, 'loss': 0.027869455337524413, 'std': 0.04800000000000001, 'EER': -1}\n",
      "[152] Eval metrics for task 3 >> {'accuracy': 0.34450000000000003, 'loss': 0.01082458770275116, 'std': 0.12050000000000001, 'EER': -1}\n",
      "[152] Eval metrics for task 4 >> {'accuracy': 0.7395, 'loss': 0.002756199240684509, 'std': 0.09749999999999998, 'EER': -1}\n",
      "[153] Eval metrics for task 1 >> {'accuracy': 0.4615, 'loss': 0.01698058831691742, 'std': 0.04450000000000001, 'EER': -1}\n",
      "[153] Eval metrics for task 2 >> {'accuracy': 0.1305, 'loss': 0.027438013315200807, 'std': 0.018499999999999996, 'EER': -1}\n",
      "[153] Eval metrics for task 3 >> {'accuracy': 0.3645, 'loss': 0.011127991437911986, 'std': 0.07950000000000002, 'EER': -1}\n",
      "[153] Eval metrics for task 4 >> {'accuracy': 0.7895, 'loss': 0.0022227443009614945, 'std': 0.03749999999999998, 'EER': -1}\n",
      "[154] Eval metrics for task 1 >> {'accuracy': 0.38649999999999995, 'loss': 0.02022149467468262, 'std': 0.0345, 'EER': -1}\n",
      "[154] Eval metrics for task 2 >> {'accuracy': 0.1095, 'loss': 0.02927898120880127, 'std': 0.0005000000000000004, 'EER': -1}\n",
      "[154] Eval metrics for task 3 >> {'accuracy': 0.391, 'loss': 0.011038587093353272, 'std': 0.069, 'EER': -1}\n",
      "[154] Eval metrics for task 4 >> {'accuracy': 0.8305, 'loss': 0.0018594548106193542, 'std': 0.03249999999999997, 'EER': -1}\n",
      "[155] Eval metrics for task 1 >> {'accuracy': 0.3395, 'loss': 0.023058870315551757, 'std': 0.11850000000000001, 'EER': -1}\n",
      "[155] Eval metrics for task 2 >> {'accuracy': 0.1155, 'loss': 0.029455023527145387, 'std': 0.0015000000000000013, 'EER': -1}\n",
      "[155] Eval metrics for task 3 >> {'accuracy': 0.3185, 'loss': 0.013417840957641602, 'std': 0.08750000000000001, 'EER': -1}\n",
      "[155] Eval metrics for task 4 >> {'accuracy': 0.847, 'loss': 0.0016269122809171677, 'std': 0.013000000000000012, 'EER': -1}\n",
      "[156] Eval metrics for task 1 >> {'accuracy': 0.366, 'loss': 0.020386492252349852, 'std': 0.159, 'EER': -1}\n",
      "[156] Eval metrics for task 2 >> {'accuracy': 0.127, 'loss': 0.028362220287323, 'std': 0.0020000000000000018, 'EER': -1}\n",
      "[156] Eval metrics for task 3 >> {'accuracy': 0.375, 'loss': 0.011565749645233154, 'std': 0.09899999999999998, 'EER': -1}\n",
      "[156] Eval metrics for task 4 >> {'accuracy': 0.8380000000000001, 'loss': 0.0017031154334545137, 'std': 0.04999999999999999, 'EER': -1}\n",
      "[157] Eval metrics for task 1 >> {'accuracy': 0.371, 'loss': 0.022134130477905273, 'std': 0.10799999999999998, 'EER': -1}\n",
      "[157] Eval metrics for task 2 >> {'accuracy': 0.14250000000000002, 'loss': 0.028753561973571776, 'std': 0.042499999999999996, 'EER': -1}\n",
      "[157] Eval metrics for task 3 >> {'accuracy': 0.345, 'loss': 0.012542661786079407, 'std': 0.031, 'EER': -1}\n",
      "[157] Eval metrics for task 4 >> {'accuracy': 0.842, 'loss': 0.00175687837600708, 'std': 0.01200000000000001, 'EER': -1}\n",
      "[158] Eval metrics for task 1 >> {'accuracy': 0.348, 'loss': 0.02297473382949829, 'std': 0.091, 'EER': -1}\n",
      "[158] Eval metrics for task 2 >> {'accuracy': 0.1505, 'loss': 0.02833201265335083, 'std': 0.005500000000000005, 'EER': -1}\n",
      "[158] Eval metrics for task 3 >> {'accuracy': 0.3145, 'loss': 0.01387147343158722, 'std': 0.0675, 'EER': -1}\n",
      "[158] Eval metrics for task 4 >> {'accuracy': 0.8534999999999999, 'loss': 0.0015861906409263612, 'std': 0.008500000000000008, 'EER': -1}\n",
      "[159] Eval metrics for task 1 >> {'accuracy': 0.40149999999999997, 'loss': 0.020281491041183472, 'std': 0.014499999999999985, 'EER': -1}\n",
      "[159] Eval metrics for task 2 >> {'accuracy': 0.1735, 'loss': 0.026817776203155518, 'std': 0.0165, 'EER': -1}\n",
      "[159] Eval metrics for task 3 >> {'accuracy': 0.3305, 'loss': 0.012917040586471558, 'std': 0.038500000000000006, 'EER': -1}\n",
      "[159] Eval metrics for task 4 >> {'accuracy': 0.8574999999999999, 'loss': 0.0016109847277402877, 'std': 0.003500000000000003, 'EER': -1}\n",
      "[160] Eval metrics for task 1 >> {'accuracy': 0.40249999999999997, 'loss': 0.02434360885620117, 'std': 0.007499999999999979, 'EER': -1}\n",
      "[160] Eval metrics for task 2 >> {'accuracy': 0.11750000000000001, 'loss': 0.03208281564712524, 'std': 0.021500000000000005, 'EER': -1}\n",
      "[160] Eval metrics for task 3 >> {'accuracy': 0.3385, 'loss': 0.01447051727771759, 'std': 0.0615, 'EER': -1}\n",
      "[160] Eval metrics for task 4 >> {'accuracy': 0.825, 'loss': 0.001972573459148407, 'std': 0.007000000000000006, 'EER': -1}\n",
      "[161] Eval metrics for task 1 >> {'accuracy': 0.362, 'loss': 0.024233243942260743, 'std': 0.101, 'EER': -1}\n",
      "[161] Eval metrics for task 2 >> {'accuracy': 0.1315, 'loss': 0.030439228534698486, 'std': 0.016499999999999994, 'EER': -1}\n",
      "[161] Eval metrics for task 3 >> {'accuracy': 0.33899999999999997, 'loss': 0.013707220077514648, 'std': 0.05600000000000002, 'EER': -1}\n",
      "[161] Eval metrics for task 4 >> {'accuracy': 0.8745, 'loss': 0.0014672493487596513, 'std': 0.006500000000000006, 'EER': -1}\n",
      "[162] Eval metrics for task 1 >> {'accuracy': 0.3375, 'loss': 0.026789395332336426, 'std': 0.08049999999999999, 'EER': -1}\n",
      "[162] Eval metrics for task 2 >> {'accuracy': 0.1535, 'loss': 0.029089622259140014, 'std': 0.006500000000000006, 'EER': -1}\n",
      "[162] Eval metrics for task 3 >> {'accuracy': 0.2895, 'loss': 0.015841218590736388, 'std': 0.024499999999999994, 'EER': -1}\n",
      "[162] Eval metrics for task 4 >> {'accuracy': 0.7605, 'loss': 0.002714072942733765, 'std': 0.09649999999999997, 'EER': -1}\n",
      "[163] Eval metrics for task 1 >> {'accuracy': 0.3725, 'loss': 0.021557574033737183, 'std': 0.1275, 'EER': -1}\n",
      "[163] Eval metrics for task 2 >> {'accuracy': 0.1365, 'loss': 0.031205233812332152, 'std': 0.03749999999999999, 'EER': -1}\n",
      "[163] Eval metrics for task 3 >> {'accuracy': 0.35350000000000004, 'loss': 0.013662642836570739, 'std': 0.04050000000000001, 'EER': -1}\n",
      "[163] Eval metrics for task 4 >> {'accuracy': 0.8435, 'loss': 0.0018340293318033218, 'std': 0.07850000000000001, 'EER': -1}\n",
      "[164] Eval metrics for task 1 >> {'accuracy': 0.4125, 'loss': 0.02118394446372986, 'std': 0.013499999999999984, 'EER': -1}\n",
      "[164] Eval metrics for task 2 >> {'accuracy': 0.133, 'loss': 0.030437739133834837, 'std': 0.025, 'EER': -1}\n",
      "[164] Eval metrics for task 3 >> {'accuracy': 0.352, 'loss': 0.013635897636413574, 'std': 0.07899999999999999, 'EER': -1}\n",
      "[164] Eval metrics for task 4 >> {'accuracy': 0.877, 'loss': 0.0014409337490797042, 'std': 0.01100000000000001, 'EER': -1}\n",
      "[165] Eval metrics for task 1 >> {'accuracy': 0.396, 'loss': 0.022160983800888063, 'std': 0.14100000000000001, 'EER': -1}\n",
      "[165] Eval metrics for task 2 >> {'accuracy': 0.1195, 'loss': 0.033240394830703734, 'std': 0.003499999999999996, 'EER': -1}\n",
      "[165] Eval metrics for task 3 >> {'accuracy': 0.3525, 'loss': 0.014102132558822632, 'std': 0.0645, 'EER': -1}\n",
      "[165] Eval metrics for task 4 >> {'accuracy': 0.8734999999999999, 'loss': 0.001410474196076393, 'std': 0.028500000000000025, 'EER': -1}\n",
      "[166] Eval metrics for task 1 >> {'accuracy': 0.366, 'loss': 0.021913593530654907, 'std': 0.128, 'EER': -1}\n",
      "[166] Eval metrics for task 2 >> {'accuracy': 0.14250000000000002, 'loss': 0.03013649845123291, 'std': 0.008499999999999994, 'EER': -1}\n",
      "[166] Eval metrics for task 3 >> {'accuracy': 0.36450000000000005, 'loss': 0.013067432522773743, 'std': 0.08449999999999999, 'EER': -1}\n",
      "[166] Eval metrics for task 4 >> {'accuracy': 0.881, 'loss': 0.0014138163924217223, 'std': 0.026000000000000023, 'EER': -1}\n",
      "[167] Eval metrics for task 1 >> {'accuracy': 0.3085, 'loss': 0.02734074854850769, 'std': 0.1285, 'EER': -1}\n",
      "[167] Eval metrics for task 2 >> {'accuracy': 0.111, 'loss': 0.033816033124923706, 'std': 0.0, 'EER': -1}\n",
      "[167] Eval metrics for task 3 >> {'accuracy': 0.324, 'loss': 0.015260091543197633, 'std': 0.07700000000000001, 'EER': -1}\n",
      "[167] Eval metrics for task 4 >> {'accuracy': 0.8500000000000001, 'loss': 0.0018028152883052826, 'std': 0.07800000000000001, 'EER': -1}\n",
      "[168] Eval metrics for task 1 >> {'accuracy': 0.331, 'loss': 0.025443528413772582, 'std': 0.105, 'EER': -1}\n",
      "[168] Eval metrics for task 2 >> {'accuracy': 0.186, 'loss': 0.028222864627838136, 'std': 0.01100000000000001, 'EER': -1}\n",
      "[168] Eval metrics for task 3 >> {'accuracy': 0.28400000000000003, 'loss': 0.016859837532043457, 'std': 0.054000000000000006, 'EER': -1}\n",
      "[168] Eval metrics for task 4 >> {'accuracy': 0.8855, 'loss': 0.001339566245675087, 'std': 0.0015000000000000013, 'EER': -1}\n",
      "[169] Eval metrics for task 1 >> {'accuracy': 0.3305, 'loss': 0.025191401720046996, 'std': 0.0905, 'EER': -1}\n",
      "[169] Eval metrics for task 2 >> {'accuracy': 0.0955, 'loss': 0.033346606969833374, 'std': 0.012499999999999997, 'EER': -1}\n",
      "[169] Eval metrics for task 3 >> {'accuracy': 0.28, 'loss': 0.016106558799743653, 'std': 0.04500000000000001, 'EER': -1}\n",
      "[169] Eval metrics for task 4 >> {'accuracy': 0.9115, 'loss': 0.0010839658081531526, 'std': 0.03149999999999997, 'EER': -1}\n",
      "[170] Eval metrics for task 1 >> {'accuracy': 0.3885, 'loss': 0.022544384241104127, 'std': 0.016500000000000015, 'EER': -1}\n",
      "[170] Eval metrics for task 2 >> {'accuracy': 0.1185, 'loss': 0.03383001065254211, 'std': 0.023499999999999993, 'EER': -1}\n",
      "[170] Eval metrics for task 3 >> {'accuracy': 0.257, 'loss': 0.01698225653171539, 'std': 0.045, 'EER': -1}\n",
      "[170] Eval metrics for task 4 >> {'accuracy': 0.879, 'loss': 0.0015095852017402648, 'std': 0.05400000000000005, 'EER': -1}\n",
      "[171] Eval metrics for task 1 >> {'accuracy': 0.32, 'loss': 0.0237052001953125, 'std': 0.08000000000000002, 'EER': -1}\n",
      "[171] Eval metrics for task 2 >> {'accuracy': 0.16799999999999998, 'loss': 0.028365633964538575, 'std': 0.008999999999999994, 'EER': -1}\n",
      "[171] Eval metrics for task 3 >> {'accuracy': 0.34299999999999997, 'loss': 0.01465517008304596, 'std': 0.094, 'EER': -1}\n",
      "[171] Eval metrics for task 4 >> {'accuracy': 0.8674999999999999, 'loss': 0.0015637247413396835, 'std': 0.004500000000000004, 'EER': -1}\n",
      "[172] Eval metrics for task 1 >> {'accuracy': 0.4135, 'loss': 0.021310786724090577, 'std': 0.05050000000000002, 'EER': -1}\n",
      "[172] Eval metrics for task 2 >> {'accuracy': 0.1545, 'loss': 0.030494104623794555, 'std': 0.01050000000000001, 'EER': -1}\n",
      "[172] Eval metrics for task 3 >> {'accuracy': 0.3615, 'loss': 0.014530930399894714, 'std': 0.07950000000000002, 'EER': -1}\n",
      "[172] Eval metrics for task 4 >> {'accuracy': 0.8775, 'loss': 0.0013933330327272416, 'std': 0.03250000000000003, 'EER': -1}\n",
      "[173] Eval metrics for task 1 >> {'accuracy': 0.436, 'loss': 0.020381820678710937, 'std': 0.02300000000000002, 'EER': -1}\n",
      "[173] Eval metrics for task 2 >> {'accuracy': 0.1315, 'loss': 0.03236850786209106, 'std': 0.035500000000000004, 'EER': -1}\n",
      "[173] Eval metrics for task 3 >> {'accuracy': 0.3185, 'loss': 0.01593905484676361, 'std': 0.05349999999999999, 'EER': -1}\n",
      "[173] Eval metrics for task 4 >> {'accuracy': 0.88, 'loss': 0.0013330358266830445, 'std': 0.006000000000000005, 'EER': -1}\n",
      "[174] Eval metrics for task 1 >> {'accuracy': 0.4165, 'loss': 0.021329387187957762, 'std': 0.01949999999999999, 'EER': -1}\n",
      "[174] Eval metrics for task 2 >> {'accuracy': 0.1615, 'loss': 0.030427948474884035, 'std': 0.027499999999999997, 'EER': -1}\n",
      "[174] Eval metrics for task 3 >> {'accuracy': 0.35250000000000004, 'loss': 0.015564551115036011, 'std': 0.07949999999999999, 'EER': -1}\n",
      "[174] Eval metrics for task 4 >> {'accuracy': 0.8625, 'loss': 0.001671159103512764, 'std': 0.0595, 'EER': -1}\n",
      "[175] Eval metrics for task 1 >> {'accuracy': 0.4435, 'loss': 0.020413018941879274, 'std': 0.017500000000000016, 'EER': -1}\n",
      "[175] Eval metrics for task 2 >> {'accuracy': 0.1535, 'loss': 0.030859093189239503, 'std': 0.01150000000000001, 'EER': -1}\n",
      "[175] Eval metrics for task 3 >> {'accuracy': 0.30400000000000005, 'loss': 0.01673852348327637, 'std': 0.025999999999999995, 'EER': -1}\n",
      "[175] Eval metrics for task 4 >> {'accuracy': 0.882, 'loss': 0.0013268817365169525, 'std': 0.008000000000000007, 'EER': -1}\n",
      "[176] Eval metrics for task 1 >> {'accuracy': 0.332, 'loss': 0.030210034608840943, 'std': 0.069, 'EER': -1}\n",
      "[176] Eval metrics for task 2 >> {'accuracy': 0.1855, 'loss': 0.02919479990005493, 'std': 0.0015000000000000013, 'EER': -1}\n",
      "[176] Eval metrics for task 3 >> {'accuracy': 0.309, 'loss': 0.016012791991233826, 'std': 0.01200000000000001, 'EER': -1}\n",
      "[176] Eval metrics for task 4 >> {'accuracy': 0.845, 'loss': 0.0017542101293802261, 'std': 0.03200000000000003, 'EER': -1}\n",
      "[177] Eval metrics for task 1 >> {'accuracy': 0.35450000000000004, 'loss': 0.025256738424301147, 'std': 0.08549999999999999, 'EER': -1}\n",
      "[177] Eval metrics for task 2 >> {'accuracy': 0.184, 'loss': 0.024409643173217775, 'std': 0.066, 'EER': -1}\n",
      "[177] Eval metrics for task 3 >> {'accuracy': 0.3625, 'loss': 0.013340118885040284, 'std': 0.1215, 'EER': -1}\n",
      "[177] Eval metrics for task 4 >> {'accuracy': 0.8454999999999999, 'loss': 0.0017783669084310532, 'std': 0.003500000000000003, 'EER': -1}\n",
      "[178] Eval metrics for task 1 >> {'accuracy': 0.379, 'loss': 0.024204558372497558, 'std': 0.14600000000000002, 'EER': -1}\n",
      "[178] Eval metrics for task 2 >> {'accuracy': 0.15000000000000002, 'loss': 0.028284090995788574, 'std': 0.012999999999999998, 'EER': -1}\n",
      "[178] Eval metrics for task 3 >> {'accuracy': 0.266, 'loss': 0.015866421937942504, 'std': 0.03399999999999999, 'EER': -1}\n",
      "[178] Eval metrics for task 4 >> {'accuracy': 0.894, 'loss': 0.0013405710607767105, 'std': 0.01200000000000001, 'EER': -1}\n",
      "[179] Eval metrics for task 1 >> {'accuracy': 0.403, 'loss': 0.022766315460205078, 'std': 0.1, 'EER': -1}\n",
      "[179] Eval metrics for task 2 >> {'accuracy': 0.154, 'loss': 0.029225388050079345, 'std': 0.027999999999999997, 'EER': -1}\n",
      "[179] Eval metrics for task 3 >> {'accuracy': 0.39, 'loss': 0.013586503982543945, 'std': 0.07, 'EER': -1}\n",
      "[179] Eval metrics for task 4 >> {'accuracy': 0.848, 'loss': 0.0017356064766645431, 'std': 0.010000000000000009, 'EER': -1}\n",
      "[180] Eval metrics for task 1 >> {'accuracy': 0.4305, 'loss': 0.020924198150634767, 'std': 0.07050000000000001, 'EER': -1}\n",
      "[180] Eval metrics for task 2 >> {'accuracy': 0.1525, 'loss': 0.028773544549942017, 'std': 0.0405, 'EER': -1}\n",
      "[180] Eval metrics for task 3 >> {'accuracy': 0.3575, 'loss': 0.014169504404067994, 'std': 0.05049999999999999, 'EER': -1}\n",
      "[180] Eval metrics for task 4 >> {'accuracy': 0.85, 'loss': 0.0016805736720561981, 'std': 0.018000000000000016, 'EER': -1}\n",
      "[181] Eval metrics for task 1 >> {'accuracy': 0.41200000000000003, 'loss': 0.021242044687271117, 'std': 0.08099999999999999, 'EER': -1}\n",
      "[181] Eval metrics for task 2 >> {'accuracy': 0.14049999999999999, 'loss': 0.02900331950187683, 'std': 0.0355, 'EER': -1}\n",
      "[181] Eval metrics for task 3 >> {'accuracy': 0.344, 'loss': 0.014013416528701783, 'std': 0.037000000000000005, 'EER': -1}\n",
      "[181] Eval metrics for task 4 >> {'accuracy': 0.8694999999999999, 'loss': 0.0014914711713790894, 'std': 0.006500000000000006, 'EER': -1}\n",
      "[182] Eval metrics for task 1 >> {'accuracy': 0.4395, 'loss': 0.019804980993270875, 'std': 0.08550000000000002, 'EER': -1}\n",
      "[182] Eval metrics for task 2 >> {'accuracy': 0.1605, 'loss': 0.028260339975357054, 'std': 0.04349999999999999, 'EER': -1}\n",
      "[182] Eval metrics for task 3 >> {'accuracy': 0.3785, 'loss': 0.013398743510246277, 'std': 0.058499999999999996, 'EER': -1}\n",
      "[182] Eval metrics for task 4 >> {'accuracy': 0.8465, 'loss': 0.0017776605486869812, 'std': 0.013500000000000012, 'EER': -1}\n",
      "[183] Eval metrics for task 1 >> {'accuracy': 0.41700000000000004, 'loss': 0.021059292793273926, 'std': 0.08299999999999999, 'EER': -1}\n",
      "[183] Eval metrics for task 2 >> {'accuracy': 0.152, 'loss': 0.02875847625732422, 'std': 0.044000000000000004, 'EER': -1}\n",
      "[183] Eval metrics for task 3 >> {'accuracy': 0.35450000000000004, 'loss': 0.01387886643409729, 'std': 0.04550000000000001, 'EER': -1}\n",
      "[183] Eval metrics for task 4 >> {'accuracy': 0.863, 'loss': 0.001563683584332466, 'std': 0.0030000000000000027, 'EER': -1}\n",
      "[184] Eval metrics for task 1 >> {'accuracy': 0.4235, 'loss': 0.02088558006286621, 'std': 0.07950000000000002, 'EER': -1}\n",
      "[184] Eval metrics for task 2 >> {'accuracy': 0.151, 'loss': 0.028554664134979247, 'std': 0.039, 'EER': -1}\n",
      "[184] Eval metrics for task 3 >> {'accuracy': 0.357, 'loss': 0.013879740357398987, 'std': 0.04100000000000001, 'EER': -1}\n",
      "[184] Eval metrics for task 4 >> {'accuracy': 0.8514999999999999, 'loss': 0.0016795082986354828, 'std': 0.020500000000000018, 'EER': -1}\n",
      "[185] Eval metrics for task 1 >> {'accuracy': 0.41300000000000003, 'loss': 0.021883796691894532, 'std': 0.092, 'EER': -1}\n",
      "[185] Eval metrics for task 2 >> {'accuracy': 0.1435, 'loss': 0.02986112403869629, 'std': 0.0415, 'EER': -1}\n",
      "[185] Eval metrics for task 3 >> {'accuracy': 0.3395, 'loss': 0.014414770364761352, 'std': 0.04050000000000001, 'EER': -1}\n",
      "[185] Eval metrics for task 4 >> {'accuracy': 0.8694999999999999, 'loss': 0.001482902020215988, 'std': 0.0015000000000000013, 'EER': -1}\n",
      "[186] Eval metrics for task 1 >> {'accuracy': 0.4275, 'loss': 0.021133315563201905, 'std': 0.0865, 'EER': -1}\n",
      "[186] Eval metrics for task 2 >> {'accuracy': 0.1505, 'loss': 0.0293054575920105, 'std': 0.04750000000000001, 'EER': -1}\n",
      "[186] Eval metrics for task 3 >> {'accuracy': 0.35450000000000004, 'loss': 0.014048175692558288, 'std': 0.05050000000000002, 'EER': -1}\n",
      "[186] Eval metrics for task 4 >> {'accuracy': 0.8614999999999999, 'loss': 0.0015802222639322281, 'std': 0.007500000000000007, 'EER': -1}\n",
      "[187] Eval metrics for task 1 >> {'accuracy': 0.4285, 'loss': 0.020559282302856446, 'std': 0.0685, 'EER': -1}\n",
      "[187] Eval metrics for task 2 >> {'accuracy': 0.1545, 'loss': 0.02848608684539795, 'std': 0.0415, 'EER': -1}\n",
      "[187] Eval metrics for task 3 >> {'accuracy': 0.35750000000000004, 'loss': 0.01387501859664917, 'std': 0.04450000000000001, 'EER': -1}\n",
      "[187] Eval metrics for task 4 >> {'accuracy': 0.85, 'loss': 0.001690999612212181, 'std': 0.016000000000000014, 'EER': -1}\n",
      "[188] Eval metrics for task 1 >> {'accuracy': 0.41700000000000004, 'loss': 0.02083983850479126, 'std': 0.08299999999999999, 'EER': -1}\n",
      "[188] Eval metrics for task 2 >> {'accuracy': 0.1465, 'loss': 0.028813095569610595, 'std': 0.043500000000000004, 'EER': -1}\n",
      "[188] Eval metrics for task 3 >> {'accuracy': 0.347, 'loss': 0.013996849298477172, 'std': 0.034, 'EER': -1}\n",
      "[188] Eval metrics for task 4 >> {'accuracy': 0.8574999999999999, 'loss': 0.0015619862675666809, 'std': 0.02350000000000002, 'EER': -1}\n",
      "[189] Eval metrics for task 1 >> {'accuracy': 0.4235, 'loss': 0.020744266033172608, 'std': 0.07950000000000002, 'EER': -1}\n",
      "[189] Eval metrics for task 2 >> {'accuracy': 0.1505, 'loss': 0.028761495590209962, 'std': 0.046500000000000014, 'EER': -1}\n",
      "[189] Eval metrics for task 3 >> {'accuracy': 0.355, 'loss': 0.013891127347946166, 'std': 0.04300000000000001, 'EER': -1}\n",
      "[189] Eval metrics for task 4 >> {'accuracy': 0.86, 'loss': 0.00160860775411129, 'std': 0.008000000000000007, 'EER': -1}\n",
      "[190] Eval metrics for task 1 >> {'accuracy': 0.438, 'loss': 0.019930439233779906, 'std': 0.08000000000000002, 'EER': -1}\n",
      "[190] Eval metrics for task 2 >> {'accuracy': 0.161, 'loss': 0.028446357488632203, 'std': 0.04000000000000001, 'EER': -1}\n",
      "[190] Eval metrics for task 3 >> {'accuracy': 0.38, 'loss': 0.013476271748542785, 'std': 0.07100000000000001, 'EER': -1}\n",
      "[190] Eval metrics for task 4 >> {'accuracy': 0.8414999999999999, 'loss': 0.0018238705843687058, 'std': 0.014500000000000013, 'EER': -1}\n",
      "[191] Eval metrics for task 1 >> {'accuracy': 0.4115, 'loss': 0.021553872585296632, 'std': 0.08449999999999999, 'EER': -1}\n",
      "[191] Eval metrics for task 2 >> {'accuracy': 0.14, 'loss': 0.02970350170135498, 'std': 0.048, 'EER': -1}\n",
      "[191] Eval metrics for task 3 >> {'accuracy': 0.3365, 'loss': 0.01422332763671875, 'std': 0.028499999999999998, 'EER': -1}\n",
      "[191] Eval metrics for task 4 >> {'accuracy': 0.874, 'loss': 0.0014744504392147065, 'std': 0.0010000000000000009, 'EER': -1}\n",
      "[192] Eval metrics for task 1 >> {'accuracy': 0.42200000000000004, 'loss': 0.02106851053237915, 'std': 0.08399999999999999, 'EER': -1}\n",
      "[192] Eval metrics for task 2 >> {'accuracy': 0.1505, 'loss': 0.02920082640647888, 'std': 0.04750000000000001, 'EER': -1}\n",
      "[192] Eval metrics for task 3 >> {'accuracy': 0.352, 'loss': 0.014015833735466004, 'std': 0.048000000000000015, 'EER': -1}\n",
      "[192] Eval metrics for task 4 >> {'accuracy': 0.863, 'loss': 0.0015789792090654374, 'std': 0.01100000000000001, 'EER': -1}\n",
      "[193] Eval metrics for task 1 >> {'accuracy': 0.45, 'loss': 0.019966290712356567, 'std': 0.066, 'EER': -1}\n",
      "[193] Eval metrics for task 2 >> {'accuracy': 0.17099999999999999, 'loss': 0.02816713833808899, 'std': 0.03399999999999999, 'EER': -1}\n",
      "[193] Eval metrics for task 3 >> {'accuracy': 0.3845, 'loss': 0.013642005681991577, 'std': 0.0695, 'EER': -1}\n",
      "[193] Eval metrics for task 4 >> {'accuracy': 0.823, 'loss': 0.0020235335528850555, 'std': 0.021999999999999964, 'EER': -1}\n",
      "[194] Eval metrics for task 1 >> {'accuracy': 0.4285, 'loss': 0.02039609956741333, 'std': 0.08250000000000002, 'EER': -1}\n",
      "[194] Eval metrics for task 2 >> {'accuracy': 0.151, 'loss': 0.028687348365783693, 'std': 0.042, 'EER': -1}\n",
      "[194] Eval metrics for task 3 >> {'accuracy': 0.352, 'loss': 0.01399486255645752, 'std': 0.04500000000000001, 'EER': -1}\n",
      "[194] Eval metrics for task 4 >> {'accuracy': 0.86, 'loss': 0.0015923843681812286, 'std': 0.01100000000000001, 'EER': -1}\n",
      "[195] Eval metrics for task 1 >> {'accuracy': 0.4275, 'loss': 0.02046361207962036, 'std': 0.0625, 'EER': -1}\n",
      "[195] Eval metrics for task 2 >> {'accuracy': 0.1635, 'loss': 0.028213897943496703, 'std': 0.03950000000000001, 'EER': -1}\n",
      "[195] Eval metrics for task 3 >> {'accuracy': 0.3625, 'loss': 0.013917051434516907, 'std': 0.045499999999999985, 'EER': -1}\n",
      "[195] Eval metrics for task 4 >> {'accuracy': 0.849, 'loss': 0.0017253443151712417, 'std': 0.018000000000000016, 'EER': -1}\n",
      "[196] Eval metrics for task 1 >> {'accuracy': 0.4215, 'loss': 0.021096760988235475, 'std': 0.0685, 'EER': -1}\n",
      "[196] Eval metrics for task 2 >> {'accuracy': 0.151, 'loss': 0.02857743549346924, 'std': 0.038, 'EER': -1}\n",
      "[196] Eval metrics for task 3 >> {'accuracy': 0.3435, 'loss': 0.014399561643600465, 'std': 0.04050000000000001, 'EER': -1}\n",
      "[196] Eval metrics for task 4 >> {'accuracy': 0.856, 'loss': 0.0016377364248037337, 'std': 0.02400000000000002, 'EER': -1}\n",
      "[197] Eval metrics for task 1 >> {'accuracy': 0.4305, 'loss': 0.02068948745727539, 'std': 0.07350000000000001, 'EER': -1}\n",
      "[197] Eval metrics for task 2 >> {'accuracy': 0.16699999999999998, 'loss': 0.02797614932060242, 'std': 0.047, 'EER': -1}\n",
      "[197] Eval metrics for task 3 >> {'accuracy': 0.374, 'loss': 0.01353201961517334, 'std': 0.04799999999999999, 'EER': -1}\n",
      "[197] Eval metrics for task 4 >> {'accuracy': 0.8374999999999999, 'loss': 0.0018533520102500915, 'std': 0.02350000000000002, 'EER': -1}\n",
      "[198] Eval metrics for task 1 >> {'accuracy': 0.438, 'loss': 0.020609917163848877, 'std': 0.07900000000000001, 'EER': -1}\n",
      "[198] Eval metrics for task 2 >> {'accuracy': 0.1575, 'loss': 0.028804483652114868, 'std': 0.0325, 'EER': -1}\n",
      "[198] Eval metrics for task 3 >> {'accuracy': 0.38, 'loss': 0.01342986798286438, 'std': 0.033, 'EER': -1}\n",
      "[198] Eval metrics for task 4 >> {'accuracy': 0.8434999999999999, 'loss': 0.001818856343626976, 'std': 0.004500000000000004, 'EER': -1}\n",
      "[199] Eval metrics for task 1 >> {'accuracy': 0.4275, 'loss': 0.021693052530288696, 'std': 0.08350000000000002, 'EER': -1}\n",
      "[199] Eval metrics for task 2 >> {'accuracy': 0.156, 'loss': 0.029185458183288573, 'std': 0.04, 'EER': -1}\n",
      "[199] Eval metrics for task 3 >> {'accuracy': 0.3645, 'loss': 0.01397744917869568, 'std': 0.055499999999999994, 'EER': -1}\n",
      "[199] Eval metrics for task 4 >> {'accuracy': 0.8554999999999999, 'loss': 0.0016815832555294038, 'std': 0.009500000000000008, 'EER': -1}\n",
      "[200] Eval metrics for task 1 >> {'accuracy': 0.4125, 'loss': 0.021405172824859618, 'std': 0.08549999999999999, 'EER': -1}\n",
      "[200] Eval metrics for task 2 >> {'accuracy': 0.14250000000000002, 'loss': 0.029076005220413207, 'std': 0.0435, 'EER': -1}\n",
      "[200] Eval metrics for task 3 >> {'accuracy': 0.3335, 'loss': 0.014287574887275696, 'std': 0.0305, 'EER': -1}\n",
      "[200] Eval metrics for task 4 >> {'accuracy': 0.8705, 'loss': 0.0014490197375416755, 'std': 0.014500000000000013, 'EER': -1}\n",
      "training_task_end\n",
      "---------------------------- Task 5 -----------------------\n",
      "[201] Eval metrics for task 1 >> {'accuracy': 0.326, 'loss': 0.014710474610328674, 'std': 0.09299999999999999, 'EER': -1}\n",
      "[201] Eval metrics for task 2 >> {'accuracy': 0.117, 'loss': 0.019541429042816163, 'std': 0.051000000000000004, 'EER': -1}\n",
      "[201] Eval metrics for task 3 >> {'accuracy': 0.2225, 'loss': 0.01282101845741272, 'std': 0.10550000000000001, 'EER': -1}\n",
      "[201] Eval metrics for task 4 >> {'accuracy': 0.669, 'loss': 0.004904455423355102, 'std': 0.0030000000000000027, 'EER': -1}\n",
      "[201] Eval metrics for task 5 >> {'accuracy': 0.6265000000000001, 'loss': 0.003988915920257568, 'std': 0.02150000000000002, 'EER': -1}\n",
      "[202] Eval metrics for task 1 >> {'accuracy': 0.1865, 'loss': 0.024062488079071045, 'std': 0.04450000000000001, 'EER': -1}\n",
      "[202] Eval metrics for task 2 >> {'accuracy': 0.088, 'loss': 0.02686170434951782, 'std': 0.005999999999999998, 'EER': -1}\n",
      "[202] Eval metrics for task 3 >> {'accuracy': 0.20600000000000002, 'loss': 0.019869303464889528, 'std': 0.07, 'EER': -1}\n",
      "[202] Eval metrics for task 4 >> {'accuracy': 0.51, 'loss': 0.007810723721981048, 'std': 0.039000000000000035, 'EER': -1}\n",
      "[202] Eval metrics for task 5 >> {'accuracy': 0.7765, 'loss': 0.0027256794869899748, 'std': 0.09449999999999997, 'EER': -1}\n",
      "[203] Eval metrics for task 1 >> {'accuracy': 0.228, 'loss': 0.020356624841690065, 'std': 0.04400000000000001, 'EER': -1}\n",
      "[203] Eval metrics for task 2 >> {'accuracy': 0.1075, 'loss': 0.02563641095161438, 'std': 0.08349999999999999, 'EER': -1}\n",
      "[203] Eval metrics for task 3 >> {'accuracy': 0.2185, 'loss': 0.01758611607551575, 'std': 0.009500000000000008, 'EER': -1}\n",
      "[203] Eval metrics for task 4 >> {'accuracy': 0.471, 'loss': 0.008907071948051452, 'std': 0.17200000000000001, 'EER': -1}\n",
      "[203] Eval metrics for task 5 >> {'accuracy': 0.8075, 'loss': 0.002287627726793289, 'std': 0.09150000000000003, 'EER': -1}\n",
      "[204] Eval metrics for task 1 >> {'accuracy': 0.1525, 'loss': 0.024196852445602417, 'std': 0.028499999999999998, 'EER': -1}\n",
      "[204] Eval metrics for task 2 >> {'accuracy': 0.091, 'loss': 0.026853244304656982, 'std': 0.022, 'EER': -1}\n",
      "[204] Eval metrics for task 3 >> {'accuracy': 0.2005, 'loss': 0.018185568571090698, 'std': 0.0015000000000000013, 'EER': -1}\n",
      "[204] Eval metrics for task 4 >> {'accuracy': 0.46699999999999997, 'loss': 0.008893977999687195, 'std': 0.035, 'EER': -1}\n",
      "[204] Eval metrics for task 5 >> {'accuracy': 0.888, 'loss': 0.0013116523921489715, 'std': 0.0020000000000000018, 'EER': -1}\n",
      "[205] Eval metrics for task 1 >> {'accuracy': 0.13849999999999998, 'loss': 0.02438757133483887, 'std': 0.0655, 'EER': -1}\n",
      "[205] Eval metrics for task 2 >> {'accuracy': 0.11499999999999999, 'loss': 0.025873936176300048, 'std': 0.042, 'EER': -1}\n",
      "[205] Eval metrics for task 3 >> {'accuracy': 0.207, 'loss': 0.018712865114212038, 'std': 0.07899999999999999, 'EER': -1}\n",
      "[205] Eval metrics for task 4 >> {'accuracy': 0.4375, 'loss': 0.009334602832794189, 'std': 0.044499999999999984, 'EER': -1}\n",
      "[205] Eval metrics for task 5 >> {'accuracy': 0.9119999999999999, 'loss': 0.0011313407346606255, 'std': 0.02999999999999997, 'EER': -1}\n",
      "[206] Eval metrics for task 1 >> {'accuracy': 0.119, 'loss': 0.027485180377960206, 'std': 0.06899999999999999, 'EER': -1}\n",
      "[206] Eval metrics for task 2 >> {'accuracy': 0.056, 'loss': 0.030888214588165284, 'std': 0.037, 'EER': -1}\n",
      "[206] Eval metrics for task 3 >> {'accuracy': 0.1195, 'loss': 0.02177597951889038, 'std': 0.0295, 'EER': -1}\n",
      "[206] Eval metrics for task 4 >> {'accuracy': 0.395, 'loss': 0.010029823780059814, 'std': 0.0030000000000000027, 'EER': -1}\n",
      "[206] Eval metrics for task 5 >> {'accuracy': 0.923, 'loss': 0.0008365524932742119, 'std': 0.014999999999999958, 'EER': -1}\n",
      "[207] Eval metrics for task 1 >> {'accuracy': 0.259, 'loss': 0.020912391424179076, 'std': 0.05, 'EER': -1}\n",
      "[207] Eval metrics for task 2 >> {'accuracy': 0.107, 'loss': 0.027283112287521363, 'std': 0.048, 'EER': -1}\n",
      "[207] Eval metrics for task 3 >> {'accuracy': 0.263, 'loss': 0.018391430616378785, 'std': 0.115, 'EER': -1}\n",
      "[207] Eval metrics for task 4 >> {'accuracy': 0.436, 'loss': 0.009465269565582276, 'std': 0.08600000000000002, 'EER': -1}\n",
      "[207] Eval metrics for task 5 >> {'accuracy': 0.8734999999999999, 'loss': 0.0016257149279117584, 'std': 0.04850000000000004, 'EER': -1}\n",
      "[208] Eval metrics for task 1 >> {'accuracy': 0.1795, 'loss': 0.026810624122619628, 'std': 0.0595, 'EER': -1}\n",
      "[208] Eval metrics for task 2 >> {'accuracy': 0.0905, 'loss': 0.027371362209320068, 'std': 0.056499999999999995, 'EER': -1}\n",
      "[208] Eval metrics for task 3 >> {'accuracy': 0.2015, 'loss': 0.018934789180755616, 'std': 0.05750000000000001, 'EER': -1}\n",
      "[208] Eval metrics for task 4 >> {'accuracy': 0.40900000000000003, 'loss': 0.010219974517822266, 'std': 0.013999999999999985, 'EER': -1}\n",
      "[208] Eval metrics for task 5 >> {'accuracy': 0.8855, 'loss': 0.0016239891648292541, 'std': 0.019500000000000017, 'EER': -1}\n",
      "[209] Eval metrics for task 1 >> {'accuracy': 0.113, 'loss': 0.02644063138961792, 'std': 0.05, 'EER': -1}\n",
      "[209] Eval metrics for task 2 >> {'accuracy': 0.03, 'loss': 0.030310002088546752, 'std': 0.022, 'EER': -1}\n",
      "[209] Eval metrics for task 3 >> {'accuracy': 0.175, 'loss': 0.018407471418380738, 'std': 0.010999999999999996, 'EER': -1}\n",
      "[209] Eval metrics for task 4 >> {'accuracy': 0.3695, 'loss': 0.010292696118354797, 'std': 0.045499999999999985, 'EER': -1}\n",
      "[209] Eval metrics for task 5 >> {'accuracy': 0.9275, 'loss': 0.0009007237702608108, 'std': 0.005500000000000005, 'EER': -1}\n",
      "[210] Eval metrics for task 1 >> {'accuracy': 0.1565, 'loss': 0.026332441091537477, 'std': 0.0665, 'EER': -1}\n",
      "[210] Eval metrics for task 2 >> {'accuracy': 0.10250000000000001, 'loss': 0.027962882995605468, 'std': 0.08549999999999999, 'EER': -1}\n",
      "[210] Eval metrics for task 3 >> {'accuracy': 0.218, 'loss': 0.019837580919265747, 'std': 0.11, 'EER': -1}\n",
      "[210] Eval metrics for task 4 >> {'accuracy': 0.444, 'loss': 0.009928911805152893, 'std': 0.0020000000000000018, 'EER': -1}\n",
      "[210] Eval metrics for task 5 >> {'accuracy': 0.902, 'loss': 0.0012150907218456267, 'std': 0.009000000000000008, 'EER': -1}\n",
      "[211] Eval metrics for task 1 >> {'accuracy': 0.1975, 'loss': 0.024386409282684325, 'std': 0.1135, 'EER': -1}\n",
      "[211] Eval metrics for task 2 >> {'accuracy': 0.068, 'loss': 0.030942384481430055, 'std': 0.054, 'EER': -1}\n",
      "[211] Eval metrics for task 3 >> {'accuracy': 0.16899999999999998, 'loss': 0.021183948755264283, 'std': 0.082, 'EER': -1}\n",
      "[211] Eval metrics for task 4 >> {'accuracy': 0.433, 'loss': 0.009789072513580322, 'std': 0.061, 'EER': -1}\n",
      "[211] Eval metrics for task 5 >> {'accuracy': 0.921, 'loss': 0.0009882544055581093, 'std': 0.008000000000000007, 'EER': -1}\n",
      "[212] Eval metrics for task 1 >> {'accuracy': 0.148, 'loss': 0.029955668210983277, 'std': 0.09, 'EER': -1}\n",
      "[212] Eval metrics for task 2 >> {'accuracy': 0.089, 'loss': 0.02936654019355774, 'std': 0.020999999999999998, 'EER': -1}\n",
      "[212] Eval metrics for task 3 >> {'accuracy': 0.2365, 'loss': 0.019369188070297243, 'std': 0.024500000000000008, 'EER': -1}\n",
      "[212] Eval metrics for task 4 >> {'accuracy': 0.4375, 'loss': 0.010321310400962829, 'std': 0.12450000000000003, 'EER': -1}\n",
      "[212] Eval metrics for task 5 >> {'accuracy': 0.911, 'loss': 0.0010545984655618667, 'std': 0.02799999999999997, 'EER': -1}\n",
      "[213] Eval metrics for task 1 >> {'accuracy': 0.198, 'loss': 0.02524577021598816, 'std': 0.006999999999999992, 'EER': -1}\n",
      "[213] Eval metrics for task 2 >> {'accuracy': 0.1455, 'loss': 0.029926177740097044, 'std': 0.0365, 'EER': -1}\n",
      "[213] Eval metrics for task 3 >> {'accuracy': 0.176, 'loss': 0.024299795150756837, 'std': 0.07300000000000001, 'EER': -1}\n",
      "[213] Eval metrics for task 4 >> {'accuracy': 0.501, 'loss': 0.010012284159660339, 'std': 0.087, 'EER': -1}\n",
      "[213] Eval metrics for task 5 >> {'accuracy': 0.859, 'loss': 0.0017829964607954025, 'std': 0.0020000000000000018, 'EER': -1}\n",
      "[214] Eval metrics for task 1 >> {'accuracy': 0.1295, 'loss': 0.026564658880233766, 'std': 0.0645, 'EER': -1}\n",
      "[214] Eval metrics for task 2 >> {'accuracy': 0.10650000000000001, 'loss': 0.02846493148803711, 'std': 0.060500000000000005, 'EER': -1}\n",
      "[214] Eval metrics for task 3 >> {'accuracy': 0.2455, 'loss': 0.01860423517227173, 'std': 0.0625, 'EER': -1}\n",
      "[214] Eval metrics for task 4 >> {'accuracy': 0.433, 'loss': 0.009742528557777404, 'std': 0.025000000000000022, 'EER': -1}\n",
      "[214] Eval metrics for task 5 >> {'accuracy': 0.9395, 'loss': 0.0008013259395956993, 'std': 0.0034999999999999476, 'EER': -1}\n",
      "[215] Eval metrics for task 1 >> {'accuracy': 0.1535, 'loss': 0.028772159337997438, 'std': 0.0675, 'EER': -1}\n",
      "[215] Eval metrics for task 2 >> {'accuracy': 0.111, 'loss': 0.029787070989608765, 'std': 0.011999999999999997, 'EER': -1}\n",
      "[215] Eval metrics for task 3 >> {'accuracy': 0.238, 'loss': 0.021009297132492066, 'std': 0.126, 'EER': -1}\n",
      "[215] Eval metrics for task 4 >> {'accuracy': 0.45399999999999996, 'loss': 0.010453468203544617, 'std': 0.034, 'EER': -1}\n",
      "[215] Eval metrics for task 5 >> {'accuracy': 0.92, 'loss': 0.000994500882923603, 'std': 0.007000000000000006, 'EER': -1}\n",
      "[216] Eval metrics for task 1 >> {'accuracy': 0.205, 'loss': 0.023072907924652098, 'std': 0.092, 'EER': -1}\n",
      "[216] Eval metrics for task 2 >> {'accuracy': 0.1335, 'loss': 0.027802735328674315, 'std': 0.0815, 'EER': -1}\n",
      "[216] Eval metrics for task 3 >> {'accuracy': 0.257, 'loss': 0.019262316942214967, 'std': 0.027999999999999983, 'EER': -1}\n",
      "[216] Eval metrics for task 4 >> {'accuracy': 0.52, 'loss': 0.00861944204568863, 'std': 0.045999999999999985, 'EER': -1}\n",
      "[216] Eval metrics for task 5 >> {'accuracy': 0.8674999999999999, 'loss': 0.0015042223036289214, 'std': 0.013500000000000012, 'EER': -1}\n",
      "[217] Eval metrics for task 1 >> {'accuracy': 0.1965, 'loss': 0.02299871873855591, 'std': 0.07550000000000001, 'EER': -1}\n",
      "[217] Eval metrics for task 2 >> {'accuracy': 0.1145, 'loss': 0.024732836961746215, 'std': 0.0175, 'EER': -1}\n",
      "[217] Eval metrics for task 3 >> {'accuracy': 0.195, 'loss': 0.0186419894695282, 'std': 0.066, 'EER': -1}\n",
      "[217] Eval metrics for task 4 >> {'accuracy': 0.43, 'loss': 0.009785301685333252, 'std': 0.013000000000000012, 'EER': -1}\n",
      "[217] Eval metrics for task 5 >> {'accuracy': 0.898, 'loss': 0.0011358440369367599, 'std': 0.015000000000000013, 'EER': -1}\n",
      "[218] Eval metrics for task 1 >> {'accuracy': 0.175, 'loss': 0.023870869398117067, 'std': 0.047, 'EER': -1}\n",
      "[218] Eval metrics for task 2 >> {'accuracy': 0.099, 'loss': 0.028983882188796998, 'std': 0.015, 'EER': -1}\n",
      "[218] Eval metrics for task 3 >> {'accuracy': 0.2365, 'loss': 0.018684844255447388, 'std': 0.0825, 'EER': -1}\n",
      "[218] Eval metrics for task 4 >> {'accuracy': 0.48950000000000005, 'loss': 0.009198992013931274, 'std': 0.04350000000000001, 'EER': -1}\n",
      "[218] Eval metrics for task 5 >> {'accuracy': 0.9, 'loss': 0.0011556876450777053, 'std': 0.019000000000000017, 'EER': -1}\n",
      "[219] Eval metrics for task 1 >> {'accuracy': 0.149, 'loss': 0.024874797105789184, 'std': 0.055999999999999994, 'EER': -1}\n",
      "[219] Eval metrics for task 2 >> {'accuracy': 0.074, 'loss': 0.028835853815078735, 'std': 0.031999999999999994, 'EER': -1}\n",
      "[219] Eval metrics for task 3 >> {'accuracy': 0.14850000000000002, 'loss': 0.021283566474914552, 'std': 0.052500000000000005, 'EER': -1}\n",
      "[219] Eval metrics for task 4 >> {'accuracy': 0.3825, 'loss': 0.01104276418685913, 'std': 0.1185, 'EER': -1}\n",
      "[219] Eval metrics for task 5 >> {'accuracy': 0.9085000000000001, 'loss': 0.0011274657770991325, 'std': 0.0015000000000000013, 'EER': -1}\n",
      "[220] Eval metrics for task 1 >> {'accuracy': 0.1535, 'loss': 0.028485935211181642, 'std': 0.0895, 'EER': -1}\n",
      "[220] Eval metrics for task 2 >> {'accuracy': 0.0935, 'loss': 0.029373286724090578, 'std': 0.018500000000000003, 'EER': -1}\n",
      "[220] Eval metrics for task 3 >> {'accuracy': 0.2515, 'loss': 0.018999393224716186, 'std': 0.07050000000000001, 'EER': -1}\n",
      "[220] Eval metrics for task 4 >> {'accuracy': 0.4905, 'loss': 0.009660447120666504, 'std': 0.11049999999999999, 'EER': -1}\n",
      "[220] Eval metrics for task 5 >> {'accuracy': 0.9155, 'loss': 0.0010422209352254868, 'std': 0.013500000000000012, 'EER': -1}\n",
      "[221] Eval metrics for task 1 >> {'accuracy': 0.177, 'loss': 0.02239232659339905, 'std': 0.10999999999999999, 'EER': -1}\n",
      "[221] Eval metrics for task 2 >> {'accuracy': 0.1235, 'loss': 0.027288346529006958, 'std': 0.024499999999999994, 'EER': -1}\n",
      "[221] Eval metrics for task 3 >> {'accuracy': 0.182, 'loss': 0.02169808292388916, 'std': 0.10099999999999999, 'EER': -1}\n",
      "[221] Eval metrics for task 4 >> {'accuracy': 0.384, 'loss': 0.010682303547859193, 'std': 0.07500000000000001, 'EER': -1}\n",
      "[221] Eval metrics for task 5 >> {'accuracy': 0.9135, 'loss': 0.0009670273512601853, 'std': 0.009500000000000008, 'EER': -1}\n",
      "[222] Eval metrics for task 1 >> {'accuracy': 0.186, 'loss': 0.02796277904510498, 'std': 0.07500000000000001, 'EER': -1}\n",
      "[222] Eval metrics for task 2 >> {'accuracy': 0.136, 'loss': 0.02903245449066162, 'std': 0.016, 'EER': -1}\n",
      "[222] Eval metrics for task 3 >> {'accuracy': 0.2215, 'loss': 0.021067962884902956, 'std': 0.1005, 'EER': -1}\n",
      "[222] Eval metrics for task 4 >> {'accuracy': 0.392, 'loss': 0.01133959186077118, 'std': 0.1, 'EER': -1}\n",
      "[222] Eval metrics for task 5 >> {'accuracy': 0.891, 'loss': 0.001390521377325058, 'std': 0.06, 'EER': -1}\n",
      "[223] Eval metrics for task 1 >> {'accuracy': 0.198, 'loss': 0.024866026401519775, 'std': 0.139, 'EER': -1}\n",
      "[223] Eval metrics for task 2 >> {'accuracy': 0.11, 'loss': 0.03088372039794922, 'std': 0.0020000000000000018, 'EER': -1}\n",
      "[223] Eval metrics for task 3 >> {'accuracy': 0.261, 'loss': 0.02059986209869385, 'std': 0.088, 'EER': -1}\n",
      "[223] Eval metrics for task 4 >> {'accuracy': 0.374, 'loss': 0.012199337601661682, 'std': 0.15800000000000003, 'EER': -1}\n",
      "[223] Eval metrics for task 5 >> {'accuracy': 0.9085000000000001, 'loss': 0.0012070634365081788, 'std': 0.004500000000000004, 'EER': -1}\n",
      "[224] Eval metrics for task 1 >> {'accuracy': 0.202, 'loss': 0.022983641624450685, 'std': 0.07, 'EER': -1}\n",
      "[224] Eval metrics for task 2 >> {'accuracy': 0.179, 'loss': 0.025430310249328614, 'std': 0.037000000000000005, 'EER': -1}\n",
      "[224] Eval metrics for task 3 >> {'accuracy': 0.27999999999999997, 'loss': 0.01836238646507263, 'std': 0.06599999999999999, 'EER': -1}\n",
      "[224] Eval metrics for task 4 >> {'accuracy': 0.47350000000000003, 'loss': 0.009947347164154052, 'std': 0.05450000000000002, 'EER': -1}\n",
      "[224] Eval metrics for task 5 >> {'accuracy': 0.8895, 'loss': 0.001286230430006981, 'std': 0.01150000000000001, 'EER': -1}\n",
      "[225] Eval metrics for task 1 >> {'accuracy': 0.1535, 'loss': 0.027050068140029908, 'std': 0.06949999999999999, 'EER': -1}\n",
      "[225] Eval metrics for task 2 >> {'accuracy': 0.15, 'loss': 0.02593026351928711, 'std': 0.056999999999999995, 'EER': -1}\n",
      "[225] Eval metrics for task 3 >> {'accuracy': 0.22, 'loss': 0.020235761165618895, 'std': 0.088, 'EER': -1}\n",
      "[225] Eval metrics for task 4 >> {'accuracy': 0.42300000000000004, 'loss': 0.011347756028175353, 'std': 0.024999999999999994, 'EER': -1}\n",
      "[225] Eval metrics for task 5 >> {'accuracy': 0.905, 'loss': 0.0012234469577670098, 'std': 0.016000000000000014, 'EER': -1}\n",
      "[226] Eval metrics for task 1 >> {'accuracy': 0.1535, 'loss': 0.02544628953933716, 'std': 0.0825, 'EER': -1}\n",
      "[226] Eval metrics for task 2 >> {'accuracy': 0.1235, 'loss': 0.025083707332611085, 'std': 0.003500000000000003, 'EER': -1}\n",
      "[226] Eval metrics for task 3 >> {'accuracy': 0.21199999999999997, 'loss': 0.01961612868309021, 'std': 0.071, 'EER': -1}\n",
      "[226] Eval metrics for task 4 >> {'accuracy': 0.37749999999999995, 'loss': 0.011315656781196594, 'std': 0.0915, 'EER': -1}\n",
      "[226] Eval metrics for task 5 >> {'accuracy': 0.9299999999999999, 'loss': 0.0009780968725681305, 'std': 0.02699999999999997, 'EER': -1}\n",
      "[227] Eval metrics for task 1 >> {'accuracy': 0.1905, 'loss': 0.025164827346801758, 'std': 0.0825, 'EER': -1}\n",
      "[227] Eval metrics for task 2 >> {'accuracy': 0.134, 'loss': 0.026952455282211303, 'std': 0.085, 'EER': -1}\n",
      "[227] Eval metrics for task 3 >> {'accuracy': 0.19649999999999998, 'loss': 0.022295723915100096, 'std': 0.0885, 'EER': -1}\n",
      "[227] Eval metrics for task 4 >> {'accuracy': 0.358, 'loss': 0.012994390487670898, 'std': 0.04400000000000001, 'EER': -1}\n",
      "[227] Eval metrics for task 5 >> {'accuracy': 0.9025, 'loss': 0.0014661899209022521, 'std': 0.058499999999999996, 'EER': -1}\n",
      "[228] Eval metrics for task 1 >> {'accuracy': 0.1805, 'loss': 0.025629339456558226, 'std': 0.07750000000000001, 'EER': -1}\n",
      "[228] Eval metrics for task 2 >> {'accuracy': 0.10949999999999999, 'loss': 0.027967416048049927, 'std': 0.06249999999999999, 'EER': -1}\n",
      "[228] Eval metrics for task 3 >> {'accuracy': 0.2225, 'loss': 0.020586071968078615, 'std': 0.1075, 'EER': -1}\n",
      "[228] Eval metrics for task 4 >> {'accuracy': 0.38549999999999995, 'loss': 0.01169504177570343, 'std': 0.023499999999999993, 'EER': -1}\n",
      "[228] Eval metrics for task 5 >> {'accuracy': 0.9305, 'loss': 0.000905275970697403, 'std': 0.01749999999999996, 'EER': -1}\n",
      "[229] Eval metrics for task 1 >> {'accuracy': 0.251, 'loss': 0.025115621089935303, 'std': 0.11, 'EER': -1}\n",
      "[229] Eval metrics for task 2 >> {'accuracy': 0.16149999999999998, 'loss': 0.02751668691635132, 'std': 0.0435, 'EER': -1}\n",
      "[229] Eval metrics for task 3 >> {'accuracy': 0.2645, 'loss': 0.020303839683532714, 'std': 0.11950000000000001, 'EER': -1}\n",
      "[229] Eval metrics for task 4 >> {'accuracy': 0.5175000000000001, 'loss': 0.00971736752986908, 'std': 0.014500000000000013, 'EER': -1}\n",
      "[229] Eval metrics for task 5 >> {'accuracy': 0.896, 'loss': 0.0012397847473621369, 'std': 0.007000000000000006, 'EER': -1}\n",
      "[230] Eval metrics for task 1 >> {'accuracy': 0.207, 'loss': 0.02323719882965088, 'std': 0.086, 'EER': -1}\n",
      "[230] Eval metrics for task 2 >> {'accuracy': 0.1365, 'loss': 0.026530655384063722, 'std': 0.060500000000000005, 'EER': -1}\n",
      "[230] Eval metrics for task 3 >> {'accuracy': 0.2025, 'loss': 0.019698184728622437, 'std': 0.042499999999999996, 'EER': -1}\n",
      "[230] Eval metrics for task 4 >> {'accuracy': 0.441, 'loss': 0.010610753059387208, 'std': 0.016000000000000014, 'EER': -1}\n",
      "[230] Eval metrics for task 5 >> {'accuracy': 0.9185000000000001, 'loss': 0.0010350170731544496, 'std': 0.013500000000000012, 'EER': -1}\n",
      "[231] Eval metrics for task 1 >> {'accuracy': 0.23299999999999998, 'loss': 0.022424847841262818, 'std': 0.09000000000000001, 'EER': -1}\n",
      "[231] Eval metrics for task 2 >> {'accuracy': 0.1515, 'loss': 0.026180371522903444, 'std': 0.0635, 'EER': -1}\n",
      "[231] Eval metrics for task 3 >> {'accuracy': 0.2215, 'loss': 0.019399192094802856, 'std': 0.046500000000000014, 'EER': -1}\n",
      "[231] Eval metrics for task 4 >> {'accuracy': 0.47150000000000003, 'loss': 0.010078209519386292, 'std': 0.02049999999999999, 'EER': -1}\n",
      "[231] Eval metrics for task 5 >> {'accuracy': 0.9105000000000001, 'loss': 0.0011685624942183496, 'std': 0.012500000000000011, 'EER': -1}\n",
      "[232] Eval metrics for task 1 >> {'accuracy': 0.2285, 'loss': 0.0227606201171875, 'std': 0.0905, 'EER': -1}\n",
      "[232] Eval metrics for task 2 >> {'accuracy': 0.157, 'loss': 0.026036139488220214, 'std': 0.047999999999999994, 'EER': -1}\n",
      "[232] Eval metrics for task 3 >> {'accuracy': 0.2395, 'loss': 0.01873884415626526, 'std': 0.0625, 'EER': -1}\n",
      "[232] Eval metrics for task 4 >> {'accuracy': 0.4905, 'loss': 0.009407384276390075, 'std': 0.012500000000000011, 'EER': -1}\n",
      "[232] Eval metrics for task 5 >> {'accuracy': 0.913, 'loss': 0.001089786935597658, 'std': 0.0, 'EER': -1}\n",
      "[233] Eval metrics for task 1 >> {'accuracy': 0.238, 'loss': 0.0225312397480011, 'std': 0.09100000000000003, 'EER': -1}\n",
      "[233] Eval metrics for task 2 >> {'accuracy': 0.1615, 'loss': 0.0254843909740448, 'std': 0.0555, 'EER': -1}\n",
      "[233] Eval metrics for task 3 >> {'accuracy': 0.241, 'loss': 0.018557937145233155, 'std': 0.06, 'EER': -1}\n",
      "[233] Eval metrics for task 4 >> {'accuracy': 0.5035000000000001, 'loss': 0.00929695987701416, 'std': 0.005500000000000005, 'EER': -1}\n",
      "[233] Eval metrics for task 5 >> {'accuracy': 0.907, 'loss': 0.0011785764619708062, 'std': 0.0020000000000000018, 'EER': -1}\n",
      "[234] Eval metrics for task 1 >> {'accuracy': 0.22799999999999998, 'loss': 0.022030398607254028, 'std': 0.085, 'EER': -1}\n",
      "[234] Eval metrics for task 2 >> {'accuracy': 0.1465, 'loss': 0.02598914909362793, 'std': 0.06149999999999999, 'EER': -1}\n",
      "[234] Eval metrics for task 3 >> {'accuracy': 0.214, 'loss': 0.01933030080795288, 'std': 0.04200000000000001, 'EER': -1}\n",
      "[234] Eval metrics for task 4 >> {'accuracy': 0.47050000000000003, 'loss': 0.009883017778396607, 'std': 0.026499999999999996, 'EER': -1}\n",
      "[234] Eval metrics for task 5 >> {'accuracy': 0.914, 'loss': 0.0011219547539949417, 'std': 0.01100000000000001, 'EER': -1}\n",
      "[235] Eval metrics for task 1 >> {'accuracy': 0.2215, 'loss': 0.022926857709884643, 'std': 0.08549999999999999, 'EER': -1}\n",
      "[235] Eval metrics for task 2 >> {'accuracy': 0.1545, 'loss': 0.025623417139053344, 'std': 0.05449999999999999, 'EER': -1}\n",
      "[235] Eval metrics for task 3 >> {'accuracy': 0.227, 'loss': 0.018738286256790162, 'std': 0.04100000000000001, 'EER': -1}\n",
      "[235] Eval metrics for task 4 >> {'accuracy': 0.48, 'loss': 0.00973722767829895, 'std': 0.016999999999999987, 'EER': -1}\n",
      "[235] Eval metrics for task 5 >> {'accuracy': 0.9145000000000001, 'loss': 0.001124831460416317, 'std': 0.008500000000000008, 'EER': -1}\n",
      "[236] Eval metrics for task 1 >> {'accuracy': 0.222, 'loss': 0.02264902353286743, 'std': 0.092, 'EER': -1}\n",
      "[236] Eval metrics for task 2 >> {'accuracy': 0.1385, 'loss': 0.026119536876678468, 'std': 0.0545, 'EER': -1}\n",
      "[236] Eval metrics for task 3 >> {'accuracy': 0.216, 'loss': 0.018867700576782227, 'std': 0.04300000000000001, 'EER': -1}\n",
      "[236] Eval metrics for task 4 >> {'accuracy': 0.47150000000000003, 'loss': 0.009830055475234986, 'std': 0.028499999999999998, 'EER': -1}\n",
      "[236] Eval metrics for task 5 >> {'accuracy': 0.921, 'loss': 0.0010451962426304817, 'std': 0.006000000000000005, 'EER': -1}\n",
      "[237] Eval metrics for task 1 >> {'accuracy': 0.2495, 'loss': 0.02162323522567749, 'std': 0.09549999999999999, 'EER': -1}\n",
      "[237] Eval metrics for task 2 >> {'accuracy': 0.17250000000000001, 'loss': 0.025022653102874756, 'std': 0.0585, 'EER': -1}\n",
      "[237] Eval metrics for task 3 >> {'accuracy': 0.2485, 'loss': 0.018219383001327513, 'std': 0.0625, 'EER': -1}\n",
      "[237] Eval metrics for task 4 >> {'accuracy': 0.5055000000000001, 'loss': 0.009391113758087159, 'std': 0.003500000000000003, 'EER': -1}\n",
      "[237] Eval metrics for task 5 >> {'accuracy': 0.9035, 'loss': 0.0012423881217837334, 'std': 0.0005000000000000004, 'EER': -1}\n",
      "[238] Eval metrics for task 1 >> {'accuracy': 0.218, 'loss': 0.02237210512161255, 'std': 0.08499999999999999, 'EER': -1}\n",
      "[238] Eval metrics for task 2 >> {'accuracy': 0.14300000000000002, 'loss': 0.025610192775726317, 'std': 0.05, 'EER': -1}\n",
      "[238] Eval metrics for task 3 >> {'accuracy': 0.22250000000000003, 'loss': 0.018669952392578126, 'std': 0.053500000000000006, 'EER': -1}\n",
      "[238] Eval metrics for task 4 >> {'accuracy': 0.4685, 'loss': 0.009682441353797913, 'std': 0.023499999999999993, 'EER': -1}\n",
      "[238] Eval metrics for task 5 >> {'accuracy': 0.919, 'loss': 0.0010496815666556358, 'std': 0.006000000000000005, 'EER': -1}\n",
      "[239] Eval metrics for task 1 >> {'accuracy': 0.2545, 'loss': 0.021979723930358887, 'std': 0.1025, 'EER': -1}\n",
      "[239] Eval metrics for task 2 >> {'accuracy': 0.1625, 'loss': 0.02630342125892639, 'std': 0.060500000000000005, 'EER': -1}\n",
      "[239] Eval metrics for task 3 >> {'accuracy': 0.23199999999999998, 'loss': 0.019442092418670655, 'std': 0.05299999999999999, 'EER': -1}\n",
      "[239] Eval metrics for task 4 >> {'accuracy': 0.497, 'loss': 0.009701647996902466, 'std': 0.014000000000000012, 'EER': -1}\n",
      "[239] Eval metrics for task 5 >> {'accuracy': 0.9065000000000001, 'loss': 0.001248870648443699, 'std': 0.007500000000000007, 'EER': -1}\n",
      "[240] Eval metrics for task 1 >> {'accuracy': 0.2445, 'loss': 0.02252251672744751, 'std': 0.09650000000000003, 'EER': -1}\n",
      "[240] Eval metrics for task 2 >> {'accuracy': 0.1665, 'loss': 0.026238063335418702, 'std': 0.0515, 'EER': -1}\n",
      "[240] Eval metrics for task 3 >> {'accuracy': 0.2385, 'loss': 0.019315816640853883, 'std': 0.058499999999999996, 'EER': -1}\n",
      "[240] Eval metrics for task 4 >> {'accuracy': 0.4865, 'loss': 0.00994030749797821, 'std': 0.016500000000000015, 'EER': -1}\n",
      "[240] Eval metrics for task 5 >> {'accuracy': 0.9085000000000001, 'loss': 0.0011967385485768319, 'std': 0.0015000000000000013, 'EER': -1}\n",
      "[241] Eval metrics for task 1 >> {'accuracy': 0.246, 'loss': 0.02192780685424805, 'std': 0.09799999999999999, 'EER': -1}\n",
      "[241] Eval metrics for task 2 >> {'accuracy': 0.1675, 'loss': 0.025520606994628905, 'std': 0.0565, 'EER': -1}\n",
      "[241] Eval metrics for task 3 >> {'accuracy': 0.2385, 'loss': 0.018815319776535035, 'std': 0.057499999999999996, 'EER': -1}\n",
      "[241] Eval metrics for task 4 >> {'accuracy': 0.497, 'loss': 0.009613617420196533, 'std': 0.010000000000000009, 'EER': -1}\n",
      "[241] Eval metrics for task 5 >> {'accuracy': 0.9085000000000001, 'loss': 0.0011914203017950058, 'std': 0.0025000000000000022, 'EER': -1}\n",
      "[242] Eval metrics for task 1 >> {'accuracy': 0.2105, 'loss': 0.02339906668663025, 'std': 0.0865, 'EER': -1}\n",
      "[242] Eval metrics for task 2 >> {'accuracy': 0.127, 'loss': 0.027473257303237915, 'std': 0.047999999999999994, 'EER': -1}\n",
      "[242] Eval metrics for task 3 >> {'accuracy': 0.1995, 'loss': 0.02007173752784729, 'std': 0.040499999999999994, 'EER': -1}\n",
      "[242] Eval metrics for task 4 >> {'accuracy': 0.439, 'loss': 0.010630249381065368, 'std': 0.016000000000000014, 'EER': -1}\n",
      "[242] Eval metrics for task 5 >> {'accuracy': 0.9215, 'loss': 0.0010265281796455383, 'std': 0.009500000000000008, 'EER': -1}\n",
      "[243] Eval metrics for task 1 >> {'accuracy': 0.2355, 'loss': 0.022169494867324828, 'std': 0.08950000000000001, 'EER': -1}\n",
      "[243] Eval metrics for task 2 >> {'accuracy': 0.161, 'loss': 0.025730375289916993, 'std': 0.07300000000000001, 'EER': -1}\n",
      "[243] Eval metrics for task 3 >> {'accuracy': 0.23149999999999998, 'loss': 0.018896727561950682, 'std': 0.056499999999999995, 'EER': -1}\n",
      "[243] Eval metrics for task 4 >> {'accuracy': 0.4905, 'loss': 0.00978084397315979, 'std': 0.0015000000000000013, 'EER': -1}\n",
      "[243] Eval metrics for task 5 >> {'accuracy': 0.9075, 'loss': 0.0011850524693727492, 'std': 0.004500000000000004, 'EER': -1}\n",
      "[244] Eval metrics for task 1 >> {'accuracy': 0.2195, 'loss': 0.023130059480667115, 'std': 0.08549999999999999, 'EER': -1}\n",
      "[244] Eval metrics for task 2 >> {'accuracy': 0.154, 'loss': 0.025896832466125487, 'std': 0.057999999999999996, 'EER': -1}\n",
      "[244] Eval metrics for task 3 >> {'accuracy': 0.231, 'loss': 0.018845748424530028, 'std': 0.05000000000000002, 'EER': -1}\n",
      "[244] Eval metrics for task 4 >> {'accuracy': 0.4825, 'loss': 0.009672112584114075, 'std': 0.006500000000000006, 'EER': -1}\n",
      "[244] Eval metrics for task 5 >> {'accuracy': 0.9145000000000001, 'loss': 0.001103860430419445, 'std': 0.004500000000000004, 'EER': -1}\n",
      "[245] Eval metrics for task 1 >> {'accuracy': 0.2555, 'loss': 0.021735380411148073, 'std': 0.09849999999999999, 'EER': -1}\n",
      "[245] Eval metrics for task 2 >> {'accuracy': 0.166, 'loss': 0.025922971725463866, 'std': 0.062000000000000006, 'EER': -1}\n",
      "[245] Eval metrics for task 3 >> {'accuracy': 0.23399999999999999, 'loss': 0.01920160746574402, 'std': 0.05299999999999999, 'EER': -1}\n",
      "[245] Eval metrics for task 4 >> {'accuracy': 0.5005, 'loss': 0.009672998666763306, 'std': 0.007500000000000007, 'EER': -1}\n",
      "[245] Eval metrics for task 5 >> {'accuracy': 0.903, 'loss': 0.0012825709581375123, 'std': 0.0040000000000000036, 'EER': -1}\n",
      "[246] Eval metrics for task 1 >> {'accuracy': 0.22049999999999997, 'loss': 0.022680285453796387, 'std': 0.0785, 'EER': -1}\n",
      "[246] Eval metrics for task 2 >> {'accuracy': 0.14600000000000002, 'loss': 0.025813717126846315, 'std': 0.049, 'EER': -1}\n",
      "[246] Eval metrics for task 3 >> {'accuracy': 0.2255, 'loss': 0.018620673656463624, 'std': 0.046500000000000014, 'EER': -1}\n",
      "[246] Eval metrics for task 4 >> {'accuracy': 0.4755, 'loss': 0.009692770361900329, 'std': 0.0005000000000000004, 'EER': -1}\n",
      "[246] Eval metrics for task 5 >> {'accuracy': 0.9115, 'loss': 0.001107650563120842, 'std': 0.0005000000000000004, 'EER': -1}\n",
      "[247] Eval metrics for task 1 >> {'accuracy': 0.238, 'loss': 0.02249366569519043, 'std': 0.08800000000000001, 'EER': -1}\n",
      "[247] Eval metrics for task 2 >> {'accuracy': 0.1645, 'loss': 0.02585875177383423, 'std': 0.0555, 'EER': -1}\n",
      "[247] Eval metrics for task 3 >> {'accuracy': 0.24, 'loss': 0.018933220863342284, 'std': 0.056999999999999995, 'EER': -1}\n",
      "[247] Eval metrics for task 4 >> {'accuracy': 0.4955, 'loss': 0.009689321041107177, 'std': 0.006500000000000006, 'EER': -1}\n",
      "[247] Eval metrics for task 5 >> {'accuracy': 0.9055, 'loss': 0.0012065078392624856, 'std': 0.0005000000000000004, 'EER': -1}\n",
      "[248] Eval metrics for task 1 >> {'accuracy': 0.22449999999999998, 'loss': 0.02235048031806946, 'std': 0.0805, 'EER': -1}\n",
      "[248] Eval metrics for task 2 >> {'accuracy': 0.1595, 'loss': 0.025209221601486205, 'std': 0.0575, 'EER': -1}\n",
      "[248] Eval metrics for task 3 >> {'accuracy': 0.2415, 'loss': 0.018346976041793823, 'std': 0.0635, 'EER': -1}\n",
      "[248] Eval metrics for task 4 >> {'accuracy': 0.494, 'loss': 0.00944615340232849, 'std': 0.01100000000000001, 'EER': -1}\n",
      "[248] Eval metrics for task 5 >> {'accuracy': 0.9105000000000001, 'loss': 0.0011474107876420022, 'std': 0.0005000000000000004, 'EER': -1}\n",
      "[249] Eval metrics for task 1 >> {'accuracy': 0.2185, 'loss': 0.023534358978271483, 'std': 0.08149999999999999, 'EER': -1}\n",
      "[249] Eval metrics for task 2 >> {'accuracy': 0.1385, 'loss': 0.0270830979347229, 'std': 0.0535, 'EER': -1}\n",
      "[249] Eval metrics for task 3 >> {'accuracy': 0.21150000000000002, 'loss': 0.019829013347625733, 'std': 0.041499999999999995, 'EER': -1}\n",
      "[249] Eval metrics for task 4 >> {'accuracy': 0.4595, 'loss': 0.010295083165168762, 'std': 0.024499999999999994, 'EER': -1}\n",
      "[249] Eval metrics for task 5 >> {'accuracy': 0.916, 'loss': 0.0010861580744385719, 'std': 0.008000000000000007, 'EER': -1}\n",
      "[250] Eval metrics for task 1 >> {'accuracy': 0.2135, 'loss': 0.023482423782348633, 'std': 0.0925, 'EER': -1}\n",
      "[250] Eval metrics for task 2 >> {'accuracy': 0.137, 'loss': 0.026846272230148314, 'std': 0.058, 'EER': -1}\n",
      "[250] Eval metrics for task 3 >> {'accuracy': 0.21000000000000002, 'loss': 0.01954496145248413, 'std': 0.043, 'EER': -1}\n",
      "[250] Eval metrics for task 4 >> {'accuracy': 0.4525, 'loss': 0.01014424729347229, 'std': 0.023499999999999993, 'EER': -1}\n",
      "[250] Eval metrics for task 5 >> {'accuracy': 0.92, 'loss': 0.0010257706567645072, 'std': 0.009000000000000008, 'EER': -1}\n",
      "training_task_end\n",
      "final avg-acc 0.38659999999999994\n",
      "final avg-forget 0.45725000000000005\n"
     ]
    }
   ],
   "source": [
    "trainer.run()\n",
    "print(\"final avg-acc\", metric_manager_callback.meters['accuracy'].compute_final())\n",
    "print(\"final avg-forget\", metric_manager_callback.meters['forgetting'].compute_final())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9801a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ebfb58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.09099999999999997, 0.052888888888888895, 0.21537499999999998, 0.23972]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_manager_callback.meters['EER'].get_eer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06af72df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.04199999999999998,\n",
       " 0.10449521520146265,\n",
       " 0.10135320528834904,\n",
       " 0.2721570089121351,\n",
       " 0.29213428419136295]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_manager_callback.meters['std'].get_std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a893b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7039ed8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.943, 0.   , 0.   , 0.   , 0.   ],\n",
       "       [0.446, 0.628, 0.   , 0.   , 0.   ],\n",
       "       [0.55 , 0.46 , 0.401, 0.   , 0.   ],\n",
       "       [0.412, 0.143, 0.334, 0.87 , 0.   ],\n",
       "       [0.214, 0.137, 0.21 , 0.452, 0.92 ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_manager_callback.meters['accuracy'].get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "173c4765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9430000000000001, 0.5365, 0.4701666666666667, 0.43975, 0.38659999999999994]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_manager_callback.meters['accuracy'].compute_overall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "706ad34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.5552033333333333\n",
      "EER:0.11979677777777775\n",
      "std:0.16242794271866196\n"
     ]
    }
   ],
   "source": [
    "print(f\"accuracy:{np.mean(metric_manager_callback.meters['accuracy'].compute_overall())}\")\n",
    "print(f\"EER:{np.mean(metric_manager_callback.meters['EER'].compute_overall())}\")\n",
    "print(f\"std:{np.mean(metric_manager_callback.meters['std'].compute_overall())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b848e47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
