{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0c3b92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_dir=./outputs/demo/dataset=CIFAR10/seed=1_epoch=1_lr=0.001_tau=1_alpha=0.001\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST, FashionMNIST, CIFAR10\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import cl_gym as cl\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "seed = 1\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "# torch.backends.cudnn.enabled = False\n",
    "\n",
    "def make_params() -> dict:\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    import uuid\n",
    "\n",
    "    params = {\n",
    "            # dataset\n",
    "            'dataset': \"CIFAR10\",\n",
    "            # 'dataset': \"FMNIST\",\n",
    "\n",
    "            # benchmark\n",
    "            'seed': seed,\n",
    "            'num_tasks': 5,\n",
    "            'epochs_per_task': 1,\n",
    "            # 'per_task_examples': 10000,\n",
    "            'per_task_examples': np.inf,\n",
    "            'per_task_memory_examples': 20,\n",
    "            'batch_size_train': 128,\n",
    "            'batch_size_memory': 128,\n",
    "            'batch_size_validation': 256,\n",
    "            'tau': 1,\n",
    "\n",
    "            # algorithm\n",
    "            'optimizer': 'sgd',\n",
    "            'learning_rate': 0.001,\n",
    "            'momentum': 0.9,\n",
    "            'learning_rate_decay': 1.0,\n",
    "            'criterion': torch.nn.CrossEntropyLoss(),\n",
    "            'device': torch.device('cuda:3' if torch.cuda.is_available() else 'cpu'),\n",
    "             \n",
    "            # sample selection\n",
    "            'alpha':0.001\n",
    "              }\n",
    "\n",
    "#     trial_id = str(uuid.uuid4())\n",
    "    trial_id = f\"demo/dataset={params['dataset']}/seed={params['seed']}_epoch={params['epochs_per_task']}_lr={params['learning_rate']}_tau={params['tau']}_alpha={params['alpha']}\"\n",
    "    params['trial_id'] = trial_id\n",
    "    params['output_dir'] = os.path.join(\"./outputs/{}\".format(trial_id))\n",
    "    print(f\"output_dir={params['output_dir']}\")\n",
    "    Path(params['output_dir']).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    return params\n",
    "\n",
    "params = make_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93b43ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from datasets import MNIST\n",
    "from datasets import FashionMNIST\n",
    "from datasets import CIFAR10, CIFAR100\n",
    "\n",
    "if params['dataset'] == 'MNIST':\n",
    "    benchmark = MNIST(num_tasks=params['num_tasks'],\n",
    "                      per_task_memory_examples=params['per_task_memory_examples'],\n",
    "                      per_task_examples = params['per_task_examples'],\n",
    "                      random_class_idx = False)\n",
    "    label_li = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "    n_feature = 28*28\n",
    "\n",
    "elif params['dataset'] == 'FMNIST':\n",
    "    benchmark = FashionMNIST(num_tasks=params['num_tasks'],\n",
    "                             per_task_memory_examples=params['per_task_memory_examples'],\n",
    "                             per_task_examples = params['per_task_examples'],\n",
    "                             random_class_idx = False)\n",
    "\n",
    "    label_li = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', \n",
    "                  'Ankel boot']\n",
    "    n_feature = 28*28\n",
    "    \n",
    "elif params['dataset'] == 'CIFAR10':\n",
    "    label_li = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    benchmark = CIFAR10(num_tasks=params['num_tasks'],\n",
    "                        per_task_memory_examples=params['per_task_memory_examples'],\n",
    "                        per_task_examples = params['per_task_examples'],\n",
    "                        random_class_idx = False)\n",
    "    n_feature = 32*32*3\n",
    "\n",
    "elif params['dataset'] == 'CIFAR100':\n",
    "    label_li = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    benchmark = CIFAR100(num_tasks=params['num_tasks'],\n",
    "                        per_task_memory_examples=params['per_task_memory_examples'],\n",
    "                        per_task_examples = params['per_task_examples'],\n",
    "                        random_class_idx = False)\n",
    "    n_feature = 32*32*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20c7b886",
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithms.imbalance import Heuristic2\n",
    "from metrics import MetricCollector2\n",
    "\n",
    "# backbone = cl.backbones.MLP2Layers(input_dim=784, hidden_dim_1=256, hidden_dim_2=256, output_dim=10)\n",
    "backbone = cl.backbones.ResNet18Small(num_classes_per_head = 2, num_classes = 10, config=params).to(params['device'])\n",
    "algorithm = Heuristic2(backbone, benchmark, params, requires_memory=True)\n",
    "metric_manager_callback = MetricCollector2(num_tasks=params['num_tasks'],\n",
    "                                                        eval_interval='epoch',\n",
    "                                                        epochs_per_task=params['epochs_per_task'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48ffa419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 3, 3, 3])\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "torch.Size([20, 20, 3, 3])\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "torch.Size([20, 20, 3, 3])\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "torch.Size([20, 20, 3, 3])\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "torch.Size([20, 20, 3, 3])\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "torch.Size([40, 20, 3, 3])\n",
      "torch.Size([40])\n",
      "torch.Size([40])\n",
      "torch.Size([40, 40, 3, 3])\n",
      "torch.Size([40])\n",
      "torch.Size([40])\n",
      "torch.Size([40, 20, 1, 1])\n",
      "torch.Size([40, 40, 3, 3])\n",
      "torch.Size([40])\n",
      "torch.Size([40])\n",
      "torch.Size([40, 40, 3, 3])\n",
      "torch.Size([40])\n",
      "torch.Size([40])\n",
      "torch.Size([80, 40, 3, 3])\n",
      "torch.Size([80])\n",
      "torch.Size([80])\n",
      "torch.Size([80, 80, 3, 3])\n",
      "torch.Size([80])\n",
      "torch.Size([80])\n",
      "torch.Size([80, 40, 1, 1])\n",
      "torch.Size([80, 80, 3, 3])\n",
      "torch.Size([80])\n",
      "torch.Size([80])\n",
      "torch.Size([80, 80, 3, 3])\n",
      "torch.Size([80])\n",
      "torch.Size([80])\n",
      "torch.Size([160, 80, 3, 3])\n",
      "torch.Size([160])\n",
      "torch.Size([160])\n",
      "torch.Size([160, 160, 3, 3])\n",
      "torch.Size([160])\n",
      "torch.Size([160])\n",
      "torch.Size([160, 80, 1, 1])\n",
      "torch.Size([160, 160, 3, 3])\n",
      "torch.Size([160])\n",
      "torch.Size([160])\n",
      "torch.Size([160, 160, 3, 3])\n",
      "torch.Size([160])\n",
      "torch.Size([160])\n",
      "torch.Size([10, 160])\n",
      "torch.Size([10])\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for p in backbone.parameters():\n",
    "    # print(n)\n",
    "    print(p.shape)\n",
    "    cnt+=1\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fe599d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight\n",
      "torch.Size([20, 3, 3, 3])\n",
      "bn1.weight\n",
      "torch.Size([20])\n",
      "bn1.bias\n",
      "torch.Size([20])\n",
      "layer1.0.conv1.weight\n",
      "torch.Size([20, 20, 3, 3])\n",
      "layer1.0.bn1.weight\n",
      "torch.Size([20])\n",
      "layer1.0.bn1.bias\n",
      "torch.Size([20])\n",
      "layer1.0.conv2.weight\n",
      "torch.Size([20, 20, 3, 3])\n",
      "layer1.0.bn2.weight\n",
      "torch.Size([20])\n",
      "layer1.0.bn2.bias\n",
      "torch.Size([20])\n",
      "layer1.1.conv1.weight\n",
      "torch.Size([20, 20, 3, 3])\n",
      "layer1.1.bn1.weight\n",
      "torch.Size([20])\n",
      "layer1.1.bn1.bias\n",
      "torch.Size([20])\n",
      "layer1.1.conv2.weight\n",
      "torch.Size([20, 20, 3, 3])\n",
      "layer1.1.bn2.weight\n",
      "torch.Size([20])\n",
      "layer1.1.bn2.bias\n",
      "torch.Size([20])\n",
      "layer2.0.conv1.weight\n",
      "torch.Size([40, 20, 3, 3])\n",
      "layer2.0.bn1.weight\n",
      "torch.Size([40])\n",
      "layer2.0.bn1.bias\n",
      "torch.Size([40])\n",
      "layer2.0.conv2.weight\n",
      "torch.Size([40, 40, 3, 3])\n",
      "layer2.0.bn2.weight\n",
      "torch.Size([40])\n",
      "layer2.0.bn2.bias\n",
      "torch.Size([40])\n",
      "layer2.0.shortcut.0.weight\n",
      "torch.Size([40, 20, 1, 1])\n",
      "layer2.1.conv1.weight\n",
      "torch.Size([40, 40, 3, 3])\n",
      "layer2.1.bn1.weight\n",
      "torch.Size([40])\n",
      "layer2.1.bn1.bias\n",
      "torch.Size([40])\n",
      "layer2.1.conv2.weight\n",
      "torch.Size([40, 40, 3, 3])\n",
      "layer2.1.bn2.weight\n",
      "torch.Size([40])\n",
      "layer2.1.bn2.bias\n",
      "torch.Size([40])\n",
      "layer3.0.conv1.weight\n",
      "torch.Size([80, 40, 3, 3])\n",
      "layer3.0.bn1.weight\n",
      "torch.Size([80])\n",
      "layer3.0.bn1.bias\n",
      "torch.Size([80])\n",
      "layer3.0.conv2.weight\n",
      "torch.Size([80, 80, 3, 3])\n",
      "layer3.0.bn2.weight\n",
      "torch.Size([80])\n",
      "layer3.0.bn2.bias\n",
      "torch.Size([80])\n",
      "layer3.0.shortcut.0.weight\n",
      "torch.Size([80, 40, 1, 1])\n",
      "layer3.1.conv1.weight\n",
      "torch.Size([80, 80, 3, 3])\n",
      "layer3.1.bn1.weight\n",
      "torch.Size([80])\n",
      "layer3.1.bn1.bias\n",
      "torch.Size([80])\n",
      "layer3.1.conv2.weight\n",
      "torch.Size([80, 80, 3, 3])\n",
      "layer3.1.bn2.weight\n",
      "torch.Size([80])\n",
      "layer3.1.bn2.bias\n",
      "torch.Size([80])\n",
      "layer4.0.conv1.weight\n",
      "torch.Size([160, 80, 3, 3])\n",
      "layer4.0.bn1.weight\n",
      "torch.Size([160])\n",
      "layer4.0.bn1.bias\n",
      "torch.Size([160])\n",
      "layer4.0.conv2.weight\n",
      "torch.Size([160, 160, 3, 3])\n",
      "layer4.0.bn2.weight\n",
      "torch.Size([160])\n",
      "layer4.0.bn2.bias\n",
      "torch.Size([160])\n",
      "layer4.0.shortcut.0.weight\n",
      "torch.Size([160, 80, 1, 1])\n",
      "layer4.1.conv1.weight\n",
      "torch.Size([160, 160, 3, 3])\n",
      "layer4.1.bn1.weight\n",
      "torch.Size([160])\n",
      "layer4.1.bn1.bias\n",
      "torch.Size([160])\n",
      "layer4.1.conv2.weight\n",
      "torch.Size([160, 160, 3, 3])\n",
      "layer4.1.bn2.weight\n",
      "torch.Size([160])\n",
      "layer4.1.bn2.bias\n",
      "torch.Size([160])\n",
      "linear.weight\n",
      "torch.Size([10, 160])\n",
      "linear.bias\n",
      "torch.Size([10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt=0\n",
    "for n, p in backbone.named_parameters():\n",
    "    print(n)\n",
    "    print(p.shape)\n",
    "    cnt+=1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6ecd316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Task 1 -----------------------\n",
      "solver=<function LS_solver at 0x7fbc5a7deca0>\n",
      "[1] Eval metrics for task 1 >> {'accuracy': 83.75, 'loss': 0.0014423785209655763, 'std': 4.449999999999998}\n",
      "training_task_end\n",
      "---------------------------- Task 2 -----------------------\n",
      "solver=<function LS_solver at 0x7fbc5a7deca0>\n",
      "losses=tensor([[2.0073, 2.1701, 2.6903, 2.2058]])\n",
      "A_np.shape=(4, 10000)\n",
      "b_np.shape=(4,)\n",
      "Elapsed time:46.554\n",
      "Loss difference:[ 2.52058974e-09 -1.67031461e-09  1.58451763e-09  1.64000519e-09]\n",
      "len(updated_seq_indices)=2788\n",
      "[2] Eval metrics for task 1 >> {'accuracy': 63.85000000000001, 'loss': 0.003664962440729141, 'std': 1.250000000000001}\n",
      "[2] Eval metrics for task 2 >> {'accuracy': 50.0, 'loss': 0.004260771095752716, 'std': 50.0}\n",
      "training_task_end\n",
      "---------------------------- Task 3 -----------------------\n",
      "solver=<function LS_solver at 0x7fbc5a7deca0>\n",
      "losses=tensor([[1.4675, 1.0663, 1.6982, 3.4718, 2.6347, 1.7467]])\n",
      "A_np.shape=(6, 10000)\n",
      "b_np.shape=(6,)\n",
      "Elapsed time:147.203\n",
      "Loss difference:[ 1.53518905  3.07001056  0.88088792 -8.92601521  1.28505556  2.15486651]\n",
      "len(updated_seq_indices)=1390\n",
      "[3] Eval metrics for task 1 >> {'accuracy': 60.400000000000006, 'loss': 0.004357323884963989, 'std': 5.199999999999999}\n",
      "[3] Eval metrics for task 2 >> {'accuracy': 51.5, 'loss': 0.0027724043130874635, 'std': 42.6}\n",
      "[3] Eval metrics for task 3 >> {'accuracy': 50.0, 'loss': 0.004419703423976898, 'std': 50.0}\n",
      "training_task_end\n",
      "---------------------------- Task 4 -----------------------\n",
      "solver=<function LS_solver at 0x7fbc5a7deca0>\n",
      "losses=tensor([[1.4575, 0.8861, 2.6568, 2.8129, 1.1287, 3.4144, 2.8045, 2.4776]])\n",
      "A_np.shape=(8, 10000)\n",
      "b_np.shape=(8,)\n",
      "Elapsed time:152.75\n",
      "Loss difference:[ 2.57689681  5.38370835 -3.94797566 -5.18058199  4.67242311 -9.72374848\n",
      "  2.919325    3.29995028]\n",
      "len(updated_seq_indices)=2267\n",
      "[4] Eval metrics for task 1 >> {'accuracy': 58.650000000000006, 'loss': 0.004976313948631287, 'std': 7.350000000000001}\n",
      "[4] Eval metrics for task 2 >> {'accuracy': 64.3, 'loss': 0.0025657668113708496, 'std': 6.0}\n",
      "[4] Eval metrics for task 3 >> {'accuracy': 68.39999999999999, 'loss': 0.0024000760912895203, 'std': 6.6000000000000005}\n",
      "[4] Eval metrics for task 4 >> {'accuracy': 64.4, 'loss': 0.002677306056022644, 'std': 22.6}\n",
      "training_task_end\n",
      "---------------------------- Task 5 -----------------------\n",
      "solver=<function LS_solver at 0x7fbc5a7deca0>\n",
      "losses=tensor([[1.1229, 1.1396, 2.7344, 2.5100, 1.9931, 1.7094, 1.9513, 2.9226, 3.7071,\n",
      "         3.1286]])\n",
      "A_np.shape=(10, 10000)\n",
      "b_np.shape=(10,)\n",
      "Elapsed time:81.733\n",
      "Loss difference:[ 2.06392895  3.86993956 -4.65491842 -2.93066049  1.54864635  2.78331282\n",
      "  0.98611343 -6.44968605  1.30192824  1.48140146]\n",
      "len(updated_seq_indices)=3490\n",
      "[5] Eval metrics for task 1 >> {'accuracy': 63.349999999999994, 'loss': 0.003963310986757279, 'std': 4.750000000000004}\n",
      "[5] Eval metrics for task 2 >> {'accuracy': 64.1, 'loss': 0.0024822971522808074, 'std': 15.700000000000003}\n",
      "[5] Eval metrics for task 3 >> {'accuracy': 68.30000000000001, 'loss': 0.002605486065149307, 'std': 2.099999999999996}\n",
      "[5] Eval metrics for task 4 >> {'accuracy': 66.10000000000001, 'loss': 0.0025021630227565765, 'std': 0.0}\n",
      "[5] Eval metrics for task 5 >> {'accuracy': 76.1, 'loss': 0.0020885708779096604, 'std': 3.0000000000000027}\n",
      "training_task_end\n",
      "final avg-acc 67.59\n",
      "final avg-forget 5.174999999999997\n"
     ]
    }
   ],
   "source": [
    "from trainers import ContinualTrainer\n",
    "\n",
    "trainer = ContinualTrainer(algorithm, params, callbacks=[metric_manager_callback])\n",
    "trainer.run()\n",
    "print(\"final avg-acc\", metric_manager_callback.meters['accuracy'].compute_final())\n",
    "print(\"final avg-forget\", metric_manager_callback.meters['forgetting'].compute_final())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c076b062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.449999999999998,\n",
       " 36.03799210555438,\n",
       " 38.318866835484,\n",
       " 13.158261425811542,\n",
       " 8.806412436401104]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_manager_callback.meters['std'].get_std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7039ed8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[83.75,  0.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [63.85, 50.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [60.4 , 51.5 , 50.  ,  0.  ,  0.  ],\n",
       "       [58.65, 64.3 , 68.4 , 64.4 ,  0.  ],\n",
       "       [63.35, 64.1 , 68.3 , 66.1 , 76.1 ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_manager_callback.meters['accuracy'].get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "173c4765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65.23383333333334"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_manager_callback.meters['accuracy'].compute_overall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "706ad34c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67.59"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_manager_callback.meters['accuracy'].compute_final()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1b2b0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.154306560650205"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(metric_manager_callback.meters['std'].get_std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f0692f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65.23383333333334"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(metric_manager_callback.meters['accuracy'].compute_overall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6d7afe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
