{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0c3b92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_dir=./outputs/greedy/dataset=MNIST/seed=1_epoch=5_lr=0.001_alpha=0.005_tau=10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import cl_gym as cl\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "seed = 1\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "# torch.backends.cudnn.enabled = False\n",
    "\n",
    "def make_params() -> dict:\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "\n",
    "    params = {\n",
    "            # dataset\n",
    "            'dataset': \"MNIST\",\n",
    "            # 'dataset': \"FMNIST\",\n",
    "\n",
    "            # benchmark\n",
    "            'seed': seed,\n",
    "            'num_tasks': 5,\n",
    "            'epochs_per_task': 5,\n",
    "            'per_task_examples': np.inf,\n",
    "            'per_task_memory_examples': 20,\n",
    "            'batch_size_train': 64,\n",
    "            'batch_size_memory': 64,\n",
    "            'batch_size_validation': 256,\n",
    "            'tau': 10,\n",
    "\n",
    "            # algorithm\n",
    "            'optimizer': 'sgd',\n",
    "            'learning_rate': 0.001,\n",
    "            'momentum': 0.9,\n",
    "            'learning_rate_decay': 1.0,\n",
    "            'criterion': torch.nn.CrossEntropyLoss(),\n",
    "            'device': torch.device('cuda:6' if torch.cuda.is_available() else 'cpu'),\n",
    "                         \n",
    "            # sample selection\n",
    "            'alpha':0.005\n",
    "              }\n",
    "\n",
    "#     trial_id = str(uuid.uuid4())\n",
    "    trial_id = f\"greedy/dataset={params['dataset']}/seed={params['seed']}_epoch={params['epochs_per_task']}_lr={params['learning_rate']}_alpha={params['alpha']}_tau={params['tau']}\"\n",
    "    params['trial_id'] = trial_id\n",
    "    params['output_dir'] = os.path.join(\"./outputs/{}\".format(trial_id))\n",
    "    print(f\"output_dir={params['output_dir']}\")\n",
    "    Path(params['output_dir']).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    return params\n",
    "\n",
    "params = make_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93b43ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "from datasets import MNIST\n",
    "from datasets import FashionMNIST\n",
    "from datasets import CIFAR10, CIFAR100\n",
    "\n",
    "if params['dataset'] == 'MNIST':\n",
    "    benchmark = MNIST(num_tasks=params['num_tasks'],\n",
    "                      per_task_memory_examples=params['per_task_memory_examples'],\n",
    "                      per_task_examples = params['per_task_examples'],\n",
    "                      random_class_idx = False)\n",
    "    label_li = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "    n_feature = 28*28\n",
    "\n",
    "elif params['dataset'] == 'FMNIST':\n",
    "    benchmark = FashionMNIST(num_tasks=params['num_tasks'],\n",
    "                             per_task_memory_examples=params['per_task_memory_examples'],\n",
    "                             per_task_examples = params['per_task_examples'],\n",
    "                             random_class_idx = False)\n",
    "\n",
    "    label_li = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', \n",
    "                  'Ankel boot']\n",
    "    n_feature = 28*28\n",
    "    \n",
    "elif params['dataset'] == 'CIFAR10':\n",
    "    label_li = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    benchmark = CIFAR10(num_tasks=params['num_tasks'],\n",
    "                        per_task_memory_examples=params['per_task_memory_examples'],\n",
    "                        per_task_examples = params['per_task_examples'],\n",
    "                        random_class_idx = False)\n",
    "    n_feature = 32*32*3\n",
    "\n",
    "elif params['dataset'] == 'CIFAR100':\n",
    "    label_li = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    benchmark = CIFAR100(num_tasks=params['num_tasks'],\n",
    "                        per_task_memory_examples=params['per_task_memory_examples'],\n",
    "                        per_task_examples = params['per_task_examples'],\n",
    "                        random_class_idx = False)\n",
    "    n_feature = 32*32*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1f11bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20c7b886",
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithms import GreedySelection\n",
    "from metrics import MetricCollector2\n",
    "\n",
    "backbone = cl.backbones.MLP2Layers(input_dim=784, hidden_dim_1=256, hidden_dim_2=256, output_dim=10)\n",
    "algorithm = GreedySelection(backbone, benchmark, params, requires_memory=True)\n",
    "metric_manager_callback = MetricCollector2(num_tasks=params['num_tasks'],\n",
    "                                                        eval_interval='epoch',\n",
    "                                                        epochs_per_task=params['epochs_per_task'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c1bb4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Task 1 -----------------------\n",
      "[1] Eval metrics for task 1 >> {'accuracy': 99.80985345680122, 'loss': 4.688272798702508e-05, 'std': 0.013935089454286675}\n",
      "[2] Eval metrics for task 1 >> {'accuracy': 99.89795918367346, 'loss': 2.993500525083384e-05, 'std': 0.10204081632653184}\n",
      "[3] Eval metrics for task 1 >> {'accuracy': 99.89795918367346, 'loss': 1.9580971925182547e-05, 'std': 0.10204081632653184}\n",
      "[4] Eval metrics for task 1 >> {'accuracy': 99.89795918367346, 'loss': 1.585140690013731e-05, 'std': 0.10204081632653184}\n",
      "[5] Eval metrics for task 1 >> {'accuracy': 99.89795918367346, 'loss': 1.4160802735381234e-05, 'std': 0.10204081632653184}\n",
      "training_task_end\n",
      "---------------------------- Task 2 -----------------------\n",
      "len(select_curr_indexes)=2438\n",
      "For debugging: len(select_curr_indexes)=2438\n",
      "[6] Eval metrics for task 1 >> {'accuracy': 99.47361323383979, 'loss': 0.00011442569447747359, 'std': 0.0858581317989715}\n",
      "[6] Eval metrics for task 2 >> {'accuracy': 60.368696753396264, 'loss': 0.004495492002522677, 'std': 12.4035804743265}\n",
      "len(select_curr_indexes)=298\n",
      "For debugging: len(select_curr_indexes)=298\n",
      "[7] Eval metrics for task 1 >> {'accuracy': 97.16870448619976, 'loss': 0.0006884172629239148, 'std': 0.07619347298390977}\n",
      "[7] Eval metrics for task 2 >> {'accuracy': 83.25274387903907, 'loss': 0.0020448618461756467, 'std': 8.995318136464808}\n",
      "len(select_curr_indexes)=205\n",
      "For debugging: len(select_curr_indexes)=205\n",
      "[8] Eval metrics for task 1 >> {'accuracy': 89.70511552638676, 'loss': 0.0020623903466172816, 'std': 6.621415085858135}\n",
      "[8] Eval metrics for task 2 >> {'accuracy': 87.94189884104689, 'loss': 0.0016239179219835302, 'std': 10.120116662829071}\n",
      "len(select_curr_indexes)=176\n",
      "For debugging: len(select_curr_indexes)=176\n",
      "[9] Eval metrics for task 1 >> {'accuracy': 95.10293985435584, 'loss': 0.0009970178065852352, 'std': 2.8562438191135464}\n",
      "[9] Eval metrics for task 2 >> {'accuracy': 92.76402640264025, 'loss': 0.001414105617217756, 'std': 1.0973597359735965}\n",
      "len(select_curr_indexes)=1384\n",
      "For debugging: len(select_curr_indexes)=1384\n",
      "[10] Eval metrics for task 1 >> {'accuracy': 95.88645149689832, 'loss': 0.0006045333917822961, 'std': 0.6441607479996392}\n",
      "[10] Eval metrics for task 2 >> {'accuracy': 90.6575715711106, 'loss': 0.0011068061796855272, 'std': 5.580052191265638}\n",
      "training_task_end\n",
      "---------------------------- Task 3 -----------------------\n",
      "len(select_curr_indexes)=4149\n",
      "For debugging: len(select_curr_indexes)=4149\n",
      "[11] Eval metrics for task 1 >> {'accuracy': 91.24157151847523, 'loss': 0.0011450980571990317, 'std': 1.4456531511282955}\n",
      "[11] Eval metrics for task 2 >> {'accuracy': 82.25756005833142, 'loss': 0.0023018240082158864, 'std': 1.366470949420523}\n",
      "[11] Eval metrics for task 3 >> {'accuracy': 71.2783008959477, 'loss': 0.0035170565101863734, 'std': 8.049601344378177}\n",
      "len(select_curr_indexes)=315\n",
      "For debugging: len(select_curr_indexes)=315\n",
      "[12] Eval metrics for task 1 >> {'accuracy': 88.7049357187809, 'loss': 0.0016175512585515953, 'std': 0.0705744853007284}\n",
      "[12] Eval metrics for task 2 >> {'accuracy': 68.59841507406554, 'loss': 0.004157218742790932, 'std': 14.638019034461585}\n",
      "[12] Eval metrics for task 3 >> {'accuracy': 86.81742211830893, 'loss': 0.00174682658153766, 'std': 0.046121669878440574}\n",
      "len(select_curr_indexes)=235\n",
      "For debugging: len(select_curr_indexes)=235\n",
      "[13] Eval metrics for task 1 >> {'accuracy': 84.04701968893285, 'loss': 0.0026917891863108244, 'std': 5.544817045761036}\n",
      "[13] Eval metrics for task 2 >> {'accuracy': 75.88091948729756, 'loss': 0.0031246467038303118, 'std': 6.871018497198561}\n",
      "[13] Eval metrics for task 3 >> {'accuracy': 84.54821312777986, 'loss': 0.001870721960271308, 'std': 6.18498442822829}\n",
      "len(select_curr_indexes)=265\n",
      "For debugging: len(select_curr_indexes)=265\n",
      "[14] Eval metrics for task 1 >> {'accuracy': 83.06864155353772, 'loss': 0.0029780873733773017, 'std': 7.033399262788819}\n",
      "[14] Eval metrics for task 2 >> {'accuracy': 80.17518612326349, 'loss': 0.0025505972305544444, 'std': 3.739542558907055}\n",
      "[14] Eval metrics for task 3 >> {'accuracy': 81.65864484487592, 'loss': 0.002047167134768426, 'std': 9.685550674472342}\n",
      "len(select_curr_indexes)=250\n",
      "For debugging: len(select_curr_indexes)=250\n",
      "[15] Eval metrics for task 1 >> {'accuracy': 87.17724534747819, 'loss': 0.0021630038888178255, 'std': 3.741121999460578}\n",
      "[15] Eval metrics for task 2 >> {'accuracy': 72.39974288126487, 'loss': 0.003585609469661283, 'std': 11.80568347532428}\n",
      "[15] Eval metrics for task 3 >> {'accuracy': 89.81681477354716, 'loss': 0.0013746857929382405, 'std': 2.0365457152512034}\n",
      "training_task_end\n",
      "---------------------------- Task 4 -----------------------\n",
      "len(select_curr_indexes)=4974\n",
      "For debugging: len(select_curr_indexes)=4974\n",
      "[16] Eval metrics for task 1 >> {'accuracy': 80.15216218646049, 'loss': 0.0027322212714111834, 'std': 7.6011417782972215}\n",
      "[16] Eval metrics for task 2 >> {'accuracy': 72.73476475554533, 'loss': 0.003951236591049553, 'std': 7.982289508020568}\n",
      "[16] Eval metrics for task 3 >> {'accuracy': 80.94444393705533, 'loss': 0.002782975119740375, 'std': 12.334578466203322}\n",
      "[16] Eval metrics for task 4 >> {'accuracy': 84.60293412833155, 'loss': 0.0016657585824004114, 'std': 6.836754587621746}\n",
      "len(select_curr_indexes)=103\n",
      "For debugging: len(select_curr_indexes)=103\n",
      "[17] Eval metrics for task 1 >> {'accuracy': 78.83507147352333, 'loss': 0.0028720504566850957, 'std': 7.508540861278434}\n",
      "[17] Eval metrics for task 2 >> {'accuracy': 71.50241768362882, 'loss': 0.0040969707064483826, 'std': 8.730140455906055}\n",
      "[17] Eval metrics for task 3 >> {'accuracy': 80.16528453873764, 'loss': 0.0030627441826090616, 'std': 11.891741937840772}\n",
      "[17] Eval metrics for task 4 >> {'accuracy': 88.23505519767998, 'loss': 0.0013341179487088176, 'std': 3.7882911058219504}\n",
      "len(select_curr_indexes)=77\n",
      "For debugging: len(select_curr_indexes)=77\n",
      "[18] Eval metrics for task 1 >> {'accuracy': 77.10060235547964, 'loss': 0.0032252784880058703, 'std': 7.304683988132698}\n",
      "[18] Eval metrics for task 2 >> {'accuracy': 70.08365952874357, 'loss': 0.004343966458149685, 'std': 8.598511013892086}\n",
      "[18] Eval metrics for task 3 >> {'accuracy': 78.2655055574329, 'loss': 0.0033708576395264814, 'std': 11.449362059675044}\n",
      "[18] Eval metrics for task 4 >> {'accuracy': 91.58844626044858, 'loss': 0.0010255672270197643, 'std': 1.504938953559215}\n",
      "len(select_curr_indexes)=63\n",
      "For debugging: len(select_curr_indexes)=63\n",
      "[19] Eval metrics for task 1 >> {'accuracy': 76.0617639126135, 'loss': 0.0033567384061520262, 'std': 7.28625370853187}\n",
      "[19] Eval metrics for task 2 >> {'accuracy': 69.00721467495588, 'loss': 0.004448186142787878, 'std': 8.512165170005376}\n",
      "[19] Eval metrics for task 3 >> {'accuracy': 77.31818472413762, 'loss': 0.0035092846879073623, 'std': 11.174686966290082}\n",
      "[19] Eval metrics for task 4 >> {'accuracy': 92.8790321925542, 'loss': 0.0009340452628673504, 'std': 0.6034580798193412}\n",
      "len(select_curr_indexes)=61\n",
      "For debugging: len(select_curr_indexes)=61\n",
      "[20] Eval metrics for task 1 >> {'accuracy': 74.57992448080553, 'loss': 0.0037256298617550105, 'std': 8.15135305223411}\n",
      "[20] Eval metrics for task 2 >> {'accuracy': 68.52271855092486, 'loss': 0.004524243158177928, 'std': 8.027669045974367}\n",
      "[20] Eval metrics for task 3 >> {'accuracy': 76.25361895280977, 'loss': 0.0035677531867296997, 'std': 11.119089804827704}\n",
      "[20] Eval metrics for task 4 >> {'accuracy': 93.54331332298969, 'loss': 0.0008687436700707596, 'std': 0.3282820077496085}\n",
      "training_task_end\n",
      "---------------------------- Task 5 -----------------------\n",
      "len(select_curr_indexes)=5175\n",
      "For debugging: len(select_curr_indexes)=5175\n",
      "[21] Eval metrics for task 1 >> {'accuracy': 78.47343342623392, 'loss': 0.0032530045396610917, 'std': 6.636698732356383}\n",
      "[21] Eval metrics for task 2 >> {'accuracy': 57.175819326118656, 'loss': 0.006826922487208472, 'std': 6.680769821168164}\n",
      "[21] Eval metrics for task 3 >> {'accuracy': 62.546007507329236, 'loss': 0.0063156516091419, 'std': 12.097577014055695}\n",
      "[21] Eval metrics for task 4 >> {'accuracy': 82.31389568085261, 'loss': 0.002165193629168792, 'std': 9.648526031047172}\n",
      "[21] Eval metrics for task 5 >> {'accuracy': 84.82395605871591, 'loss': 0.0017748466358002064, 'std': 2.688432444752875}\n",
      "len(select_curr_indexes)=205\n",
      "For debugging: len(select_curr_indexes)=205\n",
      "[22] Eval metrics for task 1 >> {'accuracy': 72.36312146003776, 'loss': 0.004001281475626267, 'std': 8.07740717432347}\n",
      "[22] Eval metrics for task 2 >> {'accuracy': 55.29146519303093, 'loss': 0.007091423907079146, 'std': 8.855821628674496}\n",
      "[22] Eval metrics for task 3 >> {'accuracy': 60.10669631848611, 'loss': 0.0068538910296836045, 'std': 10.66723443507804}\n",
      "[22] Eval metrics for task 4 >> {'accuracy': 80.78123603811443, 'loss': 0.002422265085689011, 'std': 10.450496738503528}\n",
      "[22] Eval metrics for task 5 >> {'accuracy': 89.19096712747489, 'loss': 0.0014093997679271303, 'std': 1.876794679506616}\n",
      "len(select_curr_indexes)=234\n",
      "For debugging: len(select_curr_indexes)=234\n",
      "[23] Eval metrics for task 1 >> {'accuracy': 69.01465431987774, 'loss': 0.004668718280521691, 'std': 8.606491054571608}\n",
      "[23] Eval metrics for task 2 >> {'accuracy': 55.89713331798296, 'loss': 0.006844191313023432, 'std': 7.184262030854249}\n",
      "[23] Eval metrics for task 3 >> {'accuracy': 56.91391230489621, 'loss': 0.00739059071657879, 'std': 8.259203784716831}\n",
      "[23] Eval metrics for task 4 >> {'accuracy': 78.25692712606516, 'loss': 0.0028067049603207714, 'std': 10.260818176648822}\n",
      "[23] Eval metrics for task 5 >> {'accuracy': 90.02478718229976, 'loss': 0.001296293717469462, 'std': 3.404370928583206}\n",
      "len(select_curr_indexes)=255\n",
      "For debugging: len(select_curr_indexes)=255\n",
      "[24] Eval metrics for task 1 >> {'accuracy': 70.98781803470287, 'loss': 0.004523304985488278, 'std': 10.069450687764093}\n",
      "[24] Eval metrics for task 2 >> {'accuracy': 59.285536111750716, 'loss': 0.006452326326248811, 'std': 6.315239082047741}\n",
      "[24] Eval metrics for task 3 >> {'accuracy': 54.785237412437326, 'loss': 0.007493479274761969, 'std': 7.027389878805038}\n",
      "[24] Eval metrics for task 4 >> {'accuracy': 76.62455423507144, 'loss': 0.002896736005521853, 'std': 12.519495869312685}\n",
      "[24] Eval metrics for task 5 >> {'accuracy': 86.28356088834983, 'loss': 0.0014636963681025272, 'std': 8.5628216686373}\n",
      "len(select_curr_indexes)=449\n",
      "For debugging: len(select_curr_indexes)=449\n",
      "[25] Eval metrics for task 1 >> {'accuracy': 68.61593095387934, 'loss': 0.004904154654653923, 'std': 7.595522790614045}\n",
      "[25] Eval metrics for task 2 >> {'accuracy': 53.71776421828229, 'loss': 0.00751702675740002, 'std': 14.014793921252588}\n",
      "[25] Eval metrics for task 3 >> {'accuracy': 61.673006493565794, 'loss': 0.007312738399240988, 'std': 16.942064789529926}\n",
      "[25] Eval metrics for task 4 >> {'accuracy': 84.14792897004948, 'loss': 0.00218838580845586, 'std': 7.396956207403554}\n",
      "[25] Eval metrics for task 5 >> {'accuracy': 72.28297478748756, 'loss': 0.002587103086232057, 'std': 23.91825724536665}\n",
      "training_task_end\n",
      "final avg-acc 68.08752108465289\n",
      "final avg-forget 26.440257053886\n"
     ]
    }
   ],
   "source": [
    "from trainers import ContinualTrainer\n",
    "\n",
    "trainer = ContinualTrainer(algorithm, params, callbacks=[metric_manager_callback])\n",
    "trainer.run()\n",
    "print(\"final avg-acc\", metric_manager_callback.meters['accuracy'].compute_final())\n",
    "print(\"final avg-forget\", metric_manager_callback.meters['forgetting'].compute_final())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3e684df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1384"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(benchmark.seq_indices_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47692e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12665"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(benchmark.seq_indices_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "305f6bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11800"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(algorithm.original_seq_indices_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1f42cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(np.random.choice(12089, 6000, False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c16237",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c076b062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.10204081632653184,\n",
       " 4.755129765088689,\n",
       " 10.547507988720005,\n",
       " 12.25344707791861,\n",
       " 18.392344196899067]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_manager_callback.meters['std'].get_std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8faf4a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.tensor([12, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be5b89dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(a, torch.Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7039ed8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[99.898,  0.   ,  0.   ,  0.   ,  0.   ],\n",
       "       [95.886, 90.658,  0.   ,  0.   ,  0.   ],\n",
       "       [87.177, 72.4  , 89.817,  0.   ,  0.   ],\n",
       "       [74.58 , 68.523, 76.254, 93.543,  0.   ],\n",
       "       [68.616, 53.718, 61.673, 84.148, 72.283]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_manager_callback.meters['accuracy'].get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "173c4765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[99.89795918367346,\n",
       " 93.27201153400446,\n",
       " 83.13126766743007,\n",
       " 78.22489382688246,\n",
       " 68.08752108465289]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_manager_callback.meters['accuracy'].compute_overall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706ad34c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
