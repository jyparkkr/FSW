{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0c3b92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_dir=./outputs/demo/dataset=MNIST/seed=10_epoch=5_lr=0.001_tau=10.0_alpha=0.0_lmbd_1.0_lmbdold_0.0\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST, FashionMNIST, CIFAR10\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import cl_gym as cl\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "seed = 10\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed) \n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "# torch.backends.cudnn.enabled = False\n",
    "torch.set_num_threads(6)\n",
    "\n",
    "\n",
    "def make_params() -> dict:\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    import uuid\n",
    "\n",
    "    params = {\n",
    "            # dataset\n",
    "            'dataset': \"MNIST\",\n",
    "            'model': 'MLP',\n",
    "            'random_class_idx' : False,\n",
    "\n",
    "            # benchmark\n",
    "            'seed': seed,\n",
    "            'num_tasks': 5,\n",
    "            'epochs_per_task': 5,\n",
    "            'per_task_examples': np.inf,\n",
    "            # 'per_task_examples': 10000,\n",
    "            'per_task_memory_examples': 64,\n",
    "            'batch_size_train': 64,\n",
    "            'batch_size_memory': 64,\n",
    "            'batch_size_validation': 256,\n",
    "            'tau': 10.0,\n",
    "\n",
    "            # algorithm\n",
    "            'optimizer': 'sgd',\n",
    "            'learning_rate': 0.001,\n",
    "            'momentum': 0.9,\n",
    "            'learning_rate_decay': 1.0,\n",
    "            'criterion': torch.nn.CrossEntropyLoss(),\n",
    "            'device': torch.device('cuda:7' if torch.cuda.is_available() else 'cpu'),\n",
    "             \n",
    "            # sample selection\n",
    "            'alpha': 0.00,\n",
    "            'metric' : \"EO\",\n",
    "            'lambda': 1.0,\n",
    "            'lambda_old': 0.0,\n",
    "              }\n",
    "    \n",
    "\n",
    "\n",
    "#     trial_id = str(uuid.uuid4())\n",
    "    trial_id = f\"demo/dataset={params['dataset']}/seed={params['seed']}_epoch={params['epochs_per_task']}_lr={params['learning_rate']}_tau={params['tau']}_alpha={params['alpha']}\"\n",
    "    if params['lambda'] != 0:\n",
    "        trial_id+=f\"_lmbd_{params['lambda']}_lmbdold_{params['lambda_old']}\"\n",
    "    params['trial_id'] = trial_id\n",
    "    params['output_dir'] = os.path.join(\"./outputs/{}\".format(trial_id))\n",
    "    print(f\"output_dir={params['output_dir']}\")\n",
    "    Path(params['output_dir']).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    return params\n",
    "\n",
    "params = make_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99826537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"MNIST\" in params['dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20c7b886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "from datasets import MNIST\n",
    "from datasets import FashionMNIST\n",
    "from datasets import CIFAR10, CIFAR100\n",
    "\n",
    "if params['dataset'] == 'MNIST':\n",
    "    benchmark = MNIST(num_tasks=params['num_tasks'],\n",
    "                    per_task_memory_examples=params['per_task_memory_examples'],\n",
    "                    per_task_examples = params['per_task_examples'],\n",
    "                    random_class_idx = params['random_class_idx'])\n",
    "    input_dim = (28, 28)\n",
    "elif params['dataset'] == 'FashionMNIST':\n",
    "    benchmark = FashionMNIST(num_tasks=params['num_tasks'],\n",
    "                            per_task_memory_examples=params['per_task_memory_examples'],\n",
    "                            per_task_examples = params['per_task_examples'],\n",
    "                            random_class_idx = params['random_class_idx'])\n",
    "    input_dim = (28, 28)\n",
    "elif params['dataset'] == 'CIFAR10':\n",
    "    benchmark = CIFAR10(num_tasks=params['num_tasks'],\n",
    "                        per_task_memory_examples=params['per_task_memory_examples'],\n",
    "                        per_task_examples = params['per_task_examples'],\n",
    "                        random_class_idx = params['random_class_idx'])\n",
    "    input_dim = (3, 32, 32)\n",
    "elif params['dataset'] == 'CIFAR100':        \n",
    "    benchmark = CIFAR100(num_tasks=params['num_tasks'],\n",
    "                        per_task_memory_examples=params['per_task_memory_examples'],\n",
    "                        per_task_examples = params['per_task_examples'],\n",
    "                        random_class_idx = params['random_class_idx'])\n",
    "    input_dim = (3, 32, 32)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "class_idx = benchmark.class_idx\n",
    "num_classes = len(class_idx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e73e1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FaIRL\n"
     ]
    }
   ],
   "source": [
    "from trainers import FairContinualTrainer\n",
    "from trainers.fair_trainer import FairContinualTrainer1\n",
    "# from trainers.baselines import BaseMemoryContinualTrainer as ContinualTrainer\n",
    "from metrics import FairMetricCollector\n",
    "from algorithms.fairl import FaIRL\n",
    "from algorithms.fairl import FaIRL\n",
    "from backbones import MLP2Layers2\n",
    "\n",
    "backbone = MLP2Layers2(\n",
    "    input_dim=input_dim, \n",
    "    hidden_dim_1=256, \n",
    "    hidden_dim_2=256, \n",
    "    output_dim=num_classes,\n",
    "    class_idx=class_idx,\n",
    "    config=params\n",
    "    ).to(params['device'])\n",
    "algorithm = FaIRL(backbone, benchmark, params, requires_memory=True)\n",
    "metric_manager_callback = FairMetricCollector(num_tasks=params['num_tasks'],\n",
    "                                                        eval_interval='epoch',\n",
    "                                                        epochs_per_task=params['epochs_per_task'])\n",
    "\n",
    "trainer = FairContinualTrainer1(algorithm, params, callbacks=[metric_manager_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2eac756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Task 1 -----------------------\n",
      "[1] Eval metrics for task 1 >> {'accuracy': 0.9937157241751327, 'loss': 0.0032638977887219007, 'std': 0.0018789894812550334, 'EER': -1, 'EO': -1, 'DP': -1, 'accuracy_s0': -1, 'accuracy_s1': -1, 'classwise_accuracy': {0: array([972, 980]), 1: array([1130, 1135])}, 'DP_ingredients': {}}\n",
      "[2] Eval metrics for task 1 >> {'accuracy': 0.9921851119302346, 'loss': 0.0020663118954245925, 'std': 0.003409601726153011, 'EER': -1, 'EO': -1, 'DP': -1, 'accuracy_s0': -1, 'accuracy_s1': -1, 'classwise_accuracy': {1: array([1130, 1135]), 0: array([969, 980])}, 'DP_ingredients': {}}\n",
      "[3] Eval metrics for task 1 >> {'accuracy': 0.992254787377506, 'loss': 0.0015517447857146568, 'std': 0.002458869010159126, 'EER': -1, 'EO': -1, 'DP': -1, 'accuracy_s0': -1, 'accuracy_s1': -1, 'classwise_accuracy': {0: array([970, 980]), 1: array([1129, 1135])}, 'DP_ingredients': {}}\n",
      "[4] Eval metrics for task 1 >> {'accuracy': 0.9942259282567653, 'loss': 0.0013031852442603865, 'std': 0.0013687853996223742, 'EER': -1, 'EO': -1, 'DP': -1, 'accuracy_s0': -1, 'accuracy_s1': -1, 'classwise_accuracy': {1: array([1130, 1135]), 0: array([973, 980])}, 'DP_ingredients': {}}\n",
      "[5] Eval metrics for task 1 >> {'accuracy': 0.9972174772992897, 'loss': 0.0010876902029023949, 'std': 0.0007417063741796404, 'EER': -1, 'EO': -1, 'DP': -1, 'accuracy_s0': -1, 'accuracy_s1': -1, 'classwise_accuracy': {0: array([978, 980]), 1: array([1131, 1135])}, 'DP_ingredients': {}}\n",
      "training_task_end\n",
      "training_task_end\n",
      "---------------------------- Task 2 -----------------------\n",
      "[6] Eval metrics for task 1 >> {'accuracy': 0.9933448709880428, 'loss': 0.0008362503973304802, 'std': 0.0004877281308999226, 'EER': -1, 'EO': -1, 'DP': -1, 'accuracy_s0': -1, 'accuracy_s1': -1, 'classwise_accuracy': {0: array([973, 980]), 1: array([1128, 1135])}, 'DP_ingredients': {}}\n",
      "[6] Eval metrics for task 2 >> {'accuracy': 0.0, 'loss': 0.019077572836581687, 'std': 0.0, 'EER': -1, 'EO': -1, 'DP': -1, 'accuracy_s0': -1, 'accuracy_s1': -1, 'classwise_accuracy': {3: array([   0, 1010]), 2: array([   0, 1032])}, 'DP_ingredients': {}}\n",
      "[7] Eval metrics for task 1 >> {'accuracy': 0.9872224220084509, 'loss': 0.0008762574787680985, 'std': 0.006610177110491777, 'EER': -1, 'EO': -1, 'DP': -1, 'accuracy_s0': -1, 'accuracy_s1': -1, 'classwise_accuracy': {0: array([961, 980]), 1: array([1128, 1135])}, 'DP_ingredients': {}}\n",
      "[7] Eval metrics for task 2 >> {'accuracy': 0.04605975132396961, 'loss': 0.00857327500473157, 'std': 0.0024551001611789088, 'EER': -1, 'EO': -1, 'DP': -1, 'accuracy_s0': -1, 'accuracy_s1': -1, 'classwise_accuracy': {3: array([  49, 1010]), 2: array([  45, 1032])}, 'DP_ingredients': {}}\n",
      "[8] Eval metrics for task 1 >> {'accuracy': 0.9751168749438102, 'loss': 0.0008947229343103178, 'std': 0.01695360963768766, 'EER': -1, 'EO': -1, 'DP': -1, 'accuracy_s0': -1, 'accuracy_s1': -1, 'classwise_accuracy': {1: array([1126, 1135]), 0: array([939, 980])}, 'DP_ingredients': {}}\n",
      "[8] Eval metrics for task 2 >> {'accuracy': 0.4327385064087804, 'loss': 0.004860071489089383, 'std': 0.029637731214981977, 'EER': -1, 'EO': -1, 'DP': -1, 'accuracy_s0': -1, 'accuracy_s1': -1, 'classwise_accuracy': {3: array([ 467, 1010]), 2: array([ 416, 1032])}, 'DP_ingredients': {}}\n",
      "[9] Eval metrics for task 1 >> {'accuracy': 0.9651914951002427, 'loss': 0.0008567655199244794, 'std': 0.023354760406365194, 'EER': -1, 'EO': -1, 'DP': -1, 'accuracy_s0': -1, 'accuracy_s1': -1, 'classwise_accuracy': {0: array([923, 980]), 1: array([1122, 1135])}, 'DP_ingredients': {}}\n",
      "[9] Eval metrics for task 2 >> {'accuracy': 0.6902956865453986, 'loss': 0.003206721424005641, 'std': 0.026535996622918112, 'EER': -1, 'EO': -1, 'DP': -1, 'accuracy_s0': -1, 'accuracy_s1': -1, 'classwise_accuracy': {3: array([ 724, 1010]), 2: array([ 685, 1032])}, 'DP_ingredients': {}}\n",
      "[10] Eval metrics for task 1 >> {'accuracy': 0.9567270520543019, 'loss': 0.0008446163812709475, 'std': 0.029176031646138634, 'EER': -1, 'EO': -1, 'DP': -1, 'accuracy_s0': -1, 'accuracy_s1': -1, 'classwise_accuracy': {0: array([909, 980]), 1: array([1119, 1135])}, 'DP_ingredients': {}}\n",
      "[10] Eval metrics for task 2 >> {'accuracy': 0.7886503185202242, 'loss': 0.002376901706448965, 'std': 0.019270473558983814, 'EER': -1, 'EO': -1, 'DP': -1, 'accuracy_s0': -1, 'accuracy_s1': -1, 'classwise_accuracy': {2: array([ 794, 1032]), 3: array([ 816, 1010])}, 'DP_ingredients': {}}\n",
      "training_task_end\n",
      "training_task_end\n",
      "---------------------------- Task 3 -----------------------\n"
     ]
    }
   ],
   "source": [
    "trainer.run()\n",
    "print(\"final avg-acc\", metric_manager_callback.meters['accuracy'].compute_final())\n",
    "print(\"final avg-forget\", metric_manager_callback.meters['forgetting'].compute_final())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebde5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[89.873,  0.   ,  0.   ,  0.   ,  0.   ],\n",
       "       [83.669, 49.881,  0.   ,  0.   ,  0.   ],\n",
       "       [56.745, 59.669, 49.534,  0.   ,  0.   ],\n",
       "       [51.395, 49.234, 48.427, 12.365,  0.   ],\n",
       "       [46.27 , 40.235, 40.714, 24.429, 44.758]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_manager_callback.meters['accuracy'].get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e893eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58.31999894627133"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(metric_manager_callback.meters['accuracy'].compute_overall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c786ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.28119091305616"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.round(x, 3) for x in metric_manager_callback.meters['EO'].compute_overall()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82bd073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.252, 0.356, 0.572, 0.714, 0.689]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(metric_manager_callback.meters['EO'].compute_overall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7973e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5165693908539541"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.round(x, 3) for x in metric_manager_callback.meters['DP'].compute_overall()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61271a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_id=2\n",
      "sensitive samples / all samples = 644 / 12700\n",
      "sensitive samples / selected samples = 503 / 10000\n"
     ]
    }
   ],
   "source": [
    "np.mean(metric_manager_callback.meters['DP'].compute_overall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b743813b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21212733",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
