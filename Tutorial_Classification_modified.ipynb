{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0c3b92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_dir=./outputs/seed=1_epoch=1q__\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST, FashionMNIST, CIFAR10\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import cl_gym as cl\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "seed = 1\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.enabled = False\n",
    "\n",
    "def make_params() -> dict:\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    import uuid\n",
    "\n",
    "    params = {\n",
    "            # dataset\n",
    "            'dataset': \"MNIST\",\n",
    "            # 'dataset': \"FMNIST\",\n",
    "\n",
    "            # benchmark\n",
    "            'seed': seed,\n",
    "            'num_tasks': 5,\n",
    "            'epochs_per_task': 1,\n",
    "            'per_task_examples': np.inf,\n",
    "            'per_task_memory_examples': 20,\n",
    "            'batch_size_train': 64,\n",
    "            'batch_size_memory': 64,\n",
    "            'batch_size_validation': 256,\n",
    "            'lambda': 10,\n",
    "\n",
    "            # algorithm\n",
    "            'optimizer': 'sgd',\n",
    "            'learning_rate': 0.001,\n",
    "            'momentum': 0.9,\n",
    "            'learning_rate_decay': 1.0,\n",
    "            'criterion': torch.nn.CrossEntropyLoss(),\n",
    "            'device': torch.device('cuda:6' if torch.cuda.is_available() else 'cpu'), }\n",
    "\n",
    "#     trial_id = str(uuid.uuid4())\n",
    "    trial_id = f\"seed={params['seed']}_epoch={params['epochs_per_task']}q__\"\n",
    "    params['trial_id'] = trial_id\n",
    "    params['output_dir'] = os.path.join(\"./outputs/{}\".format(trial_id))\n",
    "    print(f\"output_dir={params['output_dir']}\")\n",
    "    Path(params['output_dir']).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    return params\n",
    "\n",
    "params = make_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93b43ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 9 6 4 0 3 1 7 8 5]\n"
     ]
    }
   ],
   "source": [
    "from datasets import MNIST\n",
    "from datasets import FashionMNIST\n",
    "\n",
    "if params['dataset'] == 'MNIST':\n",
    "    benchmark = MNIST(num_tasks=params['num_tasks'],\n",
    "                      per_task_memory_examples=params['per_task_memory_examples'],\n",
    "                      per_task_examples = min(params['per_task_examples'], 10000),\n",
    "                      random_class_idx = True)\n",
    "    label_li = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "    n_feature = 28*28\n",
    "\n",
    "elif params['dataset'] == 'FMNIST':\n",
    "    benchmark = FashionMNIST(num_tasks=params['num_tasks'],\n",
    "                             per_task_memory_examples=params['per_task_memory_examples'],\n",
    "                             per_task_examples = min(params['per_task_examples'], 15000),\n",
    "                             random_class_idx = False)\n",
    "\n",
    "    label_li = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', \n",
    "                  'Ankel boot']\n",
    "    n_feature = 28*28\n",
    "    \n",
    "elif params['dataset'] == 'CIFAR10':\n",
    "    label_li = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    benchmark = cl.benchmarks.SplitCIFAR10(num_tasks=params['num_tasks'],\n",
    "                                        per_task_memory_examples=params['per_task_memory_examples'])\n",
    "    n_feature = 32*32*3\n",
    "\n",
    "params['alpha'] = 0.0501\n",
    "params['lambda'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a330b0c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11907, 1, 28, 28])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark.trains[1].inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1f11bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20c7b886",
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithms import Weighting\n",
    "from metrics import MetricCollector2\n",
    "\n",
    "backbone = cl.backbones.MLP2Layers(input_dim=784, hidden_dim_1=256, hidden_dim_2=256, output_dim=10)\n",
    "algorithm = Weighting(backbone, benchmark, params, requires_memory=True)\n",
    "metric_manager_callback = MetricCollector2(num_tasks=params['num_tasks'],\n",
    "                                                        eval_interval='epoch',\n",
    "                                                        epochs_per_task=params['epochs_per_task'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c1bb4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Task 1 -----------------------\n",
      "sample_weight.to(device)=tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:6')\n",
      "[1] Eval metrics for task 1 >> {'accuracy': 97.64821166095051, 'loss': 0.00030053448386486694, 'std': 0.07149799094967046}\n",
      "training_task_end\n",
      "load_memory_joint: len(train_loader.dataset)=20\n",
      "---------------------------- Task 2 -----------------------\n",
      "A.shape=(4, 10000)\n",
      "b.shape=(4,)\n",
      "np_weight=tensor([0.0356, 0.0322, 0.0301,  ..., 0.0298, 0.0309, 0.0287])\n",
      "np_weight.shape=torch.Size([10000])\n",
      "np_weight.sum()=tensor(303.0024)\n",
      "np_weight.mean()=tensor(0.0303)\n",
      "np_weight.max()=tensor(0.2883)\n",
      "np_weight.min()=tensor(0.0037)\n",
      "np_weight.min()=tensor(0.0037)\n",
      "sample_weight.to(device)=tensor([0.0324, 0.0304, 0.0309, 0.0327, 0.0285, 0.0313, 0.0310, 0.0325, 0.0321,\n",
      "        0.0327, 0.0322, 0.0308, 0.0322, 0.0309, 0.0299, 0.0324, 0.0302, 0.0322,\n",
      "        0.0059, 0.0311, 0.0303, 0.0284, 0.0057, 0.0328, 0.0327, 0.0322, 0.0049,\n",
      "        0.0325, 0.0304, 0.0308, 0.0294, 0.0298, 0.0273, 0.0308, 0.0323, 0.0302,\n",
      "        0.0319, 0.0324, 0.0322, 0.0293, 0.0309, 0.0279, 0.0307, 0.0308, 0.0270,\n",
      "        0.0292, 0.0309, 0.0323, 0.0137, 0.0325, 0.0305, 0.0315, 0.0276, 0.0322,\n",
      "        0.0296, 0.0340, 0.0313, 0.0279, 0.0269, 0.0306, 0.0297, 0.0354, 0.0323,\n",
      "        0.0303], device='cuda:6')\n",
      "[2] Eval metrics for task 1 >> {'accuracy': 94.75747182753553, 'loss': 0.0006137988742282144, 'std': 3.8120577592366423}\n",
      "[2] Eval metrics for task 2 >> {'accuracy': 0.0, 'loss': 0.019074919051730754, 'std': 0.0}\n",
      "training_task_end\n",
      "load_memory_joint: len(train_loader.dataset)=40\n",
      "---------------------------- Task 3 -----------------------\n",
      "A.shape=(6, 10000)\n",
      "b.shape=(6,)\n",
      "np_weight=tensor([2.7127e-09, 8.0733e-09, 8.2769e-09,  ..., 1.0000e+00, 7.0255e-08,\n",
      "        3.7513e-08])\n",
      "np_weight.shape=torch.Size([10000])\n",
      "np_weight.sum()=tensor(162.0007)\n",
      "np_weight.mean()=tensor(0.0162)\n",
      "np_weight.max()=tensor(1.)\n",
      "np_weight.min()=tensor(3.8100e-10)\n",
      "np_weight.min()=tensor(3.8100e-10)\n",
      "sample_weight.to(device)=tensor([5.3876e-08, 3.1242e-08, 1.5713e-08, 3.2644e-09, 1.0786e-08, 2.7394e-09,\n",
      "        2.7903e-09, 1.8475e-09, 3.6378e-09, 3.4742e-08, 3.5249e-09, 3.7953e-09,\n",
      "        1.5363e-09, 1.3564e-08, 5.0569e-08, 3.3205e-09, 1.8811e-09, 3.8606e-07,\n",
      "        2.6537e-09, 1.1489e-09, 3.3181e-08, 2.0513e-09, 1.2545e-09, 4.2985e-09,\n",
      "        3.1990e-09, 3.7061e-09, 4.0681e-09, 1.8318e-09, 2.0737e-08, 4.2238e-09,\n",
      "        2.7940e-09, 7.1116e-08, 3.3040e-09, 2.8616e-09, 1.8336e-09, 2.1738e-08,\n",
      "        4.8128e-09, 3.8089e-09, 4.1348e-07, 6.2376e-08, 6.6928e-09, 3.3656e-09,\n",
      "        3.1186e-09, 6.9208e-10, 2.9075e-08, 2.1992e-09, 1.1626e-09, 2.9343e-07,\n",
      "        4.0996e-09, 1.7049e-08, 3.8580e-09, 1.8208e-08, 1.0443e-08, 2.6392e-09,\n",
      "        4.8747e-09, 7.1874e-08, 1.7848e-09, 1.0000e+00, 1.2383e-07, 2.2485e-09,\n",
      "        9.9908e-10, 3.5547e-09, 1.8202e-09, 1.3162e-09], device='cuda:6')\n",
      "[3] Eval metrics for task 1 >> {'accuracy': 76.87408133268006, 'loss': 0.0033339626470189187, 'std': 1.7974374044452623}\n",
      "[3] Eval metrics for task 2 >> {'accuracy': 90.4639175257732, 'loss': 0.0011455797964764626, 'std': 3.9547980560315334}\n",
      "[3] Eval metrics for task 3 >> {'accuracy': 0.0, 'loss': 0.029494320327912143, 'std': 0.0}\n",
      "training_task_end\n",
      "load_memory_joint: len(train_loader.dataset)=60\n",
      "---------------------------- Task 4 -----------------------\n",
      "A.shape=(8, 10000)\n",
      "b.shape=(8,)\n"
     ]
    }
   ],
   "source": [
    "from trainers import ContinualTrainer2\n",
    "\n",
    "trainer = ContinualTrainer2(algorithm, params, callbacks=[metric_manager_callback])\n",
    "trainer.run()\n",
    "print(\"final avg-acc\", metric_manager_callback.meters['accuracy'].compute_final())\n",
    "print(\"final avg-forget\", metric_manager_callback.meters['forgetting'].compute_final())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c076b062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.07149799094967046,\n",
       " 12.090082371310261,\n",
       " 20.34847661261605,\n",
       " 22.663132044896688,\n",
       " 20.17097425374629]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_manager_callback.meters['std'].get_std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7039ed8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[97.648,  0.   ,  0.   ,  0.   ,  0.   ],\n",
       "       [72.954, 96.804,  0.   ,  0.   ,  0.   ],\n",
       "       [51.935, 90.052, 98.191,  0.   ,  0.   ],\n",
       "       [41.891, 85.103, 91.759, 96.486,  0.   ],\n",
       "       [38.119, 77.68 , 65.879, 88.858, 90.782]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_manager_callback.meters['accuracy'].get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173c4765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.73208188880962"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_manager_callback.meters['accuracy'].compute_overall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706ad34c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
