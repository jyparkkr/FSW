{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0c3b92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_dir=./outputs/dataset=MNIST/seed=1_epoch=1_lr=0.001_alpha=0.002_lambda=10\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST, FashionMNIST, CIFAR10\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import cl_gym as cl\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "seed = 1\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.enabled = False\n",
    "\n",
    "def make_params() -> dict:\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    import uuid\n",
    "\n",
    "    params = {\n",
    "            # dataset\n",
    "            'dataset': \"MNIST\",\n",
    "            # 'dataset': \"FMNIST\",\n",
    "\n",
    "            # benchmark\n",
    "            'seed': seed,\n",
    "            'num_tasks': 5,\n",
    "            'epochs_per_task': 1,\n",
    "            'per_task_examples': 10000,\n",
    "            'per_task_examples': np.inf,\n",
    "            'per_task_memory_examples': 20,\n",
    "            'batch_size_train': 64,\n",
    "            'batch_size_memory': 64,\n",
    "            'batch_size_validation': 256,\n",
    "            'lambda': 10,\n",
    "\n",
    "            # algorithm\n",
    "            'optimizer': 'sgd',\n",
    "            'learning_rate': 0.001,\n",
    "            'momentum': 0.9,\n",
    "            'learning_rate_decay': 1.0,\n",
    "            'criterion': torch.nn.CrossEntropyLoss(),\n",
    "            'device': torch.device('cuda:7' if torch.cuda.is_available() else 'cpu'),\n",
    "             \n",
    "            # sample selection\n",
    "            'alpha':0.002\n",
    "              }\n",
    "\n",
    "#     trial_id = str(uuid.uuid4())\n",
    "    trial_id = f\"dataset={params['dataset']}/seed={params['seed']}_epoch={params['epochs_per_task']}_lr={params['learning_rate']}_alpha={params['alpha']}_lambda={params['lambda']}\"\n",
    "    params['trial_id'] = trial_id\n",
    "    params['output_dir'] = os.path.join(\"./outputs/{}\".format(trial_id))\n",
    "    print(f\"output_dir={params['output_dir']}\")\n",
    "    Path(params['output_dir']).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    return params\n",
    "\n",
    "params = make_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93b43ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "from datasets import MNIST\n",
    "from datasets import FashionMNIST\n",
    "\n",
    "if params['dataset'] == 'MNIST':\n",
    "    benchmark = MNIST(num_tasks=params['num_tasks'],\n",
    "                      per_task_memory_examples=params['per_task_memory_examples'],\n",
    "                      per_task_examples = min(params['per_task_examples'], 10000),\n",
    "                      random_class_idx = False)\n",
    "    label_li = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "    n_feature = 28*28\n",
    "\n",
    "elif params['dataset'] == 'FMNIST':\n",
    "    benchmark = FashionMNIST(num_tasks=params['num_tasks'],\n",
    "                             per_task_memory_examples=params['per_task_memory_examples'],\n",
    "                             per_task_examples = min(params['per_task_examples'], 15000),\n",
    "                             random_class_idx = False)\n",
    "\n",
    "    label_li = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', \n",
    "                  'Ankel boot']\n",
    "    n_feature = 28*28\n",
    "    \n",
    "elif params['dataset'] == 'CIFAR10':\n",
    "    label_li = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    benchmark = cl.benchmarks.SplitCIFAR10(num_tasks=params['num_tasks'],\n",
    "                                        per_task_memory_examples=params['per_task_memory_examples'])\n",
    "    n_feature = 32*32*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a330b0c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12665, 1, 28, 28])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark.trains[1].inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20c7b886",
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithms.imbalance import Heuristic2\n",
    "from metrics import MetricCollector2\n",
    "\n",
    "backbone = cl.backbones.MLP2Layers(input_dim=784, hidden_dim_1=256, hidden_dim_2=256, output_dim=10)\n",
    "algorithm = Heuristic2(backbone, benchmark, params, requires_memory=True)\n",
    "metric_manager_callback = MetricCollector2(num_tasks=params['num_tasks'],\n",
    "                                                        eval_interval='epoch',\n",
    "                                                        epochs_per_task=params['epochs_per_task'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c1bb4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Task 1 -----------------------\n",
      "solver=<function LS_solver at 0x7ff9caa3d280>\n",
      "[1] Eval metrics for task 1 >> {'accuracy': 99.71478018520183, 'loss': 5.772249579394399e-05, 'std': 0.020902634181430013}\n",
      "training_task_end\n",
      "---------------------------- Task 2 -----------------------\n",
      "solver=<function LS_solver at 0x7ff9caa3d280>\n",
      "losses=tensor([[0.0135, 0.0136, 6.6504, 7.1469]], device='cuda:7')\n",
      "n_grads_all.mean(dim=1)=tensor([1.5128e-08, 2.8390e-09, 2.6273e-11, 1.7576e-11], device='cuda:7')\n",
      "A_np.shape=(4, 10000)\n",
      "b_np.shape=(4,)\n",
      "Elapsed time:5.884\n",
      "Loss difference:[1.30764684e-06 1.30764892e-06 1.30765768e-06 1.30764710e-06]\n",
      "len(updated_seq_indices)=10000\n",
      "[2] Eval metrics for task 1 >> {'accuracy': 96.60073721118403, 'loss': 0.0005585125134487242, 'std': 1.358446462285351}\n",
      "[2] Eval metrics for task 2 >> {'accuracy': 92.10367257655999, 'loss': 0.0010151221224423371, 'std': 3.44088187888556}\n",
      "training_task_end\n",
      "---------------------------- Task 3 -----------------------\n",
      "solver=<function LS_solver at 0x7ff9caa3d280>\n",
      "losses=tensor([[1.6479e-03, 2.1344e-03, 4.0760e-01, 2.8132e-01, 7.4605e+00, 8.1433e+00]],\n",
      "       device='cuda:7')\n",
      "n_grads_all.mean(dim=1)=tensor([ 7.5332e-09, -1.9604e-08, -4.6566e-11,  3.0295e-10,  5.7075e-11,\n",
      "         4.4097e-11], device='cuda:7')\n",
      "A_np.shape=(6, 10000)\n",
      "b_np.shape=(6,)\n",
      "Elapsed time:142.283\n",
      "Loss difference:[ 5.18274828  7.12993447 -2.89721478 -4.51071876 -1.7511024  -3.15361705]\n",
      "len(updated_seq_indices)=7119\n",
      "[3] Eval metrics for task 1 >> {'accuracy': 89.39359884923132, 'loss': 0.0016240722885086745, 'std': 0.2099253798435674}\n",
      "[3] Eval metrics for task 2 >> {'accuracy': 75.10150433648016, 'loss': 0.0032934697379561526, 'std': 6.487642950341543}\n",
      "[3] Eval metrics for task 3 >> {'accuracy': 89.70425050003197, 'loss': 0.0012325675026965879, 'std': 3.269272921556632}\n",
      "training_task_end\n",
      "---------------------------- Task 4 -----------------------\n",
      "solver=<function LS_solver at 0x7ff9caa3d280>\n",
      "losses=tensor([[4.1966e-03, 2.5786e-03, 4.1886e-03, 8.9470e-03, 2.4197e-01, 8.4202e-01,\n",
      "         1.0341e+01, 9.0916e+00]], device='cuda:7')\n",
      "n_grads_all.mean(dim=1)=tensor([ 2.2203e-09,  1.6182e-08, -6.6902e-09, -5.7134e-09,  9.0080e-10,\n",
      "        -5.5112e-11,  5.2425e-11,  7.1507e-12], device='cuda:7')\n",
      "A_np.shape=(8, 10000)\n",
      "b_np.shape=(8,)\n",
      "Elapsed time:152.558\n",
      "Loss difference:[ 11.41306053  13.58218966   9.25965447   7.17888503 -12.18979839\n",
      "  -7.83749712 -11.59559548  -9.81090606]\n",
      "len(updated_seq_indices)=8304\n",
      "[4] Eval metrics for task 1 >> {'accuracy': 80.81093230243638, 'loss': 0.002850422763373553, 'std': 5.708891486109863}\n",
      "[4] Eval metrics for task 2 >> {'accuracy': 68.16256044209072, 'loss': 0.00503793309180907, 'std': 5.093253511397649}\n",
      "[4] Eval metrics for task 3 >> {'accuracy': 78.88255413588084, 'loss': 0.003096111842382425, 'std': 9.712150548436881}\n",
      "[4] Eval metrics for task 4 >> {'accuracy': 96.72834943096431, 'loss': 0.0004621887577684504, 'std': 0.03574242707326536}\n",
      "training_task_end\n",
      "---------------------------- Task 5 -----------------------\n",
      "solver=<function LS_solver at 0x7ff9caa3d280>\n",
      "losses=tensor([[3.5153e-03, 5.4957e-03, 4.8516e-03, 4.6619e-03, 1.2635e-02, 6.4606e-03,\n",
      "         3.5885e-01, 1.6050e-02, 1.1226e+01, 1.1904e+01]], device='cuda:7')\n",
      "n_grads_all.mean(dim=1)=tensor([-5.5749e-09,  1.6838e-09, -1.2725e-08,  6.4402e-09,  5.9256e-09,\n",
      "        -1.3973e-08,  7.1875e-10, -4.9909e-09,  1.6280e-12,  4.0248e-11],\n",
      "       device='cuda:7')\n",
      "A_np.shape=(10, 10000)\n",
      "b_np.shape=(10,)\n",
      "Elapsed time:70.644\n",
      "Loss difference:[ 14.13666385  24.27619538  10.22801853  20.44185461   3.6841291\n",
      "  16.29452275 -10.53613243 -21.66692962 -26.3112629  -30.54710593]\n",
      "len(updated_seq_indices)=8907\n",
      "[5] Eval metrics for task 1 >> {'accuracy': 77.57169828283736, 'loss': 0.003749943455905779, 'std': 4.10231052773532}\n",
      "[5] Eval metrics for task 2 >> {'accuracy': 53.197578478778105, 'loss': 0.007940894125958031, 'std': 7.752033924322663}\n",
      "[5] Eval metrics for task 3 >> {'accuracy': 57.107760313444686, 'loss': 0.00736188640462169, 'std': 7.556190806718238}\n",
      "[5] Eval metrics for task 4 >> {'accuracy': 80.882066237216, 'loss': 0.002652565037976099, 'std': 10.454050673013654}\n",
      "[5] Eval metrics for task 5 >> {'accuracy': 92.22622679254269, 'loss': 0.000982888181944177, 'std': 0.43977915393898503}\n",
      "training_task_end\n",
      "final avg-acc 72.19706602096376\n",
      "final avg-forget 27.372987345120492\n"
     ]
    }
   ],
   "source": [
    "from trainers import ContinualTrainer2\n",
    "\n",
    "trainer = ContinualTrainer2(algorithm, params, callbacks=[metric_manager_callback])\n",
    "trainer.run()\n",
    "print(\"final avg-acc\", metric_manager_callback.meters['accuracy'].compute_final())\n",
    "print(\"final avg-forget\", metric_manager_callback.meters['forgetting'].compute_final())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c076b062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.020902634181430013,\n",
       " 3.44940864927104,\n",
       " 8.000457215977727,\n",
       " 11.931833400332684,\n",
       " 16.356347011705232]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_manager_callback.meters['std'].get_std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7039ed8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[99.715,  0.   ,  0.   ,  0.   ,  0.   ],\n",
       "       [96.601, 92.104,  0.   ,  0.   ,  0.   ],\n",
       "       [89.394, 75.102, 89.704,  0.   ,  0.   ],\n",
       "       [80.811, 68.163, 78.883, 96.728,  0.   ],\n",
       "       [77.572, 53.198, 57.108, 80.882, 92.226]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_manager_callback.meters['accuracy'].get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "173c4765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[99.71478018520183,\n",
       " 94.352204893872,\n",
       " 84.73311789524782,\n",
       " 81.14609907784306,\n",
       " 72.19706602096376]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_manager_callback.meters['accuracy'].compute_overall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706ad34c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
