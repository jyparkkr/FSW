{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0c3b92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_dir=./outputs/demo/dataset=MNIST/seed=10_epoch=1_lr=0.001_alpha=0.001_tau=10\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST, FashionMNIST, CIFAR10\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import cl_gym as cl\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "seed = 10\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "# torch.backends.cudnn.enabled = False\n",
    "\n",
    "def make_params() -> dict:\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    import uuid\n",
    "\n",
    "    params = {\n",
    "            # dataset\n",
    "            'dataset': \"MNIST\",\n",
    "            # 'dataset': \"FMNIST\",\n",
    "            'random_class_idx': True,\n",
    "\n",
    "            # benchmark\n",
    "            'seed': seed,\n",
    "            'num_tasks': 5,\n",
    "            'epochs_per_task': 1,\n",
    "            # 'per_task_examples': np.inf,\n",
    "            'per_task_examples': 10000,\n",
    "            'per_task_memory_examples': 20,\n",
    "            'batch_size_train': 64,\n",
    "            'batch_size_memory': 64,\n",
    "            'batch_size_validation': 256,\n",
    "            'tau': 10,\n",
    "            # 'tau': 0.0,\n",
    "\n",
    "            # algorithm\n",
    "            'optimizer': 'sgd',\n",
    "            'learning_rate': 0.001,\n",
    "            'momentum': 0.9,\n",
    "            'learning_rate_decay': 1.0,\n",
    "            'criterion': torch.nn.CrossEntropyLoss(),\n",
    "            'device': torch.device('cuda:7' if torch.cuda.is_available() else 'cpu'),\n",
    "             \n",
    "            # sample selection\n",
    "            'alpha':0.001,\n",
    "            'lambda': .01,\n",
    "            'lambda_old': 0.0,\n",
    "              }\n",
    "\n",
    "#     trial_id = str(uuid.uuid4())\n",
    "    trial_id = f\"demo/dataset={params['dataset']}/seed={params['seed']}_epoch={params['epochs_per_task']}_lr={params['learning_rate']}_alpha={params['alpha']}_tau={params['tau']}\"\n",
    "    params['trial_id'] = trial_id\n",
    "    params['output_dir'] = os.path.join(\"./outputs/{}\".format(trial_id))\n",
    "    print(f\"output_dir={params['output_dir']}\")\n",
    "    Path(params['output_dir']).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    return params\n",
    "\n",
    "params = make_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93b43ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 2 5 6 3 1 0 7 4 9]\n"
     ]
    }
   ],
   "source": [
    "from datasets import MNIST\n",
    "from datasets import FashionMNIST\n",
    "from datasets import CIFAR10, CIFAR100\n",
    "\n",
    "if params['dataset'] == 'MNIST':\n",
    "    benchmark = MNIST(num_tasks=params['num_tasks'],\n",
    "                    per_task_memory_examples=params['per_task_memory_examples'],\n",
    "                    per_task_examples = params['per_task_examples'],\n",
    "                    random_class_idx = params['random_class_idx'])\n",
    "    input_dim = (28, 28)\n",
    "elif params['dataset'] == 'FashionMNIST':\n",
    "    benchmark = FashionMNIST(num_tasks=params['num_tasks'],\n",
    "                            per_task_memory_examples=params['per_task_memory_examples'],\n",
    "                            per_task_examples = params['per_task_examples'],\n",
    "                            random_class_idx = params['random_class_idx'])\n",
    "    input_dim = (28, 28)\n",
    "elif params['dataset'] == 'CIFAR10':\n",
    "    benchmark = CIFAR10(num_tasks=params['num_tasks'],\n",
    "                        per_task_memory_examples=params['per_task_memory_examples'],\n",
    "                        per_task_examples = params['per_task_examples'],\n",
    "                        random_class_idx = params['random_class_idx'])\n",
    "    input_dim = (3, 32, 32)\n",
    "elif params['dataset'] == 'CIFAR100':        \n",
    "    benchmark = CIFAR100(num_tasks=params['num_tasks'],\n",
    "                        per_task_memory_examples=params['per_task_memory_examples'],\n",
    "                        per_task_examples = params['per_task_examples'],\n",
    "                        random_class_idx = params['random_class_idx'])\n",
    "    input_dim = (3, 32, 32)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "class_idx = benchmark.class_idx\n",
    "num_classes = len(class_idx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20c7b886",
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithms.imbalance import Heuristic2\n",
    "from metrics import MetricCollector2\n",
    "from backbones import MLP2Layers2\n",
    "\n",
    "backbone = MLP2Layers2(\n",
    "    input_dim=input_dim, \n",
    "    hidden_dim_1=256, \n",
    "    hidden_dim_2=256, \n",
    "    output_dim=num_classes,\n",
    "    class_idx=class_idx,\n",
    "    config=params\n",
    "    ).to(params['device'])\n",
    "algorithm = Heuristic2(backbone, benchmark, params, requires_memory=True)\n",
    "metric_manager_callback = MetricCollector2(num_tasks=params['num_tasks'],\n",
    "                                                        eval_interval='epoch',\n",
    "                                                        epochs_per_task=params['epochs_per_task'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0323bffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 6, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_manager_callback.meters['accuracy'].data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8efa3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainers import ContinualTrainer\n",
    "\n",
    "trainer = ContinualTrainer(algorithm, params, callbacks=[metric_manager_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c1bb4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Task 1 -----------------------\n",
      "[1] Eval metrics for task 1 >> {'accuracy': 95.8125407892014, 'loss': 0.0005002836970721974, 'fairness': 1.7233935023796998}\n",
      "training_task_end\n",
      "---------------------------- Task 2 -----------------------\n",
      "losses=tensor([[0.0475, 0.0174, 7.5142, 7.8053]])\n",
      "### Cplex absolute_minsum LP solver ###\n",
      "Elapsed time:7.414\n",
      "Fairness:[ 0.10105552  0.31314608 -0.2156891  -0.19851232]\n",
      "Current class loss:[ 0.          0.         -0.01025406 -0.00991053]\n",
      "len(updated_seq_indices)=10000\n",
      "[2] Eval metrics for task 1 >> {'accuracy': 75.33019355968355, 'loss': 0.0036637909331564177, 'fairness': 1.5108917116342768}\n",
      "[2] Eval metrics for task 2 >> {'accuracy': 95.51557804469326, 'loss': 0.0006347872437657537, 'fairness': 1.4572820805677011}\n",
      "training_task_end\n",
      "---------------------------- Task 3 -----------------------\n",
      "losses=tensor([[2.7578e-03, 1.7131e-03, 1.2940e-01, 8.6148e-02, 9.8699e+00, 8.1102e+00]])\n",
      "### Cplex absolute_minsum LP solver ###\n",
      "Elapsed time:10.045\n",
      "Fairness:[ 0.36839532  0.29107882 -0.11196433  0.40110338 -0.70648392 -0.24212942]\n",
      "Current class loss:[ 0.          0.          0.          0.         -0.02750858 -0.01357795]\n",
      "len(updated_seq_indices)=8880\n",
      "[3] Eval metrics for task 1 >> {'accuracy': 59.39524537191794, 'loss': 0.007797314602499113, 'fairness': 4.36444455056269}\n",
      "[3] Eval metrics for task 2 >> {'accuracy': 82.09718490502449, 'loss': 0.0027044484422013566, 'fairness': 7.8819382682531804}\n",
      "[3] Eval metrics for task 3 >> {'accuracy': 95.5218737732804, 'loss': 0.0005472483543249277, 'fairness': 3.2446460505081323}\n",
      "training_task_end\n",
      "---------------------------- Task 4 -----------------------\n",
      "losses=tensor([[2.3916e-03, 2.9775e-03, 5.4731e-03, 1.9817e-03, 9.2545e-02, 2.2334e-02,\n",
      "         1.2558e+01, 9.7479e+00]])\n",
      "### Cplex absolute_minsum LP solver ###\n",
      "Elapsed time:12.867\n",
      "Fairness:[ 0.28273883  0.30346234  0.01245344  0.23634848  0.04733026  0.24675364\n",
      " -0.7366056  -0.39248135]\n",
      "Current class loss:[ 0.          0.          0.          0.          0.          0.\n",
      " -0.0366728  -0.02290782]\n",
      "len(updated_seq_indices)=10000\n",
      "[4] Eval metrics for task 1 >> {'accuracy': 56.91098403450966, 'loss': 0.008782258775393485, 'fairness': 7.527000461614378}\n",
      "[4] Eval metrics for task 2 >> {'accuracy': 65.78119587706077, 'loss': 0.005796727489780736, 'fairness': 12.193751930872427}\n",
      "[4] Eval metrics for task 3 >> {'accuracy': 92.25912679373664, 'loss': 0.0011233272808137196, 'fairness': 4.833384219479214}\n",
      "[4] Eval metrics for task 4 >> {'accuracy': 97.23100134995633, 'loss': 0.00037980436596025036, 'fairness': 0.8302231398395921}\n",
      "training_task_end\n",
      "---------------------------- Task 5 -----------------------\n",
      "losses=tensor([[1.9954e-03, 1.4270e-03, 4.4837e-03, 3.4424e-03, 6.4576e-03, 4.1950e-03,\n",
      "         9.7020e-02, 2.4125e-02, 9.6477e+00, 1.0661e+01]])\n",
      "### Cplex absolute_minsum LP solver ###\n",
      "Elapsed time:14.675\n",
      "Fairness:[ 0.24566149  0.06462454  0.17565288  0.10205087  0.25714925  0.2255132\n",
      "  0.08316422 -0.33856705 -0.36598496 -0.44926477]\n",
      "Current class loss:[ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.         -0.02003363 -0.02419762]\n",
      "len(updated_seq_indices)=10000\n",
      "[5] Eval metrics for task 1 >> {'accuracy': 54.11931139869156, 'loss': 0.009051777132724599, 'fairness': 9.252781624564252}\n",
      "[5] Eval metrics for task 2 >> {'accuracy': 63.575788498085515, 'loss': 0.006619628313425425, 'fairness': 14.92107997790614}\n",
      "[5] Eval metrics for task 3 >> {'accuracy': 89.42055218737733, 'loss': 0.001568119578706079, 'fairness': 7.1433244646050555}\n",
      "[5] Eval metrics for task 4 >> {'accuracy': 84.99622806320973, 'loss': 0.0020377914981538083, 'fairness': 7.758873977606607}\n",
      "[5] Eval metrics for task 5 >> {'accuracy': 92.26922059912923, 'loss': 0.0009832909468248943, 'fairness': 0.29697084689929154}\n",
      "training_task_end\n",
      "final avg-acc 76.87622014929866\n",
      "final avg-forget 22.992278452441816\n"
     ]
    }
   ],
   "source": [
    "trainer.run()\n",
    "print(\"final avg-acc\", metric_manager_callback.meters['accuracy'].compute_final())\n",
    "print(\"final avg-forget\", metric_manager_callback.meters['forgetting'].compute_final())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ebfb58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 10.092692242504853,\n",
       " 13.073015096548668,\n",
       " 16.699487058030634,\n",
       " 14.422936160728108]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_manager_callback.meters['fairness'].get_eer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7039ed8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[95.813,  0.   ,  0.   ,  0.   ,  0.   ],\n",
       "       [75.33 , 95.516,  0.   ,  0.   ,  0.   ],\n",
       "       [59.395, 82.097, 95.522,  0.   ,  0.   ],\n",
       "       [56.911, 65.781, 92.259, 97.231,  0.   ],\n",
       "       [54.119, 63.576, 89.421, 84.996, 92.269]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_manager_callback.meters['accuracy'].get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "173c4765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.03239835424907"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_manager_callback.meters['accuracy'].compute_overall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "706ad34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:83.03239835424907\n",
      "fairness:10.857626111562451\n"
     ]
    }
   ],
   "source": [
    "print(f\"accuracy:{np.mean(metric_manager_callback.meters['accuracy'].compute_overall())}\")\n",
    "print(f\"fairness:{np.mean(metric_manager_callback.meters['fairness'].compute_overall())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b848e47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
